#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Water Quality App (Enterprise-Grade UI)
-----------------------------------------
Î¦Î¹Î»Î¹ÎºÏŒ, ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÏŒ Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½ Î±Î½Î¬Î»Ï…ÏƒÎ·Ï‚ Î´Î¿ÏÏ…Ï†Î¿ÏÎ¹ÎºÏÎ½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Ï…Î´Î¬Ï„Ï‰Î½.
"""

import os
import glob
import re
from datetime import datetime, date
import xml.etree.ElementTree as ET
import io

import numpy as np
import pandas as pd
import rasterio
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import streamlit_authenticator as stauth
from plotly.subplots import make_subplots

from rasterio.errors import NotGeoreferencedWarning
import warnings
warnings.filterwarnings("ignore", category=NotGeoreferencedWarning)

import matplotlib.pyplot as plt
import matplotlib.colors as mcolors

import streamlit_authenticator as stauth # <--- Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Î³Î¹Î± Î±Ï…Î¸ÎµÎ½Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·

# --- PAGE CONFIGURATION (MUST BE THE FIRST STREAMLIT COMMAND) ---
st.set_page_config(layout="wide", page_title="Î‘Î½Î¬Î»Ï…ÏƒÎ· Î Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ Î•Ï€Î¹Ï†Î±Î½ÎµÎ¹Î±ÎºÏÎ½ Î¥Î´Î¬Ï„Ï‰Î½ Î¤Î±Î¼Î¹ÎµÏ…Ï„Î®ÏÏ‰Î½ Î•Î¥Î‘Î˜ Î‘Î•", page_icon="ğŸ’§")
# --------------------------------------------------------------------

# --- AUTHENTICATION SETUP ---

# --- STEP 1: (Î‘Î¥Î¤ÎŸ Î¤ÎŸ Î’Î—ÎœÎ‘ Î•Î™ÎÎ‘Î™ Î Î›Î•ÎŸÎ Î Î•Î¡Î™Î¤Î¤ÎŸ ÎšÎ‘Î™ Î Î‘Î¡Î‘Î›Î•Î™Î Î•Î¤Î‘Î™/Î£Î§ÎŸÎ›Î™Î‘Î–Î•Î¤Î‘Î™) ---
# =======================================================================================
# # WHEN YOU RUN THIS SCRIPT FIRST, THIS BLOCK WILL BE ACTIVE:
# # import streamlit_authenticator as stauth # Already imported above
# # import streamlit as st
#
# # CHOOSE YOUR ACTUAL PASSWORDS HERE (MAKE SURE THEY ARE STRONG):
# # passwords_for_users = ['123'] # <--- YOUR SINGLE PASSWORD FOR 'ilioumbas'
#
# # Corrected Hasher usage
# # hashed_passwords_for_script = stauth.Hasher.hash_list(passwords_for_users)
# # st.write("--- IMPORTANT: HASHED PASSWORD GENERATION (Temporary) ---")
# # st.write("1. Copy this entire list (including the square brackets and quotes).")
# # st.write("2. Paste it to replace the 'hashed_passwords_list' variable below (in STEP 3).")
# # st.write("3. After pasting, comment out or delete this entire 'STEP 1' debug block.")
# # st.write("4. Re-run the Streamlit app with STEP 1 commented out.")
# # st.write("Generated Hashes:", hashed_passwords_for_script)
# # st.stop() # Stops the app here after printing, so you can copy the hashes
# =======================================================================================

# --- STEP 2: Define your users and their credentials ---
names = ["Ilioumbas User"]  # Display name for your user
usernames = ["ilioumbas"]   # Username for login
# ÎŸÏÎ¯ÏƒÏ„Îµ ÎµÎ´Ï Ï„Î¿Ï…Ï‚ ÎºÏ‰Î´Î¹ÎºÎ¿ÏÏ‚ Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ·Ï‚ ÏƒÎµ Î±Ï€Î»ÏŒ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ (plain text)
# Î— Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ· Î¸Î± Ï„Î¿Ï…Ï‚ ÎºÏÏ…Ï€Ï„Î¿Î³ÏÎ±Ï†Î®ÏƒÎµÎ¹ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î±.
plain_text_passwords = ["123"] # <--- YOUR SINGLE PLAIN TEXT PASSWORD FOR 'ilioumbas'

# --- STEP 3 (Î¤ÏÎ¿Ï€Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿): Create credentials dictionary using PLAIN TEXT passwords ---
credentials = {"usernames": {}}
if len(names) == len(usernames) == len(plain_text_passwords): # Basic check
    for i in range(len(usernames)):
        credentials["usernames"][usernames[i]] = {
            "name": names[i],
            "password": plain_text_passwords[i]  # Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ Ï„Î¿Î½ Î±Ï€Î»ÏŒ ÎºÏ‰Î´Î¹ÎºÏŒ ÎµÎ´Ï
        }
else:
    st.error("Error: The lists for names, usernames, and plain_text_passwords must have the same number of items.")
    st.error("Please ensure you have defined users and their plain text passwords correctly.")
    st.error(f"Debug: len(names)={len(names)}, len(usernames)={len(usernames)}, len(plain_text_passwords)={len(plain_text_passwords)}")
    st.stop()

# --- Optional Debugging: You can uncomment this to see the credentials (with plain passwords)
# --- before they are passed to the Authenticator. REMEMBER TO COMMENT IT OUT AGAIN.
# st.write("--- Debug: Credentials with PLAIN PASSWORDS (before auto-hashing) ---")
# st.write(credentials)
# st.write("--- End Debug ---")

# --- STEP 4: Initialize the Authenticator ---
# Î— Ï€Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Ï‚ auto_hash ÎµÎ¯Î½Î±Î¹ True Î±Ï€ÏŒ Ï€ÏÎ¿ÎµÏ€Î¹Î»Î¿Î³Î®.
# Î‘Ï…Ï„ÏŒ ÏƒÎ·Î¼Î±Î¯Î½ÎµÎ¹ ÏŒÏ„Î¹ Î· Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ· Î¸Î± ÎºÏÏ…Ï€Ï„Î¿Î³ÏÎ±Ï†Î®ÏƒÎµÎ¹ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î±
# Ï„Î¿Ï…Ï‚ Î±Ï€Î»Î¿ÏÏ‚ ÎºÏ‰Î´Î¹ÎºÎ¿ÏÏ‚ Ï€Î¿Ï… Ï€Î±ÏÎ­Ï‡Î¿Î½Ï„Î±Î¹ ÏƒÏ„Î¿ 'credentials' dictionary.
authenticator = None # Initialize to None in case of error below
try:
    authenticator = stauth.Authenticate(
        credentials,
        "water_quality_app_cookie_v6",    # Changed cookie name slightly for freshness
        "a_very_random_secret_key_v6",  # Changed key slightly for freshness
        cookie_expiry_days=30
        # auto_hash=True # Î‘Ï…Ï„Î® ÎµÎ¯Î½Î±Î¹ Î· Ï€ÏÎ¿ÎµÏ€Î¹Î»Î¿Î³Î®, Î´ÎµÎ½ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ Î½Î± Ï„Î¿ Î¿ÏÎ¯ÏƒÎµÏ„Îµ ÏÎ·Ï„Î¬
    )
except Exception as e:
    st.error(f"Error during stauth.Authenticate initialization: {e}")
    st.error("This often happens if the 'credentials' dictionary is malformed.")
    st.stop()

# --- Optional Debugging: Uncomment if you still face issues ---
# st.write("--- Debug: Authenticator Object Inspection (Post-User-Update) ---")
# st.write(f"Authenticator object after initialization: {authenticator}")
# if authenticator:
#     if hasattr(authenticator, 'credentials'): # The 'credentials' attribute of the authenticator object
#                                              # will now store the *hashed* passwords.
#         st.write(f"Authenticator.credentials (internal - should have hashed passwords now): {authenticator.credentials}")
#     else:
#         st.write("Authenticator object does NOT have a 'credentials' attribute after init.")
# else:
#     st.write("Authenticator object is None after initialization attempt.")
# st.write("--- End Debug: Authenticator Object Inspection ---")
# --- END OF AUTHENTICATION SETUP ---

# --- Global Configuration & Constants ---
DEBUG = False
APP_BASE_DIR = os.path.dirname(os.path.abspath(__file__)) if "__file__" in locals() else os.getcwd()
LOGO_PATH = os.path.join(APP_BASE_DIR, "logo.jpg")

WATERBODY_FOLDERS = {
    "Î“Î±Î´Î¿Ï…ÏÎ¬": "Gadoura",
}

SESSION_KEY_WATERBODY = "waterbody_choice_main"
SESSION_KEY_INDEX = "index_choice_main"
SESSION_KEY_ANALYSIS = "analysis_choice_main"
SESSION_KEY_DEFAULT_RESULTS_DASHBOARD = "dashboard_default_sampling_results"
SESSION_KEY_UPLOAD_RESULTS_DASHBOARD = "dashboard_upload_sampling_results"
SESSION_KEY_CURRENT_IMAGE_INDEX_DASH_DEF = "dash_def_current_image_idx"
SESSION_KEY_CURRENT_IMAGE_INDEX_DASH_UPL = "dash_upl_current_image_idx"

def debug_message(*args, **kwargs):
    if DEBUG:
        with st.expander("Debug Messages", expanded=False):
            st.write(*args, **kwargs)

def inject_custom_css():
    custom_css = """
    <link href="https://fonts.googleapis.com/css?family=Roboto:400,500,700&display=swap" rel="stylesheet">
    <style>
        html, body, [class*="css"] { font-family: 'Roboto', sans-serif; }
        .block-container { background: #161b22; color: #e0e0e0; padding: 1.2rem; }
        .stSidebar > div:first-child { background: #23272f; border-right: 1px solid #3a3f47; }
        .card {
            background: #1a1a1d; padding: 2rem 2.5rem; border-radius: 16px;
            box-shadow: 0 4px 16px rgba(0,0,0,0.25); margin-bottom: 2rem;
            animation: fadein 1.0s ease-in-out;
        }
        @keyframes fadein {
            0% {opacity:0; transform: translateY(10px);}
            100%{opacity:1; transform: translateY(0px);}
        }
        .header-title {
            color: #ffd600; margin-bottom: 1.5rem; font-size: 2.2rem;
            text-align: center; letter-spacing: 0.5px; font-weight: 700;
        }
        .nav-section {
            padding: 1rem 1.2rem; background: #2c2f36; border-radius: 10px;
            margin-bottom: 1.2rem; border-left: 4px solid #ffd600;
        }
        .nav-section h4 { margin: 0; color: #ffd600; font-weight: 500; font-size: 1.1rem; }
        .stButton button {
            background-color: #009688; color: #ffffff; border-radius: 8px;
            padding: 10px 22px; border: none; box-shadow: 0 3px 8px rgba(0,0,0,0.15);
            font-size: 1.05rem; transition: background-color 0.2s, box-shadow 0.2s, transform 0.2s;
            cursor: pointer;
        }
        .stButton button:hover {
            background-color: #00796b; box-shadow: 0 4px 12px rgba(0,0,0,0.2);
            transform: translateY(-1px);
        }
        .stButton button:active { background-color: #00695c; transform: translateY(0px); }
        .plotly-graph-div { border: 1px solid #2a2e37; border-radius: 10px; }
        .footer {
            text-align:center; color: #7a828e; font-size:0.85rem;
            padding: 2rem 0 0.5rem 0; border-top: 1px solid #2a2e37;
        }
        .footer a { color: #009688; text-decoration: none; }
        .footer a:hover { text-decoration: underline; }
    </style>
    """
    st.markdown(custom_css, unsafe_allow_html=True)

def add_excel_download_button(df_or_dict_of_dfs, filename_prefix: str, button_label_suffix: str, plot_key: str):
    if df_or_dict_of_dfs is None:
        debug_message(f"No data provided for Excel export: {button_label_suffix}")
        return

    is_empty_df = isinstance(df_or_dict_of_dfs, pd.DataFrame) and df_or_dict_of_dfs.empty
    is_empty_dict = False
    if isinstance(df_or_dict_of_dfs, dict):
        if not df_or_dict_of_dfs:
            is_empty_dict = True
        else:
            all_dfs_in_dict_empty = True
            for df_item in df_or_dict_of_dfs.values():
                if isinstance(df_item, pd.DataFrame) and not df_item.empty:
                    all_dfs_in_dict_empty = False
                    break
            if all_dfs_in_dict_empty:
                is_empty_dict = True

    if is_empty_df or is_empty_dict:
        debug_message(f"Empty data provided for Excel export: {button_label_suffix}")
        return

    output = io.BytesIO()
    try:
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            if isinstance(df_or_dict_of_dfs, pd.DataFrame):
                df_or_dict_of_dfs.to_excel(writer, index=False, sheet_name='Data')
            elif isinstance(df_or_dict_of_dfs, dict):
                for sheet_name, data_df in df_or_dict_of_dfs.items():
                    if isinstance(data_df, pd.DataFrame) and not data_df.empty:
                        sane_sheet_name = re.sub(r'[\[\]\*\/\\?\:\']', '_', str(sheet_name))[:31]
                        data_df.to_excel(writer, index=False, sheet_name=sane_sheet_name)
                    elif isinstance(data_df, pd.DataFrame) and data_df.empty:
                        debug_message(f"Empty DataFrame for sheet '{sheet_name}' in Excel export: {button_label_suffix}")
        excel_data = output.getvalue()
        if not excel_data:
            debug_message(f"No data written to Excel buffer for: {button_label_suffix}")
            return

        file_name_suffix = button_label_suffix.lower().replace(' ', '_').replace('/', '_').replace('&', 'and').replace('(', '').replace(')', '')
        st.download_button(
            label=f"ğŸ“¥ Save {button_label_suffix} to Excel",
            data=excel_data,
            file_name=f"{filename_prefix}_{file_name_suffix}.xlsx",
            mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            key=f"download_{plot_key}"
        )
    except Exception as e:
        st.warning(f"Could not generate Excel file for {button_label_suffix}: {e}")
        debug_message(f"Excel generation error for {button_label_suffix}: {e}")

def render_footer():
    st.markdown(f"""
        <hr style="border-color: #2a2e37;">
        <div class='footer'>
            Â© {datetime.now().year} EYATH SA â€¢ Powered by Google Gemini & Streamlit | Contact: <a href='mailto:ilioumbas@eyath.gr'>ilioumbas@eyath.gr</a>
        </div>
    """, unsafe_allow_html=True)

def run_intro_page_custom():
    with st.container():
        st.markdown('<div class="card">', unsafe_allow_html=True)
        col_logo, col_text = st.columns([0.3, 0.7], gap="large")
        with col_logo:
            if os.path.exists(LOGO_PATH):
                st.image(LOGO_PATH, width=240, output_format="auto")
            else:
                st.markdown("ğŸ’§", help="Î›Î¿Î³ÏŒÏ„Ï…Ï€Î¿ Î•Î¥Î‘Î˜")
        with col_text:
            user_name_display = st.session_state.get("name", "Î•Ï€Î¹ÏƒÎºÎ­Ï€Ï„Î·")
            st.markdown(f"""
                <h2 class='header-title'>Î•Ï†Î±ÏÎ¼Î¿Î³Î® Î‘Î½Î¬Î»Ï…ÏƒÎ·Ï‚ Î Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ Î•Ï€Î¹Ï†Î±Î½ÎµÎ¹Î±ÎºÏÎ½ Î¥Î´Î¬Ï„Ï‰Î½ Î¤Î±Î¼Î¹ÎµÏ…Ï„Î®ÏÏ‰Î½ Î•Î¥Î‘Î˜ Î‘Î•</h2>
                <p style='font-size:1.15rem;text-align:center; line-height:1.6;'>
                ÎšÎ±Î»Ï‰ÏƒÎ®ÏÎ¸Î±Ï„Îµ, <strong>{user_name_display}</strong>!<br>
                Î•Î¾ÎµÏÎµÏ…Î½Î®ÏƒÏ„Îµ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ Î¼Îµ ÎµÏ…ÎºÎ¿Î»Î¯Î±.<br>
                Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Ï„Î¹ Î¸Î­Î»ÎµÏ„Îµ Î½Î± Î´ÎµÎ¯Ï„Îµ Î±Ï€ÏŒ Ï„Î¿ Ï€Î»Î¬Î¹ Ï€Î±ÏÎ¬Î³Î¿Î½Ï„Î±Ï‚ Î´Ï…Î½Î±Î¼Î¹ÎºÎ¬, Î´Î¹Î±Î´ÏÎ±ÏƒÏ„Î¹ÎºÎ¬ Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î±
                </p>
                """, unsafe_allow_html=True)
        with st.expander("ğŸ”° ÎŸÎ´Î·Î³Î¯ÎµÏ‚ Î§ÏÎ®ÏƒÎ·Ï‚", expanded=False):
            st.markdown("""
                - **Î•Ï€Î¹Î»Î¿Î³Î® Î Î±ÏÎ±Î¼Î­Ï„ÏÏ‰Î½:** Î£Ï„Î·Î½ Ï€Î»Î±ÏŠÎ½Î® Î¼Ï€Î¬ÏÎ± (Î±ÏÎ¹ÏƒÏ„ÎµÏÎ¬), ÎµÏ€Î¹Î»Î­Î¾Ï„Îµ Ï„Î¿ Ï…Î´Î¬Ï„Î¹Î½Î¿ ÏƒÏÎ¼Î±, Ï„Î¿Î½ Î´ÎµÎ¯ÎºÏ„Î· Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ ÎºÎ±Î¹ Ï„Î¿ ÎµÎ¯Î´Î¿Ï‚ Ï„Î·Ï‚ Î±Î½Î¬Î»Ï…ÏƒÎ·Ï‚ Ï€Î¿Ï… ÎµÏ€Î¹Î¸Ï…Î¼ÎµÎ¯Ï„Îµ.
                - **Î Î»Î¿Î®Î³Î·ÏƒÎ· ÏƒÏ„Î± Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±:** ÎœÎµÏ„Î¬ Ï„Î·Î½ ÎµÏ€Î¹Î»Î¿Î³Î®, Ï„Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± ÎºÎ±Î¹ Ï„Î± Î´Î¹Î±Î´ÏÎ±ÏƒÏ„Î¹ÎºÎ¬ Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î± Î¸Î± ÎµÎ¼Ï†Î±Î½Î¹ÏƒÏ„Î¿ÏÎ½ ÏƒÏ„Î·Î½ ÎºÏÏÎ¹Î± Ï€ÎµÏÎ¹Î¿Ï‡Î®. Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï„Î¹Ï‚ ÎºÎ±ÏÏ„Î­Î»ÎµÏ‚ (tabs) Î³Î¹Î± Î½Î± Î´ÎµÎ¯Ï„Îµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ Î¿Ï€Ï„Î¹ÎºÎ¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚.
                - **Î ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÎ¼Î­Î½Î· Î”ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î±:** Î£Ï„Î·Î½ ÎµÎ½ÏŒÏ„Î·Ï„Î± "Î ÏÎ¿Ï†Î¯Î» Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ ÎºÎ±Î¹ ÏƒÏ„Î¬Î¸Î¼Î·Ï‚", Î¼Ï€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± Î±Î½ÎµÎ²Î¬ÏƒÎµÏ„Îµ Ï„Î¿ Î´Î¹ÎºÏŒ ÏƒÎ±Ï‚ Î±ÏÏ‡ÎµÎ¯Î¿ KML Î³Î¹Î± Î±Î½Î¬Î»Ï…ÏƒÎ· ÏƒÎµ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î± ÏƒÎ·Î¼ÎµÎ¯Î± ÎµÎ½Î´Î¹Î±Ï†Î­ÏÎ¿Î½Ï„Î¿Ï‚.
                - **Î¦Î¯Î»Ï„ÏÎ±:** Î£Îµ Î¿ÏÎ¹ÏƒÎ¼Î­Î½ÎµÏ‚ Î±Î½Î±Î»ÏÏƒÎµÎ¹Ï‚, Î¸Î± Î²ÏÎµÎ¯Ï„Îµ ÎµÏ€Î¹Ï€Î»Î­Î¿Î½ Ï†Î¯Î»Ï„ÏÎ± ÏƒÏ„Î·Î½ Ï€Î»Î±ÏŠÎ½Î® Î¼Ï€Î¬ÏÎ± (Ï€.Ï‡., ÎµÏÏÎ¿Ï‚ Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¹ÏÎ½, Ï„Î¹Î¼Î­Ï‚ pixel) Î³Î¹Î± Î½Î± Ï€ÏÎ¿ÏƒÎ±ÏÎ¼ÏŒÏƒÎµÏ„Îµ Ï„Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±.
                - **Î•Ï€ÎµÎ¾Î·Î³Î®ÏƒÎµÎ¹Ï‚:** ÎšÎ¬Î½Ï„Îµ ÎºÎ»Î¹Îº ÏƒÏ„Î± ÎµÎ¹ÎºÎ¿Î½Î¯Î´Î¹Î± â„¹ï¸ Î® ÏƒÏ„Î± expanders Î³Î¹Î± Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎµÏ‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ ÏƒÏ‡ÎµÏ„Î¹ÎºÎ¬ Î¼Îµ ÎºÎ¬Î¸Îµ Î³ÏÎ¬Ï†Î·Î¼Î± Î® ÎµÏ€Î¹Î»Î¿Î³Î®.
                - **Î‘ÏƒÏ†Î¬Î»ÎµÎ¹Î± Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½:** ÎŒÎ»Î± Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÎºÎ±Î¹ Ï„Î± Î±ÏÏ‡ÎµÎ¯Î± Ï€Î¿Ï… Î±Î½ÎµÎ²Î¬Î¶ÎµÏ„Îµ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î¬Î¶Î¿Î½Ï„Î±Î¹ Ï„Î¿Ï€Î¹ÎºÎ¬ ÏƒÏ„Î¿Î½ Ï€ÎµÏÎ¹Î·Î³Î·Ï„Î® ÏƒÎ±Ï‚ ÎºÎ±Î¹ Î´ÎµÎ½ Î¼ÎµÏ„Î±Ï†Î¿ÏÏ„ÏÎ½Î¿Î½Ï„Î±Î¹ ÏƒÎµ ÎµÎ¾Ï‰Ï„ÎµÏÎ¹ÎºÎ¿ÏÏ‚ Î´Î¹Î±ÎºÎ¿Î¼Î¹ÏƒÏ„Î­Ï‚.
                """)
        st.markdown('</div>', unsafe_allow_html=True)

def run_custom_sidebar_ui_custom():
    global authenticator # Access the globally defined authenticator
    if authenticator and st.session_state.get("authentication_status"): # Check if authenticator is valid and user is logged in
        st.sidebar.success(f"Î£Ï…Î½Î´ÎµÎ¸Î®ÎºÎ±Ï„Îµ Ï‰Ï‚: {st.session_state.get('name', 'N/A')}")
        authenticator.logout("Î‘Ï€Î¿ÏƒÏÎ½Î´ÎµÏƒÎ·", "sidebar", key='unique_logout_button_key')
        st.sidebar.markdown("<hr>", unsafe_allow_html=True)

    st.sidebar.markdown("<div class='nav-section'><h4>ğŸ› ï¸ Î•Ï€Î¹Î»Î¿Î³Î­Ï‚ Î‘Î½Î¬Î»Ï…ÏƒÎ·Ï‚</h4></div>", unsafe_allow_html=True)
    st.sidebar.info("â” Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Ï„Î¹Ï‚ ÏÏ…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚ ÏƒÎ±Ï‚ ÎºÎ±Î¹ Ï€ÏÎ¿Ï‡Ï‰ÏÎ®ÏƒÏ„Îµ ÏƒÏ„Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±!")

    waterbody_options = list(WATERBODY_FOLDERS.keys())
    default_wb_idx = 0 if waterbody_options else None

    waterbody = st.sidebar.selectbox("ğŸŒŠ Î¥Î´Î¬Ï„Î¹Î½Î¿ ÏƒÏÎ¼Î±", waterbody_options, index=default_wb_idx, key=SESSION_KEY_WATERBODY)
    index_name = st.sidebar.selectbox("ğŸ”¬ Î”ÎµÎ¯ÎºÏ„Î·Ï‚", ["Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ", "Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·", "Î˜Î¿Î»ÏŒÏ„Î·Ï„Î±"], key=SESSION_KEY_INDEX)
    analysis_type = st.sidebar.selectbox( "ğŸ“Š Î•Î¯Î´Î¿Ï‚ Î‘Î½Î¬Î»Ï…ÏƒÎ·Ï‚",
        ["Î•Ï€Î¹Ï†Î±Î½ÎµÎ¹Î±ÎºÎ® Î‘Ï€Î¿Ï„ÏÏ€Ï‰ÏƒÎ·", "Î ÏÎ¿Ï†Î¯Î» Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ ÎºÎ±Î¹ ÏƒÏ„Î¬Î¸Î¼Î·Ï‚", "EÏÎ³Î±Î»ÎµÎ¯Î± Î ÏÏŒÎ²Î»ÎµÏˆÎ·Ï‚ ÎºÎ±Î¹ Î­Î³ÎºÎ±Î¹ÏÎ·Ï‚ ÎµÎ½Î·Î¼Î­ÏÏ‰ÏƒÎ·Ï‚", "Î ÏÎ¿Î·Î³Î¼Î­Î½Î· Î‘Î½Î¬Î»Ï…ÏƒÎ· Î ÏÎ¿Ï„ÏÏ€Ï‰Î½ (AI)"],
        key=SESSION_KEY_ANALYSIS
    )
    st.sidebar.markdown(
        f"""<div style="padding: 0.7rem; background:#2c2f36; border-radius:8px; margin-top:1.2rem;">
        <strong>ğŸŒŠ Î¥Î´Î¬Ï„Î¹Î½Î¿ ÏƒÏÎ¼Î±:</strong> {waterbody or "<i>-</i>"}<br>
        <strong>ğŸ”¬ Î”ÎµÎ¯ÎºÏ„Î·Ï‚:</strong> {index_name or "<i>-</i>"}<br>
        <strong>ğŸ“Š Î‘Î½Î¬Î»Ï…ÏƒÎ·:</strong> {analysis_type or "<i>-</i>"}
        </div>""",
        unsafe_allow_html=True
    )
    st.sidebar.markdown("---")

@st.cache_data
def parse_sampling_kml(kml_source) -> list:
    try:
        if hasattr(kml_source, "seek"): kml_source.seek(0)
        tree = ET.parse(kml_source) if hasattr(kml_source, "read") else ET.parse(str(kml_source))
        root = tree.getroot()
        ns = {'kml': 'http://www.opengis.net/kml/2.2'}
        points = []
        for i_ls, ls in enumerate(root.findall('.//kml:LineString', ns)):
            coords_text_elem = ls.find('kml:coordinates', ns)
            if coords_text_elem is not None and coords_text_elem.text:
                coords = coords_text_elem.text.strip().split()
                for i_coord, coord_str in enumerate(coords):
                    try:
                        lon, lat, *_ = coord_str.split(',')
                        point_name = f"LS{i_ls+1}_P{i_coord+1}"
                        points.append((point_name, float(lon), float(lat)))
                    except ValueError: debug_message(f"Warning: KML: Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· ÏƒÏ…Î½Ï„ÎµÏ„Î±Î³Î¼Î­Î½Î·Ï‚ '{coord_str}'")
        if not points and kml_source: # Check if kml_source was provided but no points found
                st.warning("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÏƒÎ·Î¼ÎµÎ¯Î± LineString ÏƒÏ„Î¿ KML.")
        return points
    except FileNotFoundError:
        debug_message(f"Î ÏÎ¿ÎµÎ¹Î´Î¿Ï€Î¿Î¯Î·ÏƒÎ·: Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ KML '{kml_source}' Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ.")
        return []
    except Exception as e:
        st.error(f"Î£Ï†Î¬Î»Î¼Î± Î±Î½Î¬Î»Ï…ÏƒÎ·Ï‚ KML '{kml_source}': {e}")
        return []

def analyze_sampling_generic(sampling_points, first_image_data, first_transform,
                                images_folder, lake_height_path, selected_points_names,
                                lower_thresh=0, upper_thresh=255, date_min=None, date_max=None):
    results_colors = {name: [] for name, _, _ in sampling_points}
    results_mg = {name: [] for name, _, _ in sampling_points}

    if not os.path.isdir(images_folder):
        st.error(f"ÎŸ Ï†Î¬ÎºÎµÎ»Î¿Ï‚ ÎµÎ¹ÎºÏŒÎ½Ï‰Î½ '{images_folder}' Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ."); return go.Figure(), go.Figure(), go.Figure(), go.Figure(), {}, {}, pd.DataFrame()

    for filename in sorted(os.listdir(images_folder)):
        if not filename.lower().endswith(('.tif', '.tiff')): continue
        m = re.search(r'(\d{4})[_-]?(\d{2})[_-]?(\d{2})', filename)
        if not m: continue
        try: date_obj = datetime(int(m.group(1)), int(m.group(2)), int(m.group(3)))
        except ValueError: debug_message(f"Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· {filename}: Î¼Î· Î­Î³ÎºÏ…ÏÎ· Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±."); continue

        if (date_min and date_obj.date() < date_min) or \
           (date_max and date_obj.date() > date_max): continue

        try:
            with rasterio.open(os.path.join(images_folder, filename)) as src:
                if src.count < 3: debug_message(f"Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· {filename}: <3 ÎºÎ±Î½Î¬Î»Î¹Î±."); continue
                for name, lon, lat in sampling_points:
                    if name not in selected_points_names: continue
                    col, row = map(int, (~src.transform) * (lon, lat))
                    if not (0 <= col < src.width and 0 <= row < src.height): continue
                    win = rasterio.windows.Window(col,row,1,1)
                    try:
                        r,g,b = src.read(1,window=win)[0,0], src.read(2,window=win)[0,0], src.read(3,window=win)[0,0]
                        mg_val = (g / 255.0) * 2.0 # Placeholder conversion
                        results_mg[name].append((date_obj, mg_val))
                        results_colors[name].append((date_obj, (r/255., g/255., b/255.)))
                    except IndexError: debug_message(f"Î£Ï†Î¬Î»Î¼Î± Index pixel Î³Î¹Î± {name} ÏƒÏ„Î¿ {filename}.")
        except Exception as e: st.warning(f"Î£Ï†Î¬Î»Î¼Î± ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ {filename}: {e}")

    # Ensure first_image_data is suitable for px.imshow (e.g., 3 bands, normalized)
    if first_image_data is None or first_image_data.ndim != 3 or first_image_data.shape[0] < 3:
        st.error("ÎœÎ· Î­Î³ÎºÏ…ÏÎ± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Ï€ÏÏÏ„Î·Ï‚ ÎµÎ¹ÎºÏŒÎ½Î±Ï‚ Î³Î¹Î± ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ·.")
        return go.Figure(), go.Figure(), go.Figure(), go.Figure(), {}, {}, pd.DataFrame()

    rgb_disp = first_image_data[:3, :, :].transpose((1,2,0)) # Use first 3 bands
    if rgb_disp.max() > 1.0: # Normalize if not already in 0-1 range
        rgb_disp = rgb_disp / 255.0
    rgb_disp = np.clip(rgb_disp, 0, 1)


    fig_geo = px.imshow(rgb_disp, title='Î•Î¹ÎºÏŒÎ½Î± Î‘Î½Î±Ï†Î¿ÏÎ¬Ï‚ & Î£Î·Î¼ÎµÎ¯Î±'); fig_geo.update_layout(height=600, uirevision='geo')
    if first_transform: # Ensure transform is available
        for n,lon,lat in sampling_points:
            if n in selected_points_names:
                col,row = map(int, (~first_transform) * (lon,lat))
                fig_geo.add_trace(go.Scatter(x=[col],y=[row],mode='markers+text',marker=dict(color='red',size=10,symbol='x'),name=n,text=n,textposition="top right"))
    fig_geo.update_xaxes(visible=False); fig_geo.update_yaxes(visible=False,scaleanchor="x",scaleratio=1)

    df_h = pd.DataFrame(columns=['Date','Height'])
    if os.path.exists(str(lake_height_path)):
        try:
            df_h_temp = pd.read_excel(lake_height_path)
            if not df_h_temp.empty and len(df_h_temp.columns) >=2:
                df_h['Date']=pd.to_datetime(df_h_temp.iloc[:,0],errors='coerce'); df_h['Height']=pd.to_numeric(df_h_temp.iloc[:,1],errors='coerce')
                df_h.dropna(inplace=True); df_h.sort_values('Date',inplace=True)
        except Exception: df_h = pd.DataFrame(columns=['Date','Height'])

    fig_colors = make_subplots(specs=[[{"secondary_y":True}]]); pt_y_map={n:i for i,n in enumerate(selected_points_names)}
    for n_iter in selected_points_names:
        if n_iter in results_colors and results_colors[n_iter]:
            dts,cols=zip(*sorted(results_colors[n_iter],key=lambda x:x[0])) if results_colors[n_iter] else ([],[])
            c_rgb=[f"rgb({int(c[0]*255)},{int(c[1]*255)},{int(c[2]*255)})" for c in cols]
            fig_colors.add_trace(go.Scatter(x=list(dts),y=[pt_y_map.get(n_iter,-1)]*len(dts),mode='markers',marker=dict(color=c_rgb,size=10),name=n_iter),secondary_y=False)
    if not df_h.empty: fig_colors.add_trace(go.Scatter(x=df_h['Date'],y=df_h['Height'],name='Î£Ï„Î¬Î¸Î¼Î·',mode='lines',line=dict(color='blue')),secondary_y=True)
    fig_colors.update_layout(title='Î§ÏÏÎ¼Î±Ï„Î± Pixel & Î£Ï„Î¬Î¸Î¼Î·',yaxis=dict(tickmode='array',tickvals=list(pt_y_map.values()),ticktext=list(pt_y_map.keys())),yaxis2=dict(title='Î£Ï„Î¬Î¸Î¼Î· (m)'), uirevision='colors')

    all_mg_by_d={};
    for p_name in selected_points_names:
        if p_name in results_mg:
            for d,v in results_mg[p_name]: all_mg_by_d.setdefault(d,[]).append(v)
    s_dts_mg=sorted(all_mg_by_d.keys()); mean_mg=[np.mean(all_mg_by_d[d]) for d in s_dts_mg if all_mg_by_d[d]]
    fig_mg=go.Figure();
    if s_dts_mg and mean_mg: fig_mg.add_trace(go.Scatter(x=s_dts_mg,y=mean_mg,mode='lines+markers',marker=dict(color=mean_mg,colorscale='Viridis',colorbar=dict(title='mg/mÂ³'),size=8)))
    fig_mg.update_layout(title='ÎœÎ­ÏƒÎ¿ mg/mÂ³', uirevision='mg')

    fig_dual=make_subplots(specs=[[{"secondary_y":True}]])
    if not df_h.empty: fig_dual.add_trace(go.Scatter(x=df_h['Date'],y=df_h['Height'],name='Î£Ï„Î¬Î¸Î¼Î· Î›Î¯Î¼Î½Î·Ï‚',mode='lines'),secondary_y=False)
    if s_dts_mg and mean_mg: fig_dual.add_trace(go.Scatter(x=s_dts_mg,y=mean_mg,name='ÎœÎ­ÏƒÎ¿ mg/mÂ³',mode='lines+markers', marker=dict(color=mean_mg, colorscale='Viridis', showscale=False)),secondary_y=True)
    fig_dual.update_layout(title='Î£Ï„Î¬Î¸Î¼Î· & ÎœÎ­ÏƒÎ¿ mg/mÂ³', uirevision='dual',
                            yaxis=dict(title=dict(text="Î£Ï„Î¬Î¸Î¼Î· (m)",font=dict(color="deepskyblue")), tickfont=dict(color="deepskyblue"), side='left'),
                            yaxis2=dict(title=dict(text="ÎœÎ­ÏƒÎ¿ mg/mÂ³",font=dict(color="lightgreen")), tickfont=dict(color="lightgreen"), overlaying='y', side='right'))
    return fig_geo,fig_dual,fig_colors,fig_mg,results_colors,results_mg,df_h

@st.cache_resource
def create_chl_legend_figure(orientation="horizontal", theme_bg_color=None, theme_text_color=None):
    levels = [0, 6, 12, 20, 30, 50]
    colors = ["#496FF2", "#82D35F", "#FEFD05", "#FD0004", "#8E2026", "#D97CF5"]
    cmap = mcolors.LinearSegmentedColormap.from_list("ChlLegend", list(zip(np.linspace(0, 1, len(levels)), colors)))
    norm = mcolors.Normalize(vmin=levels[0], vmax=levels[-1])

    if orientation == "horizontal":
        fig, ax = plt.subplots(figsize=(7, 1.2))
        fig.subplots_adjust(bottom=0.45, top=0.9, left=0.05, right=0.95)
        cbar_orientation = "horizontal"
    else:
        fig, ax = plt.subplots(figsize=(1.8, 6))
        fig.subplots_adjust(left=0.3, right=0.7, top=0.95, bottom=0.05)
        cbar_orientation = "vertical"

    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
    sm.set_array([])
    cbar = fig.colorbar(sm, cax=ax, orientation=cbar_orientation, ticks=levels, aspect=30 if orientation=="horizontal" else 20, shrink=0.95)

    label_text = "Î£Ï…Î³ÎºÎ­Î½Ï„ÏÏ‰ÏƒÎ· Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·Ï‚-Î± (mg/mÂ³)"
    tick_labels = [str(l) for l in levels]

    if orientation == "horizontal":
        ax.set_xlabel(label_text, fontsize=10)
        ax.set_xticklabels(tick_labels, fontsize=9)
    else:
        ax.set_ylabel(label_text, fontsize=10)
        ax.set_yticklabels(tick_labels, fontsize=9)

    # Apply theme colors if provided
    if theme_bg_color:
        fig.patch.set_facecolor(theme_bg_color)
        ax.set_facecolor(theme_bg_color)
    if theme_text_color:
        ax.xaxis.label.set_color(theme_text_color)
        ax.yaxis.label.set_color(theme_text_color)
        ax.tick_params(axis='x', colors=theme_text_color)
        ax.tick_params(axis='y', colors=theme_text_color)
        cbar.ax.xaxis.label.set_color(theme_text_color) # Colorbar label for x-axis
        cbar.ax.yaxis.label.set_color(theme_text_color) # Colorbar label for y-axis
        cbar.ax.tick_params(axis='x', colors=theme_text_color) # Colorbar tick labels for x-axis
        cbar.ax.tick_params(axis='y', colors=theme_text_color) # Colorbar tick labels for y-axis


    plt.tight_layout(pad=0.5)
    return fig

@st.cache_data
def get_data_folder(waterbody: str, index_name: str) -> str | None:
    waterbody_folder_name = WATERBODY_FOLDERS.get(waterbody)
    if not waterbody_folder_name:
        st.error(f"Î”ÎµÎ½ Î­Ï‡ÎµÎ¹ Î¿ÏÎ¹ÏƒÏ„ÎµÎ¯ Î±Î½Ï„Î¹ÏƒÏ„Î¿Î¯Ï‡Î¹ÏƒÎ· Ï†Î±ÎºÎ­Î»Î¿Ï… Î³Î¹Î± Ï„Î¿ Ï…Î´Î¬Ï„Î¹Î½Î¿ ÏƒÏÎ¼Î±: '{waterbody}'.")
        return None

    index_specific_folder = ""
    if index_name == "Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ":
        index_specific_folder = "Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ"
    elif index_name == "Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·":
        index_specific_folder = "Chlorophyll"
    elif index_name == "Î˜Î¿Î»ÏŒÏ„Î·Ï„Î±":
        index_specific_folder = "Î˜Î¿Î»ÏŒÏ„Î·Ï„Î±"
    else:
        index_specific_folder = index_name # Fallback

    data_folder = os.path.join(APP_BASE_DIR, waterbody_folder_name, index_specific_folder)
    debug_message(f"DEBUG: Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· Ï†Î±ÎºÎ­Î»Î¿Ï… Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½: {data_folder}")

    if not os.path.exists(data_folder) or not os.path.isdir(data_folder):
        return None
    return data_folder

@st.cache_data
def extract_date_from_filename(filename: str) -> tuple[int | None, datetime | None]:
    basename = os.path.basename(filename)
    match = re.search(r'(\d{4})[_-]?(\d{2})[_-]?(\d{2})', basename)

    if match:
        year, month, day = map(int, match.groups())
        try:
            date_obj = datetime(year, month, day)
            day_of_year = date_obj.timetuple().tm_yday
            return day_of_year, date_obj
        except ValueError as e:
            debug_message(f"DEBUG: Î£Ï†Î¬Î»Î¼Î± Î¼ÎµÏ„Î±Ï„ÏÎ¿Ï€Î®Ï‚ Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±Ï‚ Î±Ï€ÏŒ '{basename}': {e}")
            return None, None
    return None, None

@st.cache_data
def load_lake_shape_from_xml(xml_file_path: str, bounds: tuple = None,
                                xml_width: float = 518.0, xml_height: float = 505.0):
    debug_message(f"DEBUG: Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Ï€ÎµÏÎ¹Î³ÏÎ¬Î¼Î¼Î±Ï„Î¿Ï‚ Î±Ï€ÏŒ: {xml_file_path}")
    try:
        tree = ET.parse(xml_file_path)
        root = tree.getroot()
        points_xml = []
        for point_elem in root.findall("point"):
            x_str, y_str = point_elem.get("x"), point_elem.get("y")
            if x_str and y_str: points_xml.append([float(x_str), float(y_str)])

        if not points_xml:
            st.warning(f"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÏƒÎ·Î¼ÎµÎ¯Î± ÏƒÏ„Î¿ XML: {os.path.basename(xml_file_path)}"); return None

        points_to_return = points_xml
        if bounds:
            minx, miny, maxx, maxy = bounds
            points_to_return = [[minx + (x/xml_width)*(maxx-minx), maxy - (y/xml_height)*(maxy-miny)] for x,y in points_xml]

        if points_to_return and (points_to_return[0] != points_to_return[-1]):
            points_to_return.append(points_to_return[0]) # Close the polygon

        debug_message(f"DEBUG: Î¦Î¿ÏÏ„ÏÎ¸Î·ÎºÎ±Î½ {len(points_to_return)} ÏƒÎ·Î¼ÎµÎ¯Î± Ï€ÎµÏÎ¹Î³ÏÎ¬Î¼Î¼Î±Ï„Î¿Ï‚.")
        return {"type": "Polygon", "coordinates": [points_to_return]}
    except FileNotFoundError:
        st.error(f"Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ XML Ï€ÎµÏÎ¹Î³ÏÎ¬Î¼Î¼Î±Ï„Î¿Ï‚ Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ: {xml_file_path}"); return None
    except Exception as e:
        st.error(f"Î£Ï†Î¬Î»Î¼Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ Ï€ÎµÏÎ¹Î³ÏÎ¬Î¼Î¼Î±Ï„Î¿Ï‚ Î±Ï€ÏŒ {os.path.basename(xml_file_path)}: {e}"); return None

@st.cache_data
def read_image(file_path: str, lake_shape: dict = None):
    debug_message(f"DEBUG: Î‘Î½Î¬Î³Î½Ï‰ÏƒÎ· ÎµÎ¹ÎºÏŒÎ½Î±Ï‚: {file_path}")
    try:
        with rasterio.open(file_path) as src:
            img = src.read(1).astype(np.float32)
            profile = src.profile.copy(); profile.update(dtype="float32")

            if src.nodata is not None: img = np.where(img == src.nodata, np.nan, img)
            img = np.where(img == 0, np.nan, img) # Treat 0 as NaN if appropriate

            if lake_shape:
                from rasterio.features import geometry_mask
                poly_mask = geometry_mask([lake_shape], transform=src.transform, invert=True, out_shape=img.shape) # Invert=True to keep data INSIDE
                img = np.where(poly_mask, img, np.nan)
            return img, profile
    except Exception as e:
        st.warning(f"Î ÏÎ¿ÎµÎ¹Î´Î¿Ï€Î¿Î¯Î·ÏƒÎ·: Î£Ï†Î¬Î»Î¼Î± Î±Î½Î¬Î³Î½Ï‰ÏƒÎ·Ï‚ ÎµÎ¹ÎºÏŒÎ½Î±Ï‚ {os.path.basename(file_path)}: {e}. Î Î±ÏÎ±Î»ÎµÎ¯Ï€ÎµÏ„Î±Î¹."); return None, None

@st.cache_data
def load_data_for_lake_processing(input_folder: str, shapefile_name="shapefile.xml"):
    debug_message(f"DEBUG: load_data_for_lake_processing Î³Î¹Î±: {input_folder}")
    if not os.path.exists(input_folder):
        st.error(f"ÎŸ Ï†Î¬ÎºÎµÎ»Î¿Ï‚ ÎµÎ¹ÏƒÏŒÎ´Î¿Ï… Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹: {input_folder}"); return None, None, None, None

    shape_file_path = next((sp for sp in [os.path.join(input_folder, shapefile_name), os.path.join(input_folder, "shapefile.txt")] if os.path.exists(sp)), None)
    if shape_file_path: debug_message(f"Î’ÏÎ­Î¸Î·ÎºÎµ Î±ÏÏ‡ÎµÎ¯Î¿ Ï€ÎµÏÎ¹Î³ÏÎ¬Î¼Î¼Î±Ï„Î¿Ï‚: {shape_file_path}")

    tif_files = sorted([fp for fp in glob.glob(os.path.join(input_folder, "*.tif")) if os.path.basename(fp).lower() != "mask.tif"])
    if not tif_files:
        st.warning(f"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ GeoTIFF Î±ÏÏ‡ÎµÎ¯Î± ÏƒÏ„Î¿Î½ Ï†Î¬ÎºÎµÎ»Î¿: {input_folder}"); return None, None, None, None

    first_profile, lake_geom = None, None
    try:
        with rasterio.open(tif_files[0]) as src_first:
            first_profile = src_first.profile.copy()
            if shape_file_path: lake_geom = load_lake_shape_from_xml(shape_file_path, bounds=src_first.bounds)
    except Exception as e:
        st.error(f"Î£Ï†Î¬Î»Î¼Î± Ï€ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î±ÏƒÎ¯Î±Ï‚ Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ (Ï€ÏÏÏ„Î· ÎµÎ¹ÎºÏŒÎ½Î±/shapefile): {e}"); return None, None, None, None

    images, days, dates_list = [], [], []
    for fp_iter in tif_files:
        day_yr, date_obj = extract_date_from_filename(fp_iter)
        if day_yr is None: continue
        img_data, _ = read_image(fp_iter, lake_shape=lake_geom)
        if img_data is not None: images.append(img_data); days.append(day_yr); dates_list.append(date_obj)

    if not images:
        st.warning(f"Î”ÎµÎ½ Ï†Î¿ÏÏ„ÏÎ¸Î·ÎºÎ±Î½ Î­Î³ÎºÏ…ÏÎµÏ‚ ÎµÎ¹ÎºÏŒÎ½ÎµÏ‚ Î±Ï€ÏŒ Ï„Î¿Î½ Ï†Î¬ÎºÎµÎ»Î¿: {input_folder}."); return None, None, None, None
    return np.stack(images, axis=0), np.array(days), dates_list, first_profile


def run_lake_processing_app(waterbody: str, index_name: str):
    with st.container():
        st.markdown('<div class="card">', unsafe_allow_html=True) # Changed from custom-card to card
        st.header(f"Î•Ï€Î¹Ï†Î±Î½ÎµÎ¹Î±ÎºÎ® Î‘Ï€Î¿Ï„ÏÏ€Ï‰ÏƒÎ·: {waterbody} - {index_name}")

        data_folder = get_data_folder(waterbody, index_name)
        if not data_folder:
            expected_folder_name = ""
            if index_name == "Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ": expected_folder_name = "Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ"
            elif index_name == "Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·": expected_folder_name = "Chlorophyll"
            elif index_name == "Î˜Î¿Î»ÏŒÏ„Î·Ï„Î±": expected_folder_name = "Î˜Î¿Î»ÏŒÏ„Î·Ï„Î±"
            else: expected_folder_name = index_name
            
            waterbody_actual_folder = WATERBODY_FOLDERS.get(waterbody, 'ÎœÎ—_ÎšÎ‘Î˜ÎŸÎ¡Î™Î£ÎœÎ•ÎÎŸ_Î¦Î‘ÎšÎ•Î›ÎŸ')
            st.error(f"ÎŸ Ï†Î¬ÎºÎµÎ»Î¿Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î³Î¹Î± '{waterbody} - {index_name}' Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ. "
                        f"Î•Î»Î­Î³Î¾Ï„Îµ ÏŒÏ„Î¹ Î¿ Ï†Î¬ÎºÎµÎ»Î¿Ï‚ '{expected_folder_name}' "
                        f"Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î¼Î­ÏƒÎ± ÏƒÏ„Î¿Î½ ÎºÎ±Ï„Î¬Î»Î¿Î³Î¿ '{os.path.join(APP_BASE_DIR, waterbody_actual_folder)}'.")
            st.markdown('</div>', unsafe_allow_html=True); return

        input_folder_geotiffs = os.path.join(data_folder, "GeoTIFFs")
        
        with st.spinner(f"Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î³Î¹Î± {waterbody} - {index_name}..."):
            STACK, DAYS, DATES, _ = load_data_for_lake_processing(input_folder_geotiffs)

        if STACK is None or not DATES:
            st.markdown('</div>', unsafe_allow_html=True); return

        st.sidebar.subheader(f"Î¦Î¯Î»Ï„ÏÎ± Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ ({index_name})") # Simplified title
        min_avail_date = min(DATES).date() if DATES else date.today()
        max_avail_date = max(DATES).date() if DATES else date.today()
        unique_years_avail = sorted(list(set(d.year for d in DATES if d))) if DATES else []

        clean_index_name_for_key = re.sub(r'[^a-zA-Z0-9_]', '', index_name) 
        key_suffix = f"_lp_{waterbody}_{clean_index_name_for_key}"
        common_filename_prefix = f"{waterbody}_{index_name}_surface_map"

        threshold_range_val = st.sidebar.slider("Î•ÏÏÎ¿Ï‚ Ï„Î¹Î¼ÏÎ½ pixel:", 0, 255, (0, 255), 
                                                key=f"thresh{key_suffix}", 
                                                help="ÎŸÏÎ¯ÏƒÏ„Îµ Ï„Î¿ ÎºÎ±Ï„ÏÏ†Î»Î¹ ÎºÎ±Î¹ Î±Î½ÏÏ†Î»Î¹ Î³Î¹Î± Ï„Î¹Ï‚ Ï„Î¹Î¼Î­Ï‚ pixel.")
        
        col_start_lp, col_end_lp = st.sidebar.columns(2)
        refined_start_val = col_start_lp.date_input("ÎˆÎ½Î±ÏÎ¾Î· Ï€ÎµÏÎ¹ÏŒÎ´Î¿Ï…:", value=min_avail_date, 
                                                    min_value=min_avail_date, max_value=max_avail_date, 
                                                    key=f"refined_start{key_suffix}")
        refined_end_val = col_end_lp.date_input("Î›Î®Î¾Î· Ï€ÎµÏÎ¹ÏŒÎ´Î¿Ï…:", value=max_avail_date, 
                                                min_value=min_avail_date, max_value=max_avail_date, 
                                                key=f"refined_end{key_suffix}")
        
        if refined_start_val > refined_end_val:
            st.sidebar.error("Î— Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î± Î­Î½Î±ÏÎ¾Î·Ï‚ Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎµÎ¯Î½Î±Î¹ Ï€ÏÎ¹Î½ Î® Î¯Î´Î¹Î± Î¼Îµ Ï„Î·Î½ Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î± Î»Î®Î¾Î·Ï‚.")
            st.markdown('</div>', unsafe_allow_html=True); return
            
        display_option_val = st.sidebar.radio("Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· ÎœÎ­ÏƒÎ¿Ï… Î”ÎµÎ¯Î³Î¼Î±Ï„Î¿Ï‚:", 
                                            options=["Thresholded", "Original"], index=0, 
                                            key=f"display_opt{key_suffix}", horizontal=True)

        month_options_map = {i: datetime(2000, i, 1).strftime('%B') for i in range(1, 13)}
        
        default_months = st.session_state.get(f"sel_months{key_suffix}", list(month_options_map.keys()))
        selected_months_val = st.sidebar.multiselect("Î•Ï€Î¹Î»Î¿Î³Î® ÎœÎ·Î½ÏÎ½:",
                                                    options=list(month_options_map.keys()),
                                                    format_func=lambda x: month_options_map[x],
                                                    default=default_months,
                                                    key=f"sel_months{key_suffix}")
        
        default_years = st.session_state.get(f"sel_years{key_suffix}", unique_years_avail)
        selected_years_val = st.sidebar.multiselect("Î•Ï€Î¹Î»Î¿Î³Î® Î•Ï„ÏÎ½:", 
                                                    options=unique_years_avail,
                                                    default=default_years,
                                                    key=f"sel_years{key_suffix}")
        
        start_dt_conv = datetime.combine(refined_start_val, datetime.min.time())
        end_dt_conv = datetime.combine(refined_end_val, datetime.max.time())

        indices_to_keep = [
            i for i, dt_obj in enumerate(DATES)
            if (start_dt_conv <= dt_obj <= end_dt_conv and
                (not selected_months_val or dt_obj.month in selected_months_val) and
                (not selected_years_val or dt_obj.year in selected_years_val))
        ]

        if not indices_to_keep:
            st.info("Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± Ï„Î·Î½ ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î· Ï€ÎµÏÎ¯Î¿Î´Î¿/Î¼Î®Î½ÎµÏ‚/Î­Ï„Î·. Î Î±ÏÎ±ÎºÎ±Î»Ï Ï€ÏÎ¿ÏƒÎ±ÏÎ¼ÏŒÏƒÏ„Îµ Ï„Î± Ï†Î¯Î»Ï„ÏÎ±.")
            st.markdown('</div>', unsafe_allow_html=True); return

        with st.spinner("Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Ï†Î¹Î»Ï„ÏÎ±ÏÎ¹ÏƒÎ¼Î­Î½Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÎºÎ±Î¹ Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î³ÏÎ±Ï†Î·Î¼Î¬Ï„Ï‰Î½..."):
            stack_filt = STACK[indices_to_keep, :, :]
            days_filt = DAYS[indices_to_keep]
            filtered_dates_objects = [DATES[i] for i in indices_to_keep]

            lower_t, upper_t = threshold_range_val
            in_range_bool_mask = np.logical_and(stack_filt >= lower_t, stack_filt <= upper_t)
            
            st.subheader("Î‘Î½Î¬Î»Ï…ÏƒÎ· Î§Î±ÏÏ„ÏÎ½")
            expander_col1, expander_col2 = st.columns(2)

            # Î‘Ï…Ï„Î­Ï‚ Î¿Î¹ Î³ÏÎ±Î¼Î¼Î­Ï‚ Ï…Ï€Î¿Î¸Î­Ï„Î¿Ï…Î¼Îµ ÏŒÏ„Î¹ ÎµÎ¯Î½Î±Î¹ Î®Î´Î· ÏƒÏ‰ÏƒÏ„Î¬ ÏƒÏ„Î¿Î¹Ï‡Î¹ÏƒÎ¼Î­Î½ÎµÏ‚ Î¼Î­ÏƒÎ± ÏƒÏ„Î¿
        # with st.spinner("Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Ï†Î¹Î»Ï„ÏÎ±ÏÎ¹ÏƒÎ¼Î­Î½Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÎºÎ±Î¹ Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î³ÏÎ±Ï†Î·Î¼Î¬Ï„Ï‰Î½..."):

        with expander_col1:
            with st.expander("Î§Î¬ÏÏ„Î·Ï‚: Î—Î¼Î­ÏÎµÏ‚ ÎµÎ½Ï„ÏŒÏ‚ Î•ÏÏÎ¿Ï…Ï‚ Î¤Î¹Î¼ÏÎ½", expanded=True):
                days_in_range_map = np.nansum(in_range_bool_mask, axis=0)
                fig_days = px.imshow(days_in_range_map, color_continuous_scale="plasma", labels={"color": "Î—Î¼Î­ÏÎµÏ‚"})
                st.plotly_chart(fig_days, use_container_width=True, key=f"fig_days_map{key_suffix}")
                df_days_in_range = pd.DataFrame(days_in_range_map)
                add_excel_download_button(df_days_in_range, common_filename_prefix, "Days_in_Range_Map", f"excel_days_map{key_suffix}")
                st.caption("Î”ÎµÎ¯Ï‡Î½ÎµÎ¹ Ï€ÏŒÏƒÎµÏ‚ Î·Î¼Î­ÏÎµÏ‚ ÎºÎ¬Î¸Îµ pixel Î®Ï„Î±Î½ ÎµÎ½Ï„ÏŒÏ‚ Ï„Î¿Ï… ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î¿Ï… ÎµÏÏÎ¿Ï…Ï‚ Ï„Î¹Î¼ÏÎ½.")

        # ÎŸÎ¹ tick_vals_days ÎºÎ±Î¹ tick_text_days Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎµÎ¯Î½Î±Î¹ ÏƒÏ„Î¿ Î¯Î´Î¹Î¿ ÎµÏ€Î¯Ï€ÎµÎ´Î¿ Î¼Îµ Ï„Î± with expander_colX
        # Î±Î½ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ½Ï„Î±Î¹ ÎºÎ±Î¹ Î±Ï€ÏŒ Ï„Î¿ expander_col2, Î® Ï€Î¹Î¿ Î¼Î­ÏƒÎ± Î±Î½ ÎµÎ¯Î½Î±Î¹ Î¼ÏŒÎ½Î¿ Î³Î¹Î± Ï„Î¿ expander_col1
        # Î‘Ï‚ Ï…Ï€Î¿Î¸Î­ÏƒÎ¿Ï…Î¼Îµ ÏŒÏ„Î¹ ÎµÎ¯Î½Î±Î¹ Î³ÎµÎ½Î¹ÎºÎ¬ Î³Î¹Î± Ï„Î·Î½ ÎµÎ½ÏŒÏ„Î·Ï„Î± Ï‡Î±ÏÏ„ÏÎ½, Î¬ÏÎ± ÏƒÏ„Î¿ Î¯Î´Î¹Î¿ ÎµÏ€Î¯Ï€ÎµÎ´Î¿ Î¼Îµ Ï„Î± expander_colX
        # Î‘Î½ ÏŒÎ¼Ï‰Ï‚ Ï„Î¿ tick_vals_days ÎºÎ±Î¹ tick_text_days ÎµÎ¯Î½Î±Î¹ Î•ÎÎ© Î±Ï€ÏŒ Ï„Î¿ `with expander_col1:`
        # Ï„ÏŒÏ„Îµ Ï„Î¿ `with expander_col2:` Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎµÎ¯Î½Î±Î¹ ÏƒÏ„Î¿ Î¯Î´Î¹Î¿ ÎµÏ€Î¯Ï€ÎµÎ´Î¿ Î¼Îµ Ï„Î¿ `with expander_col1:`

        # Î”Î™ÎŸÎ¡Î˜Î©Î£Î—: ÎŸÎ¹ tick_vals_days ÎºÎ±Î¹ tick_text_days Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎµÎ¯Î½Î±Î¹ Î­Î¾Ï‰ Î±Ï€ÏŒ Ï„Î¿ with expander_col1
        # ÎºÎ±Î¹ ÏƒÏ„Î¿ Î¯Î´Î¹Î¿ ÎµÏ€Î¯Ï€ÎµÎ´Î¿ Î¼Îµ Î±Ï…Ï„ÏŒ, Î±Î½ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ½Ï„Î±Î¹ ÎºÎ±Î¹ Î±Ï€ÏŒ Ï„Î¿ expander_col2.
        # Î‘Î½ Î´ÎµÎ½ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ½Ï„Î±Î¹ Î±Ï€ÏŒ Ï„Î¿ expander_col2, Î¼Ï€Î¿ÏÎ¿ÏÎ½ Î½Î± Î¼ÎµÎ¯Î½Î¿Ï…Î½ Î¼Î­ÏƒÎ± Î® Î½Î± Î¼ÎµÏ„Î±ÎºÎ¹Î½Î·Î¸Î¿ÏÎ½.
        # Î“Î¹Î± Î±ÏƒÏ†Î¬Î»ÎµÎ¹Î±, Î±Ï‚ Ï„Î± Î²Î³Î¬Î»Î¿Ï…Î¼Îµ Î­Î½Î± ÎµÏ€Î¯Ï€ÎµÎ´Î¿ Î­Î¾Ï‰ Î±Ï€ÏŒ Ï„Î¿ expander_col1 Î±Î»Î»Î¬ Î¼Î­ÏƒÎ± ÏƒÏ„Î¿ spinner.

    # Î‘Ï‚ Ï…Ï€Î¿Î¸Î­ÏƒÎ¿Ï…Î¼Îµ ÏŒÏ„Î¹ Î¿Î¹ tick_vals_days ÎºÎ±Î¹ tick_text_days Î¿ÏÎ¯Î¶Î¿Î½Ï„Î±Î¹ ÎµÎ´Ï,
    # ÏƒÏ„Î¿ Î¯Î´Î¹Î¿ ÎµÏ€Î¯Ï€ÎµÎ´Î¿ Î¼Îµ Ï„Î± st.subheader ÎºÎ±Î¹ st.columns
    tick_vals_days = [1, 32, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335, 365]
    tick_text_days = ["Î™Î±Î½", "Î¦ÎµÎ²", "ÎœÎ±Ï", "Î‘Ï€Ï", "ÎœÎ±Î", "Î™Î¿Ï…Î½", "Î™Î¿Ï…Î»", "Î‘Ï…Î³", "Î£ÎµÏ€", "ÎŸÎºÏ„", "ÎÎ¿Îµ", "Î”ÎµÎº", ""]

    with expander_col2:
        with st.expander("Î§Î¬ÏÏ„Î·Ï‚: ÎœÎ­ÏƒÎ· Î—Î¼Î­ÏÎ± Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ·Ï‚ ÎµÎ½Ï„ÏŒÏ‚ Î•ÏÏÎ¿Ï…Ï‚", expanded=True):
            days_array_expanded = days_filt.reshape((-1, 1, 1))
            sum_days_in_range = np.nansum(days_array_expanded * in_range_bool_mask, axis=0)
            count_pixels_in_range = np.nansum(in_range_bool_mask, axis=0)
            mean_day_map = np.divide(sum_days_in_range, count_pixels_in_range,
                                     out=np.full(sum_days_in_range.shape, np.nan),
                                     where=(count_pixels_in_range != 0))
            fig_mean_day = px.imshow(mean_day_map, color_continuous_scale="RdBu",
                                     labels={"color": "ÎœÎ­ÏƒÎ· Î—Î¼Î­ÏÎ± (1-365)"},
                                     color_continuous_midpoint=182)
            fig_mean_day.update_layout(coloraxis_colorbar=dict(tickmode='array', tickvals=tick_vals_days, ticktext=tick_text_days))
            st.plotly_chart(fig_mean_day, use_container_width=True, key=f"fig_mean_day_map{key_suffix}")
            df_mean_day_map = pd.DataFrame(mean_day_map)
            add_excel_download_button(df_mean_day_map, common_filename_prefix, "Mean_Day_Map", f"excel_mean_day_map{key_suffix}")
            st.caption("Î”ÎµÎ¯Ï‡Î½ÎµÎ¹ Ï„Î· Î¼Î­ÏƒÎ· Î·Î¼Î­ÏÎ± Ï„Î¿Ï… Î­Ï„Î¿Ï…Ï‚ Ï€Î¿Ï… Î­Î½Î± pixel Î®Ï„Î±Î½ ÎµÎ½Ï„ÏŒÏ‚ Ï„Î¿Ï… ÎµÏÏÎ¿Ï…Ï‚ Ï„Î¹Î¼ÏÎ½.")

    st.subheader("Î‘Î½Î¬Î»Ï…ÏƒÎ· Î”ÎµÎ¯Î³Î¼Î±Ï„Î¿Ï‚ Î•Î¹ÎºÏŒÎ½Î±Ï‚") # Î£Ï„Î¿ Î¯Î´Î¹Î¿ ÎµÏ€Î¯Ï€ÎµÎ´Î¿ Î¼Îµ Ï„Î¿ Ï€ÏÎ¿Î·Î³Î¿ÏÎ¼ÎµÎ½Î¿ st.subheader
    expander_col3, expander_col4 = st.columns(2) # Î£Ï„Î¿ Î¯Î´Î¹Î¿ ÎµÏ€Î¯Ï€ÎµÎ´Î¿

    # Î•Î´Ï ÎµÎ¯Î½Î±Î¹ Ï„Î¿ Î´Î¹Î¿ÏÎ¸Ï‰Î¼Î­Î½Î¿ expander_col3
    with expander_col3: # Î ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎµÎ¯Î½Î±Î¹ ÏƒÏ„Î¿ Î¯Î´Î¹Î¿ ÎµÏ€Î¯Ï€ÎµÎ´Î¿ Î¼Îµ Ï„Î¿ 'with expander_col1:'
        with st.expander("Î§Î¬ÏÏ„Î·Ï‚: ÎœÎ­ÏƒÎ¿ Î”ÎµÎ¯Î³Î¼Î± Î•Î¹ÎºÏŒÎ½Î±Ï‚", expanded=True):
            average_sample_img_display = None  # Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·

            # Î‘Ï…Ï„ÏŒ ÎµÎ¯Î½Î±Î¹ Î¼Î­ÏƒÎ± ÏƒÏ„Î¿: with expander_col3:
            #                     with st.expander("Î§Î¬ÏÏ„Î·Ï‚: ÎœÎ­ÏƒÎ¿ Î”ÎµÎ¯Î³Î¼Î± Î•Î¹ÎºÏŒÎ½Î±Ï‚", expanded=True):
            average_sample_img_display = None  # Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· ÏƒÏ„Î·Î½ Î±ÏÏ‡Î® Ï„Î¿Ï… expander

            if display_option_val.lower() == "thresholded":
                if 'stack_filt' in locals() and stack_filt is not None:
                    filtered_stack_for_avg = np.where(in_range_bool_mask, stack_filt, np.nan)
                    
                    # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ ÎºÎ±Î¸ÏŒÎ»Î¿Ï… Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÎºÎ±Î¹ Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Ï„Î¿Ï…Î»Î¬Ï‡Î¹ÏƒÏ„Î¿Î½ Î¼Î¯Î± Î¼Î·-NaN Ï„Î¹Î¼Î®
                    if filtered_stack_for_avg.shape[0] > 0 and np.any(~np.isnan(filtered_stack_for_avg)):
                        average_sample_img_display = np.nanmean(filtered_stack_for_avg, axis=0) # Î‘Ï…Ï„Î® ÎµÎ¯Î½Î±Î¹ Î· Î³ÏÎ±Î¼Î¼Î® 747 (Î® ÎºÎ¿Î½Ï„Î¬)
                    else:
                        # Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î® ÎµÎ¯Î½Î±Î¹ ÏŒÎ»Î± NaN
                        if 'STACK' in locals() and STACK is not None and STACK.ndim == 3:
                            average_sample_img_display = np.full(STACK.shape[1:], np.nan, dtype=float)
                        # (Î¤Î¿ st.caption Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î¼Ï€ÎµÎ¹ ÎµÎ´Ï Î® Î¼ÎµÏ„Î¬ Ï„Î·Î½ ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ·)
                else: # stack_filt Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î® ÎµÎ¯Î½Î±Î¹ None
                    if 'STACK' in locals() and STACK is not None and STACK.ndim == 3:
                        average_sample_img_display = np.full(STACK.shape[1:], np.nan, dtype=float)

            else:  # Original
                if 'stack_filt' in locals() and stack_filt is not None:
                    # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ ÎºÎ±Î¸ÏŒÎ»Î¿Ï… Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÎºÎ±Î¹ Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Ï„Î¿Ï…Î»Î¬Ï‡Î¹ÏƒÏ„Î¿Î½ Î¼Î¯Î± Î¼Î·-NaN Ï„Î¹Î¼Î®
                    if stack_filt.shape[0] > 0 and np.any(~np.isnan(stack_filt)):
                        average_sample_img_display = np.nanmean(stack_filt, axis=0) # Î‘Ï…Ï„Î® ÎµÎ¯Î½Î±Î¹ Î· Î³ÏÎ±Î¼Î¼Î® 747 (Î® ÎºÎ¿Î½Ï„Î¬)
                    else:
                        # Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î® ÎµÎ¯Î½Î±Î¹ ÏŒÎ»Î± NaN
                        if 'STACK' in locals() and STACK is not None and STACK.ndim == 3:
                            average_sample_img_display = np.full(STACK.shape[1:], np.nan, dtype=float)
                else: # stack_filt Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î® ÎµÎ¯Î½Î±Î¹ None
                    if 'STACK' in locals() and STACK is not None and STACK.ndim == 3:
                        average_sample_img_display = np.full(STACK.shape[1:], np.nan, dtype=float)

            # ÎŸ Ï…Ï€ÏŒÎ»Î¿Î¹Ï€Î¿Ï‚ ÎºÏÎ´Î¹ÎºÎ±Ï‚ Î³Î¹Î± Ï„Î·Î½ ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ· (if average_sample_img_display is not None and not np.all(np.isnan(average_sample_img_display)): ...)
            # Ï€Î±ÏÎ±Î¼Î­Î½ÎµÎ¹ ÏŒÏ€Ï‰Ï‚ Ï„Î¿Î½ ÎµÎ¯Ï‡Î±Ï„Îµ Î® ÏŒÏ€Ï‰Ï‚ Ï„Î¿Î½ Î´Î¹Î¿ÏÎ¸ÏÏƒÎ±Î¼Îµ Ï€ÏÎ¿Î·Î³Î¿Ï…Î¼Î­Î½Ï‰Ï‚.
            # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ ÎºÎ±Î¹ ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ· Ï„Î¿Ï… Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î¿Ï‚
            if average_sample_img_display is not None and not np.all(np.isnan(average_sample_img_display)):
                if average_sample_img_display.size > 0:
                    try:
                        avg_min_disp = float(np.nanmin(average_sample_img_display))
                        avg_max_disp = float(np.nanmax(average_sample_img_display))

                        if np.isnan(avg_min_disp) or np.isnan(avg_max_disp):
                            st.caption("Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î­Î³ÎºÏ…ÏÎµÏ‚ Ï„Î¹Î¼Î­Ï‚ Î³Î¹Î± Ï„Î·Î½ Î¿Ï€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Ï„Î¿Ï… 'ÎœÎ­ÏƒÎ¿Ï… Î”ÎµÎ¯Î³Î¼Î±Ï„Î¿Ï‚ Î•Î¹ÎºÏŒÎ½Î±Ï‚'.")
                        else:
                            fig_sample_disp = px.imshow(average_sample_img_display, color_continuous_scale="jet",
                                                        range_color=[avg_min_disp, avg_max_disp] if avg_min_disp < avg_max_disp else None,
                                                        labels={"color": "Î¤Î¹Î¼Î® Pixel"})
                            st.plotly_chart(fig_sample_disp, use_container_width=True, key=f"fig_sample_map{key_suffix}")
                            df_avg_sample_display = pd.DataFrame(average_sample_img_display)
                            add_excel_download_button(df_avg_sample_display, common_filename_prefix, "Average_Sample_Map", f"excel_avg_sample_map{key_suffix}")
                            st.caption(f"ÎœÎ­ÏƒÎ· Ï„Î¹Î¼Î® pixel (ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ·: {display_option_val}).")
                    except Exception as e:
                        st.caption(f"Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ Ï€ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î±ÏƒÎ¯Î± Ï„Î¿Ï… Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î¿Ï‚ 'ÎœÎ­ÏƒÎ¿Ï… Î”ÎµÎ¯Î³Î¼Î±Ï„Î¿Ï‚ Î•Î¹ÎºÏŒÎ½Î±Ï‚': {e}")
                else:
                    st.caption("Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± Ï„Î¿ 'ÎœÎ­ÏƒÎ¿ Î”ÎµÎ¯Î³Î¼Î± Î•Î¹ÎºÏŒÎ½Î±Ï‚' (ÎºÎµÎ½ÏŒ Î¼Î­Î³ÎµÎ¸Î¿Ï‚ Ï€Î¯Î½Î±ÎºÎ±).")
            else:
                st.caption("Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± Ï„Î¿ 'ÎœÎ­ÏƒÎ¿ Î”ÎµÎ¯Î³Î¼Î± Î•Î¹ÎºÏŒÎ½Î±Ï‚'.")

    # ÎŸ ÎºÏÎ´Î¹ÎºÎ±Ï‚ Î³Î¹Î± Ï„Î¿ expander_col4 Î¸Î± Î±ÎºÎ¿Î»Î¿Ï…Î¸Î®ÏƒÎµÎ¹ ÎµÎ´Ï, ÏƒÏ„Î¿ Î¯Î´Î¹Î¿ ÎµÏ€Î¯Ï€ÎµÎ´Î¿ Î¼Îµ Ï„Î¿ 'with expander_col3:'
    # with expander_col4:
    #     ...

        # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ ÎºÎ±Î¹ ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ· Ï„Î¿Ï… Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î¿Ï‚
        if average_sample_img_display is not None and not np.all(np.isnan(average_sample_img_display)):
            # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ Ï„Î¿ array Î­Ï‡ÎµÎ¹ Î¼Î·-NaN Ï„Î¹Î¼Î­Ï‚ ÎºÎ±Î¹ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î±Ï€Î»Î¬ Î­Î½Î± Î¬Î´ÎµÎ¹Î¿ array Î±Ï€ÏŒ Ï„Î¿ np.array([[]])
            if average_sample_img_display.size > 0 : # Î•Î¾Î±ÏƒÏ†Î±Î»Î¯Î¶ÎµÎ¹ ÏŒÏ„Î¹ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ shape (0,) Î® Ï€Î±ÏÏŒÎ¼Î¿Î¹Î¿
                try:
                    avg_min_disp = float(np.nanmin(average_sample_img_display))
                    avg_max_disp = float(np.nanmax(average_sample_img_display))

                    # Î•Ï€Î¹Ï€Î»Î­Î¿Î½ Î­Î»ÎµÎ³Ï‡Î¿Ï‚ Î³Î¹Î± Ï„Î·Î½ Ï€ÎµÏÎ¯Ï€Ï„Ï‰ÏƒÎ· Ï€Î¿Ï… avg_min_disp == avg_max_disp (Ï€.Ï‡. ÏƒÏ„Î±Î¸ÎµÏÎ® ÎµÎ¹ÎºÏŒÎ½Î±)
                    # Î® Î±Î½ ÎºÎ¬Ï€Î¿Î¹Î¿ Î±Ï€ÏŒ Î±Ï…Ï„Î¬ ÎµÎ¯Î½Î±Î¹ NaN (Î±Î½ ÎºÎ±Î¹ Ï„Î¿ np.all(np.isnan) Î¸Î± Î­Ï€ÏÎµÏ€Îµ Î½Î± Ï„Î¿ Î­Ï‡ÎµÎ¹ Ï€Î¹Î¬ÏƒÎµÎ¹)
                    if np.isnan(avg_min_disp) or np.isnan(avg_max_disp):
                         st.caption("Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î­Î³ÎºÏ…ÏÎµÏ‚ Ï„Î¹Î¼Î­Ï‚ Î³Î¹Î± Ï„Î·Î½ Î¿Ï€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Ï„Î¿Ï… 'ÎœÎ­ÏƒÎ¿Ï… Î”ÎµÎ¯Î³Î¼Î±Ï„Î¿Ï‚ Î•Î¹ÎºÏŒÎ½Î±Ï‚'.")
                    else:
                        fig_sample_disp = px.imshow(average_sample_img_display, color_continuous_scale="jet",
                                                    range_color=[avg_min_disp, avg_max_disp] if avg_min_disp < avg_max_disp else None,
                                                    labels={"color": "Î¤Î¹Î¼Î® Pixel"})
                        st.plotly_chart(fig_sample_disp, use_container_width=True, key=f"fig_sample_map{key_suffix}")
                        df_avg_sample_display = pd.DataFrame(average_sample_img_display)
                        add_excel_download_button(df_avg_sample_display, common_filename_prefix, "Average_Sample_Map", f"excel_avg_sample_map{key_suffix}")
                        st.caption(f"ÎœÎ­ÏƒÎ· Ï„Î¹Î¼Î® pixel (ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ·: {display_option_val}).")
                except Exception as e: # Î Î¹Î¬Î½ÎµÎ¹ Ï€Î¹Î¸Î±Î½Î¬ ÏƒÏ†Î¬Î»Î¼Î±Ï„Î± Î±Ï€ÏŒ nanmin/nanmax Î±Î½ Ï„Î¿ array ÎµÎ¯Î½Î±Î¹ Ï€ÏÎ¿Î²Î»Î·Î¼Î±Ï„Î¹ÎºÏŒ
                    st.caption(f"Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ Ï€ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î±ÏƒÎ¯Î± Ï„Î¿Ï… Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î¿Ï‚ 'ÎœÎ­ÏƒÎ¿Ï… Î”ÎµÎ¯Î³Î¼Î±Ï„Î¿Ï‚ Î•Î¹ÎºÏŒÎ½Î±Ï‚': {e}")
            else: # average_sample_img_display.size == 0
                 st.caption("Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± Ï„Î¿ 'ÎœÎ­ÏƒÎ¿ Î”ÎµÎ¯Î³Î¼Î± Î•Î¹ÎºÏŒÎ½Î±Ï‚' (ÎºÎµÎ½ÏŒ Î¼Î­Î³ÎµÎ¸Î¿Ï‚ Ï€Î¯Î½Î±ÎºÎ±).")
        else: # average_sample_img_display is None or all NaN
            st.caption("Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± Ï„Î¿ 'ÎœÎ­ÏƒÎ¿ Î”ÎµÎ¯Î³Î¼Î± Î•Î¹ÎºÏŒÎ½Î±Ï‚'.")            
            with expander_col4:
                with st.expander("Î§Î¬ÏÏ„Î·Ï‚: Î§ÏÏŒÎ½Î¿Ï‚ ÎœÎ­Î³Î¹ÏƒÏ„Î·Ï‚ Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ·Ï‚ ÎµÎ½Ï„ÏŒÏ‚ Î•ÏÏÎ¿Ï…Ï‚", expanded=True):
                    stack_for_time_max = np.where(in_range_bool_mask, stack_filt, np.nan) 
                    time_max_map = np.full(stack_for_time_max.shape[1:], np.nan, dtype=float)
                    valid_pixels_mask = ~np.all(np.isnan(stack_for_time_max), axis=0)
                    
                    if np.any(valid_pixels_mask) and filtered_dates_objects: 
                        max_indices_flat = np.nanargmax(stack_for_time_max[:, valid_pixels_mask], axis=0)
                        days_for_time_max = np.array([d.timetuple().tm_yday for d in filtered_dates_objects])
                        if len(days_for_time_max) > 0: 
                            valid_max_indices = np.clip(max_indices_flat, 0, len(days_for_time_max) - 1)
                            time_max_map[valid_pixels_mask] = days_for_time_max[valid_max_indices]

                    fig_time_max = px.imshow(time_max_map, color_continuous_scale="RdBu", 
                                            labels={"color": "Î—Î¼Î­ÏÎ± ÎœÎ­Î³Î¹ÏƒÏ„Î·Ï‚ (1-365)"},
                                            color_continuous_midpoint=182,
                                            range_color=[1,365])
                    fig_time_max.update_layout(coloraxis_colorbar=dict(tickmode='array', tickvals=tick_vals_days, ticktext=tick_text_days))
                    st.plotly_chart(fig_time_max, use_container_width=True, key=f"fig_time_max_map{key_suffix}")
                    df_time_max_map = pd.DataFrame(time_max_map)
                    add_excel_download_button(df_time_max_map, common_filename_prefix, "Time_Max_Value_Map", f"excel_time_max_map{key_suffix}")
                    st.caption("Î”ÎµÎ¯Ï‡Î½ÎµÎ¹ Ï„Î·Î½ Î·Î¼Î­ÏÎ± Ï„Î¿Ï… Î­Ï„Î¿Ï…Ï‚ Ï€Î¿Ï… ÎºÎ¬Î¸Îµ pixel ÎµÎ¯Ï‡Îµ Ï„Î· Î¼Î­Î³Î¹ÏƒÏ„Î· Ï„Î¹Î¼Î® (ÎµÎ½Ï„ÏŒÏ‚ Ï„Î¿Ï… ÎµÏÏÎ¿Ï…Ï‚).")

            st.subheader("Î ÏÏŒÏƒÎ¸ÎµÏ„Î· Î‘Î½Î¬Î»Ï…ÏƒÎ· ÎšÎ±Ï„Î±Î½Î¿Î¼Î®Ï‚ Î—Î¼ÎµÏÏÎ½ ÎµÎ½Ï„ÏŒÏ‚ Î•ÏÏÎ¿Ï…Ï‚")
            stack_full_in_range = (STACK >= lower_t) & (STACK <= upper_t)
            num_cols_display = 3
            
            with st.expander("ÎœÎ·Î½Î¹Î±Î¯Î± ÎšÎ±Ï„Î±Î½Î¿Î¼Î® Î—Î¼ÎµÏÏÎ½ ÎµÎ½Ï„ÏŒÏ‚ Î•ÏÏÎ¿Ï…Ï‚", expanded=False):
                st.caption("Î•Î¼Ï†Î±Î½Î¯Î¶Î¿Î½Ï„Î±Î¹ Î¼ÏŒÎ½Î¿ Î¿Î¹ Î¼Î®Î½ÎµÏ‚ Ï€Î¿Ï… Î­Ï‡Î¿Ï…Î½ ÎµÏ€Î¹Î»ÎµÎ³ÎµÎ¯ Ï€Î±ÏÎ±Ï€Î¬Î½Ï‰.")
                months_to_show = [m for m in range(1, 13) if m in selected_months_val]
                if not months_to_show:
                    st.info("Î”ÎµÎ½ Î­Ï‡Î¿Ï…Î½ ÎµÏ€Î¹Î»ÎµÎ³ÎµÎ¯ Î¼Î®Î½ÎµÏ‚ Î³Î¹Î± Ï„Î·Î½ Î¼Î·Î½Î¹Î±Î¯Î± Î±Î½Î¬Î»Ï…ÏƒÎ·.")
                else:
                    cols_monthly = st.columns(num_cols_display)
                    col_idx_monthly = 0
                    for month_num in months_to_show:
                        indices_for_month_all_years = [
                            i for i, dt_obj in enumerate(DATES)
                            if dt_obj.month == month_num and (not selected_years_val or dt_obj.year in selected_years_val)
                        ]
                        if indices_for_month_all_years:
                            monthly_sum_in_range = np.sum(stack_full_in_range[indices_for_month_all_years, :, :], axis=0)
                            month_name_disp = month_options_map[month_num]
                            fig_month_disp = px.imshow(monthly_sum_in_range, color_continuous_scale="plasma", title=month_name_disp, labels={"color": "Î—Î¼Î­ÏÎµÏ‚"})
                            fig_month_disp.update_layout(margin=dict(l=0,r=0,t=30,b=0), height=350)
                            fig_month_disp.update_coloraxes(showscale=False)
                            cols_monthly[col_idx_monthly].plotly_chart(fig_month_disp, use_container_width=True, key=f"fig_month_{month_num}{key_suffix}")
                            df_monthly_sum = pd.DataFrame(monthly_sum_in_range)
                            add_excel_download_button(df_monthly_sum, common_filename_prefix, f"Monthly_Dist_{month_name_disp}", f"excel_month_{month_num}{key_suffix}")
                            col_idx_monthly = (col_idx_monthly + 1) % num_cols_display
            
            with st.expander("Î•Ï„Î®ÏƒÎ¹Î± ÎšÎ±Ï„Î±Î½Î¿Î¼Î® Î—Î¼ÎµÏÏÎ½ ÎµÎ½Ï„ÏŒÏ‚ Î•ÏÏÎ¿Ï…Ï‚", expanded=False):
                st.caption("Î•Î¼Ï†Î±Î½Î¯Î¶Î¿Î½Ï„Î±Î¹ Î¼ÏŒÎ½Î¿ Ï„Î± Î­Ï„Î· Ï€Î¿Ï… Î­Ï‡Î¿Ï…Î½ ÎµÏ€Î¹Î»ÎµÎ³ÎµÎ¯ Ï€Î±ÏÎ±Ï€Î¬Î½Ï‰.")
                years_to_show = [y for y in unique_years_avail if y in selected_years_val]
                if not years_to_show:
                    st.info("Î”ÎµÎ½ Î­Ï‡Î¿Ï…Î½ ÎµÏ€Î¹Î»ÎµÎ³ÎµÎ¯ Î­Ï„Î· Î³Î¹Î± Ï„Î·Î½ ÎµÏ„Î®ÏƒÎ¹Î± Î±Î½Î¬Î»Ï…ÏƒÎ·.")
                else:
                    cols_yearly = st.columns(num_cols_display)
                    col_idx_yearly = 0
                    for year_val in years_to_show:
                        indices_for_year_selected_months = [
                            i for i, dt_obj in enumerate(DATES)
                            if dt_obj.year == year_val and (not selected_months_val or dt_obj.month in selected_months_val)
                        ]
                        if indices_for_year_selected_months:
                            yearly_sum_in_range = np.sum(stack_full_in_range[indices_for_year_selected_months, :, :], axis=0)
                            fig_year_disp = px.imshow(yearly_sum_in_range, color_continuous_scale="plasma", title=f"ÎˆÏ„Î¿Ï‚: {year_val}", labels={"color": "Î—Î¼Î­ÏÎµÏ‚"})
                            fig_year_disp.update_layout(margin=dict(l=0,r=0,t=30,b=0), height=350)
                            fig_year_disp.update_coloraxes(showscale=False)
                            cols_yearly[col_idx_yearly].plotly_chart(fig_year_disp, use_container_width=True, key=f"fig_year_{year_val}{key_suffix}")
                            df_yearly_sum = pd.DataFrame(yearly_sum_in_range)
                            add_excel_download_button(df_yearly_sum, common_filename_prefix, f"Yearly_Dist_Year_{year_val}", f"excel_year_{year_val}{key_suffix}")
                            col_idx_yearly = (col_idx_yearly + 1) % num_cols_display
        st.markdown('</div>', unsafe_allow_html=True)

def image_navigation_ui(images_folder: str, available_dates_map: dict, 
                        session_state_key_for_idx: str, key_prefix: str,
                        show_legend: bool = False, index_name_for_legend: str = ""):
    if not available_dates_map:
        st.info("Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼ÎµÏ‚ ÎµÎ¹ÎºÏŒÎ½ÎµÏ‚ Î¼Îµ Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±."); return None

    sorted_date_strings = sorted(available_dates_map.keys())
    
    if session_state_key_for_idx not in st.session_state:
        st.session_state[session_state_key_for_idx] = 0

    current_idx = st.session_state[session_state_key_for_idx]
    if current_idx >= len(sorted_date_strings): # Handle empty or out-of-bounds index
        current_idx = 0
        st.session_state[session_state_key_for_idx] = current_idx


    col_prev, col_select, col_next = st.columns([1,2,1])
    if col_prev.button("<< Î ÏÎ¿Î·Î³.", key=f"{key_prefix}_prev", help="Î ÏÎ¿Î·Î³Î¿ÏÎ¼ÎµÎ½Î· ÎµÎ¹ÎºÏŒÎ½Î±", use_container_width=True):
        current_idx = max(0, current_idx - 1)
        st.session_state[session_state_key_for_idx] = current_idx; st.rerun()

    if col_next.button("Î•Ï€ÏŒÎ¼. >>", key=f"{key_prefix}_next", help="Î•Ï€ÏŒÎ¼ÎµÎ½Î· ÎµÎ¹ÎºÏŒÎ½Î±", use_container_width=True):
        current_idx = min(len(sorted_date_strings) - 1, current_idx + 1)
        st.session_state[session_state_key_for_idx] = current_idx; st.rerun()
            
    def update_idx_from_select_nav(): 
        selected_val = st.session_state[f"{key_prefix}_select_nav"]
        if selected_val in sorted_date_strings:
                st.session_state[session_state_key_for_idx] = sorted_date_strings.index(selected_val)

    col_select.selectbox("Î•Ï€Î¹Î»Î¿Î³Î® Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±Ï‚:", options=sorted_date_strings, index=current_idx, 
                        key=f"{key_prefix}_select_nav", on_change=update_idx_from_select_nav,
                        label_visibility="collapsed")
    
    current_idx = st.session_state[session_state_key_for_idx] 
    actual_selected_date_str = sorted_date_strings[current_idx]

    st.caption(f"Î•Î¼Ï†Î±Î½Î¯Î¶ÎµÏ„Î±Î¹ ÎµÎ¹ÎºÏŒÎ½Î± Î³Î¹Î±: {actual_selected_date_str}")
    image_filename = available_dates_map[actual_selected_date_str]
    image_full_path = os.path.join(images_folder, image_filename)

    if os.path.exists(image_full_path):
        st.image(image_full_path, caption=f"{image_filename}", use_column_width=True)
        if show_legend and index_name_for_legend == "Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·":
            try: # Use Streamlit's theme colors if available
                theme_bg = st.get_option("theme.backgroundColor")
                theme_text = st.get_option("theme.textColor")
                legend_fig = create_chl_legend_figure(orientation="horizontal", theme_bg_color=theme_bg, theme_text_color=theme_text)
            except: # Fallback if theme options are not accessible (e.g., older Streamlit version)
                legend_fig = create_chl_legend_figure(orientation="horizontal")
            st.pyplot(legend_fig)
    else:
        st.error(f"Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ ÎµÎ¹ÎºÏŒÎ½Î±Ï‚ Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ: {image_full_path}")
    return image_full_path


def analyze_sampling_for_dashboard(sampling_points: list, first_image_data_rgb, first_image_transform,
                                    images_folder_path: str, lake_height_excel_path: str, 
                                    selected_point_names_for_plot: list | None = None):
    def _geographic_to_pixel(lon: float, lat: float, transform_matrix) -> tuple[int, int]:
        inv_transform = ~transform_matrix; px, py = inv_transform * (lon, lat); return int(px), int(py)

    def _map_rgb_to_mg(r_val: float, g_val: float, b_val: float, mg_factor: float = 2.0) -> float:
        return (g_val / 255.0) * mg_factor 

    results_colors_dash, results_mg_dash = {n:[] for n,_,_ in sampling_points}, {n:[] for n,_,_ in sampling_points}
    if not os.path.isdir(images_folder_path):
        st.error(f"ÎŸ Ï†Î¬ÎºÎµÎ»Î¿Ï‚ ÎµÎ¹ÎºÏŒÎ½Ï‰Î½ '{images_folder_path}' Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Î³Î¹Î± dashboard."); return go.Figure(),go.Figure(),go.Figure(),go.Figure(),{},{},pd.DataFrame()

    for filename in sorted(os.listdir(images_folder_path)):
        if not filename.lower().endswith(('.tif', '.tiff')): continue
        m = re.search(r'(\d{4})[_-]?(\d{2})[_-]?(\d{2})', filename)
        if not m: continue
        try: date_obj = datetime(int(m.groups()[0]), int(m.groups()[1]), int(m.groups()[2]))
        except ValueError: continue

        try:
            with rasterio.open(os.path.join(images_folder_path, filename)) as src:
                if src.count < 3: continue
                for name, lon, lat in sampling_points:
                    col, row = _geographic_to_pixel(lon, lat, src.transform)
                    if 0 <= col < src.width and 0 <= row < src.height:
                        win = rasterio.windows.Window(col,row,1,1)
                        pixel_data = src.read([1,2,3], window=win)
                        r,g,b = pixel_data[0,0,0], pixel_data[1,0,0], pixel_data[2,0,0]
                        
                        mg_v = _map_rgb_to_mg(r,g,b)
                        results_mg_dash[name].append((date_obj, mg_v))
                        results_colors_dash[name].append((date_obj, (r/255.,g/255.,b/255.)))
        except Exception as e: debug_message(f"Î£Ï†Î¬Î»Î¼Î± {filename} Î³Î¹Î± dashboard: {e}"); continue
            
    if first_image_data_rgb is None or first_image_transform is None:
        st.error("Î”ÎµÎ´Î¿Î¼Î­Î½Î± ÎµÎ¹ÎºÏŒÎ½Î±Ï‚ Î±Î½Î±Ï†Î¿ÏÎ¬Ï‚ (first_image_data_rgb / first_image_transform) Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î±.")
        return go.Figure(),go.Figure(),go.Figure(),go.Figure(),{},{},pd.DataFrame()

    rgb_disp_data = first_image_data_rgb.transpose((1,2,0))
    if rgb_disp_data.max() > 1:
        rgb_disp_data = rgb_disp_data / 255.0
    rgb_disp_data = np.clip(rgb_disp_data, 0, 1)

    fig_geo_d = px.imshow(rgb_disp_data, title='Î•Î¹ÎºÏŒÎ½Î± Î‘Î½Î±Ï†Î¿ÏÎ¬Ï‚ & Î£Î·Î¼ÎµÎ¯Î± Î”ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î±Ï‚')
    for n,lon,lat in sampling_points:
        col,row=_geographic_to_pixel(lon,lat,first_image_transform)
        fig_geo_d.add_trace(go.Scatter(x=[col],y=[row],mode='markers+text', marker=dict(color='red',size=10,symbol='x'),name=n,text=n,textposition="top right", hovertemplate=f'<b>{n}</b><br>Lon:{lon:.4f}<br>Lat:{lat:.4f}<extra></extra>'))
    fig_geo_d.update_xaxes(visible=False); fig_geo_d.update_yaxes(visible=False,scaleanchor="x",scaleratio=1); fig_geo_d.update_layout(height=600,showlegend=True,legend_title_text="Î£Î·Î¼ÎµÎ¯Î±",uirevision='dashboard_geo')

    df_h_d = pd.DataFrame(columns=['Date', 'Height']) 
    if os.path.exists(str(lake_height_excel_path)):
        try:
            df_tmp=pd.read_excel(lake_height_excel_path)
            if not df_tmp.empty and len(df_tmp.columns)>=2:
                df_h_d['Date']=pd.to_datetime(df_tmp.iloc[:,0],errors='coerce'); df_h_d['Height']=pd.to_numeric(df_tmp.iloc[:,1],errors='coerce')
                df_h_d.dropna(inplace=True); df_h_d.sort_values('Date',inplace=True)
        except Exception as e: st.warning(f"Î£Ï†Î¬Î»Î¼Î± Î±Î½Î¬Î³Î½Ï‰ÏƒÎ·Ï‚ ÏƒÏ„Î¬Î¸Î¼Î·Ï‚ (dashboard): {e}")
            
    fig_colors_d=make_subplots(specs=[[{"secondary_y":True}]])
    pts_plot = selected_point_names_for_plot if selected_point_names_for_plot else [p[0] for p in sampling_points]
    pt_y_idx={n:i for i,n in enumerate(pts_plot)}

    for n_iter in pts_plot:
        if n_iter in results_colors_dash and results_colors_dash[n_iter]:
            d_list=sorted(results_colors_dash[n_iter],key=lambda x:x[0])
            if d_list:
                dts_c,cols_c_norm=zip(*d_list)
                cols_rgb_s=[f"rgb({int(c[0]*255)},{int(c[1]*255)},{int(c[2]*255)})" for c in cols_c_norm]
                y_p=pt_y_idx.get(n_iter,-1)
                if y_p != -1:
                    fig_colors_d.add_trace(go.Scatter(x=list(dts_c),y=[y_p]*len(dts_c),mode='markers',marker=dict(color=cols_rgb_s,size=10),name=n_iter,legendgroup=n_iter),secondary_y=False)
    
    if not df_h_d.empty: fig_colors_d.add_trace(go.Scatter(x=df_h_d['Date'],y=df_h_d['Height'],name='Î£Ï„Î¬Î¸Î¼Î·',mode='lines',line=dict(color='blue',width=2),legendgroup="h_grp"),secondary_y=True)
    fig_colors_d.update_layout(title='Î§ÏÏÎ¼Î±Ï„Î± Pixel & Î£Ï„Î¬Î¸Î¼Î·',xaxis_title='Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±',
                                yaxis=dict(title='Î£Î·Î¼ÎµÎ¯Î±',tickmode='array',tickvals=list(pt_y_idx.values()),ticktext=list(pt_y_idx.keys()),showgrid=False),
                                yaxis2=dict(title='Î£Ï„Î¬Î¸Î¼Î· (m)',showgrid=True,gridcolor='rgba(128,128,128,0.2)'),showlegend=True,uirevision='dashboard_colors')

    all_mg_vals_date_d={};
    for p_n in pts_plot: 
        if p_n in results_mg_dash:
            for d_obj,val_mg in results_mg_dash[p_n]: all_mg_vals_date_d.setdefault(d_obj,[]).append(val_mg)
    s_dates_mg_d=sorted(all_mg_vals_date_d.keys())
    avg_mg_d=[np.mean(all_mg_vals_date_d[d_obj]) for d_obj in s_dates_mg_d if all_mg_vals_date_d[d_obj]]
    
    fig_mg_d=go.Figure()
    if s_dates_mg_d and avg_mg_d: fig_mg_d.add_trace(go.Scatter(x=s_dates_mg_d,y=avg_mg_d,mode='lines+markers',name='ÎœÎ­ÏƒÎ¿ mg/mÂ³',marker=dict(color=avg_mg_d,colorscale='Viridis',reversescale=True,colorbar=dict(title='mg/mÂ³',thickness=15),size=10),line=dict(color='grey')))
    fig_mg_d.update_layout(title='ÎœÎ­ÏƒÎ¿ mg/mÂ³ (Î•Ï€Î¹Î»ÎµÎ³Î¼Î­Î½Î± Î£Î·Î¼ÎµÎ¯Î±)',xaxis_title='Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±',yaxis_title='mg/mÂ³',uirevision='dashboard_mg')

    fig_dual_d=make_subplots(specs=[[{"secondary_y":True}]])
    if not df_h_d.empty: 
        fig_dual_d.add_trace(go.Scatter(x=df_h_d['Date'],y=df_h_d['Height'],name='Î£Ï„Î¬Î¸Î¼Î·',mode='lines',line=dict(color='deepskyblue')),secondary_y=False)
    if s_dates_mg_d and avg_mg_d: 
        fig_dual_d.add_trace(go.Scatter(x=s_dates_mg_d,y=avg_mg_d,name='ÎœÎ­ÏƒÎ¿ mg/mÂ³',mode='lines+markers',marker=dict(color=avg_mg_d,colorscale='Viridis',reversescale=True,size=10,showscale=False),line=dict(color='lightgreen')),secondary_y=True)
    
    fig_dual_d.update_layout(
        title='Î£Ï„Î¬Î¸Î¼Î· & ÎœÎ­ÏƒÎ¿ mg/mÂ³',
        xaxis_title='Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±',
        uirevision='dashboard_dual', 
        yaxis=dict(title=dict(text="Î£Ï„Î¬Î¸Î¼Î· (m)", font=dict(color="deepskyblue")), tickfont=dict(color="deepskyblue"),side='left'),
        yaxis2=dict(title=dict(text="mg/mÂ³", font=dict(color="lightgreen")), tickfont=dict(color="lightgreen"),overlaying='y', side='right')
    )
    
    return fig_geo_d,fig_dual_d,fig_colors_d,fig_mg_d,results_colors_dash,results_mg_dash,df_h_d


def run_water_quality_dashboard(waterbody: str, index_name: str):
    with st.container():
        st.markdown('<div class="card">', unsafe_allow_html=True) # Changed to card
        st.header(f"Î ÏÎ¿Ï†Î¯Î» Î Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ ÎºÎ±Î¹ Î£Ï„Î¬Î¸Î¼Î·Ï‚: {waterbody} - {index_name}")
        
        clean_index_name_for_key = re.sub(r'[^a-zA-Z0-9_]', '', index_name)
        key_suffix_dash = f"_dash_{waterbody}_{clean_index_name_for_key}"
        common_filename_prefix_dash = f"{waterbody}_{index_name}" 

        data_folder = get_data_folder(waterbody, index_name)
        if not data_folder: 
            st.error(f"Î¦Î¬ÎºÎµÎ»Î¿Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î³Î¹Î± '{waterbody} - {index_name}' Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ. Î Î±ÏÎ±ÎºÎ±Î»Ï ÎµÎ»Î­Î³Î¾Ï„Îµ Ï„Î¹Ï‚ ÏÏ…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹ Ï„Î· Î´Î¿Î¼Î® Ï„Ï‰Î½ Ï†Î±ÎºÎ­Î»Ï‰Î½ ÏƒÎ±Ï‚.")
            st.markdown('</div>', unsafe_allow_html=True); return

        images_folder_path = os.path.join(data_folder,"GeoTIFFs")
        lake_height_excel_path = os.path.join(data_folder,"lake height.xlsx")
        default_sampling_kml_path = os.path.join(data_folder,"sampling.kml")
        vid_path = next((p for n in ["timelapse.mp4","timelapse.gif","Sentinel-2_L1C-202307221755611-timelapse.gif"] for p in [os.path.join(data_folder,n), os.path.join(images_folder_path,n)] if os.path.exists(p)), None)
        
        st.sidebar.subheader(f"Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚ Î Î¯Î½Î±ÎºÎ± ({index_name})")
        available_tifs = {str(d.date()):fn for fn in (os.listdir(images_folder_path) if os.path.exists(images_folder_path) else []) if fn.lower().endswith(('.tif','.tiff')) for _,d in [extract_date_from_filename(fn)] if d}
        
        first_img_rgb, first_img_transform = None, None
        if available_tifs:
            sel_bg_date_options = sorted(available_tifs.keys(),reverse=True)
            sel_bg_date_index = 0 if sel_bg_date_options else None

            sel_bg_date = st.sidebar.selectbox("Î•Î¹ÎºÏŒÎ½Î± Î‘Î½Î±Ï†Î¿ÏÎ¬Ï‚:", sel_bg_date_options, index=sel_bg_date_index, key=f"bg_date{key_suffix_dash}")
            if sel_bg_date and available_tifs.get(sel_bg_date):
                try:
                    with rasterio.open(os.path.join(images_folder_path,available_tifs[sel_bg_date])) as src:
                        if src.count>=3: first_img_rgb,first_img_transform = src.read([1,2,3]),src.transform
                        else: st.sidebar.error("Î•Î¹ÎºÏŒÎ½Î± < 3 ÎºÎ±Î½Î¬Î»Î¹Î±.")
                except Exception as e: st.sidebar.error(f"Î£Ï†Î¬Î»Î¼Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ Î±Î½Î±Ï†Î¿ÏÎ¬Ï‚: {e}")
        else: st.sidebar.warning("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ GeoTIFF Î³Î¹Î± ÎµÎ¹ÎºÏŒÎ½Î± Î±Î½Î±Ï†Î¿ÏÎ¬Ï‚.")

        if first_img_rgb is None: 
            st.error("Î‘Ï€Î±Î¹Ï„ÎµÎ¯Ï„Î±Î¹ Î­Î³ÎºÏ…ÏÎ· ÎµÎ¹ÎºÏŒÎ½Î± Î±Î½Î±Ï†Î¿ÏÎ¬Ï‚ GeoTIFF (Ï„Î¿Ï…Î»Î¬Ï‡Î¹ÏƒÏ„Î¿Î½ 3 ÎºÎ±Î½Î¬Î»Î¹Î±) Î³Î¹Î± Ï„Î· ÏƒÏ…Î½Î­Ï‡ÎµÎ¹Î± Ï„Î·Ï‚ Î±Î½Î¬Î»Ï…ÏƒÎ·Ï‚.")
            st.markdown('</div>', unsafe_allow_html=True); return

        tabs_ctrl = st.tabs(["Î”ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î± 1 (Î ÏÎ¿ÎµÏ€Î¹Î»Î¿Î³Î®)", "Î”ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î± 2 (Î‘Î½Î­Î²Î±ÏƒÎ¼Î± KML)"])
        
        with tabs_ctrl[0]: # Default Sampling
            st.markdown("##### Î‘Î½Î¬Î»Ï…ÏƒÎ· Î¼Îµ Î ÏÎ¿ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î± Î£Î·Î¼ÎµÎ¯Î±")
            def_pts_list = parse_sampling_kml(default_sampling_kml_path) if os.path.exists(default_sampling_kml_path) else []
            st.session_state[f"def_pts_list{key_suffix_dash}"] = def_pts_list 
            
            if def_pts_list:
                all_def_point_names = [n for n,_,_ in def_pts_list]
                default_selection = all_def_point_names[:] 

                sel_pts_def_names = st.multiselect("Î£Î·Î¼ÎµÎ¯Î± (Î ÏÎ¿ÎµÏ€Î¹Î»Î¿Î³Î®):", all_def_point_names, default=default_selection, key=f"sel_def{key_suffix_dash}")
                st.session_state[f"sel_pts_def_names{key_suffix_dash}"] = sel_pts_def_names 
                if st.button("Î•ÎºÏ„Î­Î»ÎµÏƒÎ· (Î ÏÎ¿ÎµÏ€Î¹Î»Î¿Î³Î®)", key=f"run_def{key_suffix_dash}", type="primary", use_container_width=True):
                    with st.spinner("Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Î±Î½Î¬Î»Ï…ÏƒÎ·Ï‚ Î³Î¹Î± Ï€ÏÎ¿ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î± ÏƒÎ·Î¼ÎµÎ¯Î±..."): 
                        st.session_state[SESSION_KEY_DEFAULT_RESULTS_DASHBOARD] = analyze_sampling_for_dashboard(
                            def_pts_list, first_img_rgb, first_img_transform, images_folder_path, lake_height_excel_path, sel_pts_def_names
                        )
            else: st.caption("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï„Î¿ Ï€ÏÎ¿ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Î´ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î±Ï‚ (sampling.kml).")

            if SESSION_KEY_DEFAULT_RESULTS_DASHBOARD in st.session_state and st.session_state[SESSION_KEY_DEFAULT_RESULTS_DASHBOARD]:
                res_def = st.session_state[SESSION_KEY_DEFAULT_RESULTS_DASHBOARD]
                current_def_pts_list = st.session_state.get(f"def_pts_list{key_suffix_dash}", [])
                current_sel_pts_def_names_for_plot = st.session_state.get(f"sel_pts_def_names{key_suffix_dash}", [p[0] for p in current_def_pts_list])


                if isinstance(res_def, tuple) and len(res_def) == 7:
                    fig_g, fig_d, fig_c, fig_m, res_c_data, res_m_data, df_h_data = res_def
                    
                    n_tabs_titles = ["GeoTIFF","Î•Î¹ÎºÏŒÎ½ÎµÏ‚","Video/GIF","Î§ÏÏÎ¼Î±Ï„Î± Pixel","ÎœÎ­ÏƒÎ¿ mg/mÂ³","Î£Ï…Î½Î´Ï…Î±ÏƒÎ¼Î­Î½Î¿","mg/mÂ³ Î±Î½Î¬ Î£Î·Î¼ÎµÎ¯Î¿"]
                    n_tabs_def_display = st.tabs(n_tabs_titles)
                    tab_prefix_key = f"def_tab_{key_suffix_dash}"

                    with n_tabs_def_display[0]: 
                        st.plotly_chart(fig_g, use_container_width=True, key=f"geo_d_chart_disp_{tab_prefix_key}")
                        if current_def_pts_list:
                            points_to_export_df = pd.DataFrame(
                                [pt for pt in current_def_pts_list if pt[0] in current_sel_pts_def_names_for_plot],
                                columns=['PointName', 'Longitude', 'Latitude']
                            ) if current_sel_pts_def_names_for_plot else pd.DataFrame(current_def_pts_list, columns=['PointName', 'Longitude', 'Latitude'])
                            
                            if not points_to_export_df.empty:
                                add_excel_download_button(points_to_export_df, f"{common_filename_prefix_dash}_default", "Sampling Points", f"excel_geo_def_{tab_prefix_key}")
                        if index_name == "Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·": 
                            try:
                                theme_bg = st.get_option("theme.backgroundColor")
                                theme_text = st.get_option("theme.textColor")
                                st.pyplot(create_chl_legend_figure(theme_bg_color=theme_bg, theme_text_color=theme_text))
                            except:
                                st.pyplot(create_chl_legend_figure())

                    with n_tabs_def_display[1]: 
                        image_navigation_ui(images_folder_path,available_tifs,SESSION_KEY_CURRENT_IMAGE_INDEX_DASH_DEF,f"nav_def_disp_{key_suffix_dash}",index_name=="Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·",index_name)
                    with n_tabs_def_display[2]: 
                        if vid_path: 
                            if vid_path.endswith(".mp4"): st.video(vid_path)
                            else: st.image(vid_path)
                            if index_name=="Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·": 
                                try:
                                    theme_bg = st.get_option("theme.backgroundColor")
                                    theme_text = st.get_option("theme.textColor")
                                    st.pyplot(create_chl_legend_figure(theme_bg_color=theme_bg, theme_text_color=theme_text))
                                except:
                                    st.pyplot(create_chl_legend_figure())
                        else: st.caption("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ video/timelapse.")

                    with n_tabs_def_display[3]: 
                        c1_disp,c2_disp=st.columns([.85,.15])
                        c1_disp.plotly_chart(fig_c, use_container_width=True, key=f"colors_d_chart_disp_{tab_prefix_key}")
                        excel_sheets_colors = {}
                        if isinstance(df_h_data, pd.DataFrame) and not df_h_data.empty:
                            excel_sheets_colors['LakeHeight'] = df_h_data.copy()
                        if res_c_data: 
                            for point_name, data_list in res_c_data.items():
                                if data_list and (point_name in current_sel_pts_def_names_for_plot):
                                    df_point_colors = pd.DataFrame(data_list, columns=['Date', 'RGB_Normalized'])
                                    df_point_colors['R_norm'] = df_point_colors['RGB_Normalized'].apply(lambda x: x[0])
                                    df_point_colors['G_norm'] = df_point_colors['RGB_Normalized'].apply(lambda x: x[1])
                                    df_point_colors['B_norm'] = df_point_colors['RGB_Normalized'].apply(lambda x: x[2])
                                    excel_sheets_colors[f"{point_name}_Colors"] = df_point_colors[['Date', 'R_norm', 'G_norm', 'B_norm']].sort_values(by="Date")
                        if excel_sheets_colors:
                                add_excel_download_button(excel_sheets_colors, f"{common_filename_prefix_dash}_default", "Pixel Colors and Height", f"excel_colors_def_{tab_prefix_key}")
                        if index_name=="Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·": 
                            try:
                                theme_bg = st.get_option("theme.backgroundColor")
                                theme_text = st.get_option("theme.textColor")
                                c2_disp.pyplot(create_chl_legend_figure("vertical", theme_bg_color=theme_bg, theme_text_color=theme_text))
                            except:
                                c2_disp.pyplot(create_chl_legend_figure("vertical"))


                    with n_tabs_def_display[4]: 
                        st.plotly_chart(fig_m, use_container_width=True, key=f"mg_d_chart_disp_{tab_prefix_key}")
                        temp_all_mg_by_d_loc = {} 
                        for p_name_temp in current_sel_pts_def_names_for_plot:
                            if p_name_temp in res_m_data:
                                for d_obj_temp, val_mg_temp in res_m_data[p_name_temp]:
                                    temp_all_mg_by_d_loc.setdefault(d_obj_temp, []).append(val_mg_temp)
                        
                        s_dts_mg_temp_loc = sorted(temp_all_mg_by_d_loc.keys())
                        mean_mg_temp_loc = [np.mean(temp_all_mg_by_d_loc[d]) for d in s_dts_mg_temp_loc if temp_all_mg_by_d_loc[d]]
                        st.session_state[f's_dts_mg_def{tab_prefix_key}'] = s_dts_mg_temp_loc 
                        st.session_state[f'mean_mg_def{tab_prefix_key}'] = mean_mg_temp_loc

                        if s_dts_mg_temp_loc and mean_mg_temp_loc:
                            df_mean_mg = pd.DataFrame({'Date': s_dts_mg_temp_loc, 'Mean_mg_m3': mean_mg_temp_loc}).sort_values(by="Date")
                            add_excel_download_button(df_mean_mg, f"{common_filename_prefix_dash}_default", "Mean mg_m3 (Selected Points)", f"excel_mean_mg_def_{tab_prefix_key}")

                    with n_tabs_def_display[5]: 
                        st.plotly_chart(fig_d, use_container_width=True, key=f"dual_d_chart_disp_{tab_prefix_key}")
                        s_dts_mg_for_dual = st.session_state.get(f's_dts_mg_def{tab_prefix_key}', [])
                        mean_mg_for_dual = st.session_state.get(f'mean_mg_def{tab_prefix_key}', [])
                        df_mean_mg_for_dual = pd.DataFrame({'Date': s_dts_mg_for_dual, 'Mean_mg_m3': mean_mg_for_dual}) if s_dts_mg_for_dual and mean_mg_for_dual else pd.DataFrame(columns=['Date', 'Mean_mg_m3'])
                        df_dual_export = pd.DataFrame()
                        if isinstance(df_h_data, pd.DataFrame) and not df_h_data.empty:
                            df_dual_export = df_h_data.copy()
                        if not df_mean_mg_for_dual.empty:
                            if not df_dual_export.empty:
                                df_dual_export = pd.merge(df_dual_export, df_mean_mg_for_dual, on='Date', how='outer')
                            else:
                                df_dual_export = df_mean_mg_for_dual
                        if not df_dual_export.empty:
                            df_dual_export.sort_values('Date', inplace=True, ignore_index=True)
                            add_excel_download_button(df_dual_export, f"{common_filename_prefix_dash}_default", "Height and Mean mg_m3", f"excel_dual_def_{tab_prefix_key}")
                        
                    with n_tabs_def_display[6]: 
                        point_options_for_detail = current_sel_pts_def_names_for_plot
                        if not point_options_for_detail: 
                                st.caption("Î”ÎµÎ½ Î­Ï‡Î¿Ï…Î½ ÎµÏ€Î¹Î»ÎµÎ³ÎµÎ¯ ÏƒÎ·Î¼ÎµÎ¯Î± Î³Î¹Î± ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ·.")
                        else:
                            sel_pt_d_disp = st.selectbox("Î£Î·Î¼ÎµÎ¯Î¿ Î³Î¹Î± mg/mÂ³:", point_options_for_detail, key=f"detail_d_sel_disp_{tab_prefix_key}")
                            if sel_pt_d_disp and res_m_data.get(sel_pt_d_disp): 
                                mg_d_p_list = sorted(res_m_data[sel_pt_d_disp], key=lambda x: x[0])
                                if mg_d_p_list: 
                                    dts_detail, vals_detail = zip(*mg_d_p_list)
                                    max_val_detail = max(vals_detail) if vals_detail else 1 
                                    mk_cols_detail = px.colors.sample_colorscale("Viridis", [v/(max_val_detail if max_val_detail > 0 else 1) for v in vals_detail])
                                    fig_det_d_disp = go.Figure(go.Scatter(x=list(dts_detail),y=list(vals_detail),mode='lines+markers',marker=dict(color=mk_cols_detail,size=10),line=dict(color="grey"),name=sel_pt_d_disp))
                                    fig_det_d_disp.update_layout(title=f"mg/mÂ³ Î³Î¹Î± {sel_pt_d_disp}",xaxis_title="Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±",yaxis_title="mg/mÂ³")
                                    st.plotly_chart(fig_det_d_disp,use_container_width=True, key=f"detail_d_chart_disp_{tab_prefix_key}")

                                    df_point_mg_detail = pd.DataFrame({'Date': list(dts_detail), f'mg_m3': list(vals_detail)}).sort_values(by="Date")
                                    add_excel_download_button(df_point_mg_detail, f"{common_filename_prefix_dash}_default_point_{sel_pt_d_disp}", f"mg_m3 for {sel_pt_d_disp}", f"excel_detail_mg_def_{sel_pt_d_disp}_{tab_prefix_key}")
                                else: st.caption(f"Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± mg/mÂ³ Î³Î¹Î± Ï„Î¿ ÏƒÎ·Î¼ÎµÎ¯Î¿ '{sel_pt_d_disp}'.")
                            elif sel_pt_d_disp: st.caption(f"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± mg/mÂ³ Î³Î¹Î± Ï„Î¿ ÏƒÎ·Î¼ÎµÎ¯Î¿ '{sel_pt_d_disp}'.")
                            else: st.caption("Î Î±ÏÎ±ÎºÎ±Î»Ï ÎµÏ€Î¹Î»Î­Î¾Ï„Îµ Î­Î½Î± ÏƒÎ·Î¼ÎµÎ¯Î¿.")
                else: 
                    st.error("Î£Ï†Î¬Î»Î¼Î± Î¼Î¿ÏÏ†Î®Ï‚ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ (Î ÏÎ¿ÎµÏ€Î¹Î»Î¿Î³Î®).")

        with tabs_ctrl[1]: # Upload KML
            st.markdown("##### Î‘Î½Î¬Î»Ï…ÏƒÎ· Î¼Îµ Î‘Î½ÎµÎ²Î±ÏƒÎ¼Î­Î½Î¿ KML")
            upl_file = st.file_uploader("Î‘Î½Î­Î²Î±ÏƒÎ¼Î± KML:", type="kml", key=f"upl_kml_{key_suffix_dash}")
            if upl_file:
                upl_pts_list = parse_sampling_kml(upl_file)
                st.session_state[f"upl_pts_list{key_suffix_dash}"] = upl_pts_list
                if upl_pts_list:
                    st.success(f"Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(upl_pts_list)} ÏƒÎ·Î¼ÎµÎ¯Î±.")
                    all_upl_point_names = [n for n,_,_ in upl_pts_list]
                    default_upl_selection = all_upl_point_names[:] 

                    sel_pts_upl_names = st.multiselect("Î£Î·Î¼ÎµÎ¯Î± (KML):", all_upl_point_names, default=default_upl_selection, key=f"sel_upl_{key_suffix_dash}")
                    st.session_state[f"sel_pts_upl_names{key_suffix_dash}"] = sel_pts_upl_names
                    if st.button("Î•ÎºÏ„Î­Î»ÎµÏƒÎ· (KML)",key=f"run_upl_{key_suffix_dash}",type="primary", use_container_width=True):
                        with st.spinner("Î•ÎºÏ„Î­Î»ÎµÏƒÎ·..."): 
                            st.session_state[SESSION_KEY_UPLOAD_RESULTS_DASHBOARD] = analyze_sampling_for_dashboard(
                                upl_pts_list, first_img_rgb, first_img_transform,
                                images_folder_path, lake_height_excel_path, sel_pts_upl_names
                            )
                else: 
                    st.error("Î¤Î¿ KML Î´ÎµÎ½ Ï€ÎµÏÎ¹ÎµÎ¯Ï‡Îµ Î­Î³ÎºÏ…ÏÎ± ÏƒÎ·Î¼ÎµÎ¯Î± Î® Î´ÎµÎ½ Î¼Ï€ÏŒÏÎµÏƒÎµ Î½Î± Î±Î½Î±Î»Ï…Î¸ÎµÎ¯.")
            
            if SESSION_KEY_UPLOAD_RESULTS_DASHBOARD in st.session_state and st.session_state[SESSION_KEY_UPLOAD_RESULTS_DASHBOARD]:
                res_upl = st.session_state[SESSION_KEY_UPLOAD_RESULTS_DASHBOARD]
                current_upl_pts_list = st.session_state.get(f"upl_pts_list{key_suffix_dash}", [])
                current_sel_pts_upl_names_for_plot = st.session_state.get(f"sel_pts_upl_names{key_suffix_dash}", [p[0] for p in current_upl_pts_list])

                if isinstance(res_upl, tuple) and len(res_upl) == 7:
                    fig_g_u, fig_d_u, fig_c_u, fig_m_u, res_c_data_u, res_m_data_u, df_h_data_u = res_upl
                    
                    n_tabs_u_titles = ["GeoTIFF","Î•Î¹ÎºÏŒÎ½ÎµÏ‚","Video/GIF","Î§ÏÏÎ¼Î±Ï„Î±","ÎœÎ­ÏƒÎ¿ mg/mÂ³","Î”Î¹Ï€Î»ÏŒ","mg/mÂ³ Î±Î½Î¬ Î£Î·Î¼ÎµÎ¯Î¿"]
                    n_tabs_upl_display = st.tabs(n_tabs_u_titles)
                    tab_prefix_key_upl = f"upl_tab_{key_suffix_dash}"

                    # Tab 0: GeoTIFF
                    with n_tabs_upl_display[0]:
                        st.plotly_chart(fig_g_u, use_container_width=True, key=f"geo_u_chart_disp_{tab_prefix_key_upl}")
                        if current_upl_pts_list:
                            points_to_export_df_upl = pd.DataFrame(
                                [pt for pt in current_upl_pts_list if pt[0] in current_sel_pts_upl_names_for_plot],
                                columns=['PointName', 'Longitude', 'Latitude']
                            ) if current_sel_pts_upl_names_for_plot else pd.DataFrame(current_upl_pts_list, columns=['PointName', 'Longitude', 'Latitude'])
                            if not points_to_export_df_upl.empty:
                                add_excel_download_button(points_to_export_df_upl, f"{common_filename_prefix_dash}_upload", "Sampling Points", f"excel_geo_upl_{tab_prefix_key_upl}")
                        if index_name == "Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·": 
                            try:
                                theme_bg = st.get_option("theme.backgroundColor")
                                theme_text = st.get_option("theme.textColor")
                                st.pyplot(create_chl_legend_figure(theme_bg_color=theme_bg, theme_text_color=theme_text))
                            except:
                                st.pyplot(create_chl_legend_figure())

                    # Tab 1: Images
                    with n_tabs_upl_display[1]:
                        image_navigation_ui(images_folder_path,available_tifs,SESSION_KEY_CURRENT_IMAGE_INDEX_DASH_UPL,f"nav_upl_disp_{key_suffix_dash}",index_name=="Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·",index_name)
                    # Tab 2: Video/GIF
                    with n_tabs_upl_display[2]:
                        if vid_path:
                            if vid_path.endswith(".mp4"): st.video(vid_path)
                            else: st.image(vid_path)
                            if index_name=="Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·": 
                                try:
                                    theme_bg = st.get_option("theme.backgroundColor")
                                    theme_text = st.get_option("theme.textColor")
                                    st.pyplot(create_chl_legend_figure(theme_bg_color=theme_bg, theme_text_color=theme_text))
                                except:
                                    st.pyplot(create_chl_legend_figure())
                        else: st.caption("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ video/timelapse.")
                    # Tab 3: Pixel Colors
                    with n_tabs_upl_display[3]:
                        c1u_disp, c2u_disp = st.columns([.85, .15])
                        c1u_disp.plotly_chart(fig_c_u, use_container_width=True, key=f"colors_u_chart_disp_{tab_prefix_key_upl}")
                        excel_sheets_colors_u = {}
                        if isinstance(df_h_data_u, pd.DataFrame) and not df_h_data_u.empty:
                            excel_sheets_colors_u['LakeHeight'] = df_h_data_u.copy()
                        if res_c_data_u:
                            for point_name, data_list in res_c_data_u.items():
                                if data_list and (point_name in current_sel_pts_upl_names_for_plot):
                                    df_point_colors = pd.DataFrame(data_list, columns=['Date', 'RGB_Normalized'])
                                    df_point_colors['R_norm'] = df_point_colors['RGB_Normalized'].apply(lambda x: x[0])
                                    df_point_colors['G_norm'] = df_point_colors['RGB_Normalized'].apply(lambda x: x[1])
                                    df_point_colors['B_norm'] = df_point_colors['RGB_Normalized'].apply(lambda x: x[2])
                                    excel_sheets_colors_u[f"{point_name}_Colors"] = df_point_colors[['Date', 'R_norm', 'G_norm', 'B_norm']].sort_values(by="Date")
                        if excel_sheets_colors_u:
                            add_excel_download_button(excel_sheets_colors_u, f"{common_filename_prefix_dash}_upload", "Pixel Colors and Height", f"excel_colors_upl_{tab_prefix_key_upl}")
                        if index_name == "Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·": 
                            try:
                                theme_bg = st.get_option("theme.backgroundColor")
                                theme_text = st.get_option("theme.textColor")
                                c2u_disp.pyplot(create_chl_legend_figure("vertical", theme_bg_color=theme_bg, theme_text_color=theme_text))
                            except:
                                c2u_disp.pyplot(create_chl_legend_figure("vertical"))
                    # Tab 4: Mean mg/m3
                    with n_tabs_upl_display[4]:
                        st.plotly_chart(fig_m_u, use_container_width=True, key=f"mg_u_chart_disp_{tab_prefix_key_upl}")
                        temp_all_mg_by_d_u_loc = {}
                        for p_name_temp in current_sel_pts_upl_names_for_plot:
                            if p_name_temp in res_m_data_u:
                                for d_obj_temp, val_mg_temp in res_m_data_u[p_name_temp]:
                                    temp_all_mg_by_d_u_loc.setdefault(d_obj_temp, []).append(val_mg_temp)
                        s_dts_mg_temp_u_loc = sorted(temp_all_mg_by_d_u_loc.keys())
                        mean_mg_temp_u_loc = [np.mean(temp_all_mg_by_d_u_loc[d]) for d in s_dts_mg_temp_u_loc if temp_all_mg_by_d_u_loc[d]]
                        st.session_state[f's_dts_mg_upl{tab_prefix_key_upl}'] = s_dts_mg_temp_u_loc
                        st.session_state[f'mean_mg_upl{tab_prefix_key_upl}'] = mean_mg_temp_u_loc
                        if s_dts_mg_temp_u_loc and mean_mg_temp_u_loc:
                            df_mean_mg_u = pd.DataFrame({'Date': s_dts_mg_temp_u_loc, 'Mean_mg_m3': mean_mg_temp_u_loc}).sort_values(by="Date")
                            add_excel_download_button(df_mean_mg_u, f"{common_filename_prefix_dash}_upload", "Mean mg_m3 (Selected Points)", f"excel_mean_mg_upl_{tab_prefix_key_upl}")
                    # Tab 5: Dual Axis
                    with n_tabs_upl_display[5]:
                        st.plotly_chart(fig_d_u, use_container_width=True, key=f"dual_u_chart_disp_{tab_prefix_key_upl}")
                        s_dts_mg_for_dual_u = st.session_state.get(f's_dts_mg_upl{tab_prefix_key_upl}', [])
                        mean_mg_for_dual_u = st.session_state.get(f'mean_mg_upl{tab_prefix_key_upl}', [])
                        df_mean_mg_for_dual_u = pd.DataFrame({'Date': s_dts_mg_for_dual_u, 'Mean_mg_m3': mean_mg_for_dual_u}) if s_dts_mg_for_dual_u and mean_mg_for_dual_u else pd.DataFrame(columns=['Date', 'Mean_mg_m3'])
                        df_dual_export_u = pd.DataFrame()
                        if isinstance(df_h_data_u, pd.DataFrame) and not df_h_data_u.empty:
                            df_dual_export_u = df_h_data_u.copy()
                        if not df_mean_mg_for_dual_u.empty:
                            if not df_dual_export_u.empty:
                                df_dual_export_u = pd.merge(df_dual_export_u, df_mean_mg_for_dual_u, on='Date', how='outer')
                            else:
                                df_dual_export_u = df_mean_mg_for_dual_u
                        if not df_dual_export_u.empty:
                            df_dual_export_u.sort_values('Date', inplace=True, ignore_index=True)
                            add_excel_download_button(df_dual_export_u, f"{common_filename_prefix_dash}_upload", "Height and Mean mg_m3", f"excel_dual_upl_{tab_prefix_key_upl}")

                    with n_tabs_upl_display[6]: 
                        point_options_for_detail_u = current_sel_pts_upl_names_for_plot if current_sel_pts_upl_names_for_plot else list(res_m_data_u.keys()) # Use selected points or all if none selected
                        if not point_options_for_detail_u:
                            st.caption("Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î± ÏƒÎ·Î¼ÎµÎ¯Î± Î³Î¹Î± ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ·.")
                        else:
                            sel_pt_u_disp = st.selectbox("Î£Î·Î¼ÎµÎ¯Î¿ Î³Î¹Î± mg/mÂ³ (KML):", point_options_for_detail_u, key=f"detail_u_sel_disp_{tab_prefix_key_upl}")
                            if sel_pt_u_disp and res_m_data_u.get(sel_pt_u_disp):
                                mg_d_pu_list = sorted(res_m_data_u[sel_pt_u_disp], key=lambda x: x[0])
                                if mg_d_pu_list:
                                    dts_u_detail, vals_u_detail = zip(*mg_d_pu_list)
                                    mk_cols_u_detail = px.colors.sample_colorscale("Viridis", [v/(max(vals_u_detail) if max(vals_u_detail) and max(vals_u_detail)>0 else 1) for v in vals_u_detail])
                                    fig_det_u_disp = go.Figure(go.Scatter(x=list(dts_u_detail),y=list(vals_u_detail),mode='lines+markers',marker=dict(color=mk_cols_u_detail,size=10),line=dict(color="grey"),name=sel_pt_u_disp))
                                    fig_det_u_disp.update_layout(title=f"mg/mÂ³ Î³Î¹Î± {sel_pt_u_disp} (KML)",xaxis_title="Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±",yaxis_title="mg/mÂ³")
                                    st.plotly_chart(fig_det_u_disp, use_container_width=True, key=f"detail_u_chart_disp_{tab_prefix_key_upl}")
                                    
                                                                
                                    df_point_mg_detail_u = pd.DataFrame({'Date': list(dts_u_detail), f'mg_m3': list(vals_u_detail)}).sort_values(by="Date")
                                    add_excel_download_button(df_point_mg_detail_u, f"{common_filename_prefix_dash}_upload_point_{sel_pt_u_disp}", f"mg_m3 for {sel_pt_u_disp}", f"excel_detail_mg_upl_{sel_pt_u_disp}_{tab_prefix_key_upl}")
                                else: st.caption(f"Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± mg/mÂ³ Î³Î¹Î± Ï„Î¿ ÏƒÎ·Î¼ÎµÎ¯Î¿ '{sel_pt_u_disp}'.")
                            elif sel_pt_u_disp : st.caption(f"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± mg/mÂ³ Î³Î¹Î± Ï„Î¿ ÏƒÎ·Î¼ÎµÎ¯Î¿ '{sel_pt_u_disp}'.")
                            else: st.caption("Î Î±ÏÎ±ÎºÎ±Î»Ï ÎµÏ€Î¹Î»Î­Î¾Ï„Îµ Î­Î½Î± ÏƒÎ·Î¼ÎµÎ¯Î¿.")
                else:
                    st.error("Î£Ï†Î¬Î»Î¼Î± Î¼Î¿ÏÏ†Î®Ï‚ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ (Upload KML).")
        st.markdown('</div>', unsafe_allow_html=True)


def run_predictive_tools(waterbody: str, initial_selected_index: str):
    with st.container():
        st.markdown('<div class="custom-card">', unsafe_allow_html=True)
        st.header(f"Î•ÏÎ³Î±Î»ÎµÎ¯Î± Î ÏÏŒÎ²Î»ÎµÏˆÎ·Ï‚ & ÎˆÎ³ÎºÎ±Î¹ÏÎ·Ï‚ Î•Î½Î·Î¼Î­ÏÏ‰ÏƒÎ·Ï‚: {waterbody}")
        st.markdown(f"Î Î±ÏÎ¬Î»Î»Î·Î»Î· Î‘Î½Î¬Î»Ï…ÏƒÎ· Î³Î¹Î± Î”ÎµÎ¯ÎºÏ„ÎµÏ‚: **Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ, Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·, Î˜Î¿Î»ÏŒÏ„Î·Ï„Î±**")
        
        clean_initial_index_name = re.sub(r'[^a-zA-Z0-9_]', '', initial_selected_index)
        key_suffix_pred_section = f"_pred_tool_{waterbody}_{clean_initial_index_name}"
        
        chart_display_options = {
            "GeoTIFF": "geo", 
            "Î§ÏÏÎ¼Î±Ï„Î± Pixel & Î£Ï„Î¬Î¸Î¼Î·": "colors", 
            "Î£Ï„Î¬Î¸Î¼Î· Î›Î¯Î¼Î½Î·Ï‚ (ÎœÏŒÎ½Î¿)": "lake_height_only",
            "ÎœÎ­ÏƒÎ¿ mg/mÂ³": "mg",
            "Î£Ï…Î½Î´Ï…Î±ÏƒÎ¼Î­Î½Î¿ (Î£Ï„Î¬Î¸Î¼Î· & ÎœÎ­ÏƒÎ¿ mg/mÂ³)": "dual"
        }
        selected_charts_to_display = st.multiselect(
            "Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Ï„ÏÏ€Î¿Ï…Ï‚ Î´Î¹Î±Î³ÏÎ±Î¼Î¼Î¬Ï„Ï‰Î½ Î³Î¹Î± ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ·:",
            options=list(chart_display_options.keys()),
            default=list(chart_display_options.keys()),
            key=f"select_charts{key_suffix_pred_section}"
        )

        st.subheader("ÎšÎ¿Î¹Î½Î­Ï‚ Î Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ Î¦Î¹Î»Ï„ÏÎ±ÏÎ¯ÏƒÎ¼Î±Ï„Î¿Ï‚ Î³Î¹Î± ÏŒÎ»Î¿Ï…Ï‚ Ï„Î¿Ï…Ï‚ Î”ÎµÎ¯ÎºÏ„ÎµÏ‚")
        col_filt1, col_filt2 = st.columns(2)
        with col_filt1:
            lower_thresh_common, upper_thresh_common = st.slider(
                "Î•ÏÏÎ¿Ï‚ Ï„Î¹Î¼ÏÎ½ pixel:", 0, 255, (0, 255), 
                key=f"thresh_common{key_suffix_pred_section}"
            )
            sampling_type_common = st.radio(
                "Î£ÏÎ½Î¿Î»Î¿ Î£Î·Î¼ÎµÎ¯Ï‰Î½ Î”ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î±Ï‚:", 
                ["Î ÏÎ¿ÎµÏ€Î¹Î»Î¿Î³Î®", "Î‘Î½Î­Î²Î±ÏƒÎ¼Î± KML"], 
                key=f"sampling_type_common{key_suffix_pred_section}", 
                horizontal=True
            )
        with col_filt2:
            date_min_common = st.date_input("Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î± Î±Ï€ÏŒ:", value=date(2015, 1, 1), key=f"date_min_common{key_suffix_pred_section}")
            date_max_common = st.date_input("Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î± Î­Ï‰Ï‚:", value=date.today(), key=f"date_max_common{key_suffix_pred_section}")

        uploaded_kml_common = None
        if sampling_type_common == "Î‘Î½Î­Î²Î±ÏƒÎ¼Î± KML":
            uploaded_kml_common = st.file_uploader(
                "Î‘Î½ÎµÎ²Î¬ÏƒÏ„Îµ Î­Î½Î± Î±ÏÏ‡ÎµÎ¯Î¿ KML (Î¸Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î·Î¸ÎµÎ¯ Î³Î¹Î± ÏŒÎ»Î¿Ï…Ï‚ Ï„Î¿Ï…Ï‚ Î´ÎµÎ¯ÎºÏ„ÎµÏ‚):", 
                type="kml", 
                key=f"kml_upload_common{key_suffix_pred_section}"
            )

        if st.button("Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Î Î±ÏÎ¬Î»Î»Î·Î»Î·Ï‚ Î‘Î½Î¬Î»Ï…ÏƒÎ·Ï‚ & Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Î‘Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½", key=f"recalc_parallel{key_suffix_pred_section}", type="primary", use_container_width=True):
            indices_to_analyze = ["Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ", "Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·", "Î˜Î¿Î»ÏŒÏ„Î·Ï„Î±"]
            analysis_results_all_indices = {} 
            
            sampling_points_to_use_for_analysis = None
            default_kml_found = False # Moved definition higher
            if sampling_type_common == "Î ÏÎ¿ÎµÏ€Î¹Î»Î¿Î³Î®":
                for idx_for_kml in indices_to_analyze: 
                    temp_data_folder_for_kml = get_data_folder(waterbody, idx_for_kml)
                    if temp_data_folder_for_kml:
                        default_kml_path_common = os.path.join(temp_data_folder_for_kml, "sampling.kml")
                        if os.path.exists(default_kml_path_common):
                            sampling_points_to_use_for_analysis = parse_sampling_kml(default_kml_path_common)
                            if sampling_points_to_use_for_analysis:
                                default_kml_found = True
                                st.caption(f"Î§ÏÎ®ÏƒÎ· Ï€ÏÎ¿ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î¿Ï… KML Î±Ï€ÏŒ Ï„Î¿Î½ Ï†Î¬ÎºÎµÎ»Î¿ Ï„Î¿Ï… Î´ÎµÎ¯ÎºÏ„Î·: {idx_for_kml}")
                                break 
                if not default_kml_found:
                    st.error(f"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï€ÏÎ¿ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ KML (sampling.kml) ÏƒÎµ ÎºÎ±Î½Î­Î½Î±Î½ Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Ï†Î±ÎºÎ­Î»Î¿Ï…Ï‚ Ï„Ï‰Î½ Î´ÎµÎ¹ÎºÏ„ÏÎ½ Î³Î¹Î± Ï„Î¿ {waterbody}.")
                    st.markdown('</div>', unsafe_allow_html=True); return 
            elif sampling_type_common == "Î‘Î½Î­Î²Î±ÏƒÎ¼Î± KML":
                if uploaded_kml_common:
                    sampling_points_to_use_for_analysis = parse_sampling_kml(uploaded_kml_common)
                    if not sampling_points_to_use_for_analysis: # Check if KML parsing failed
                         st.error("Î¤Î¿ Î±Î½ÎµÎ²Î±ÏƒÎ¼Î­Î½Î¿ KML Î´ÎµÎ½ Ï€ÎµÏÎ¹ÎµÎ¯Ï‡Îµ Î­Î³ÎºÏ…ÏÎ± ÏƒÎ·Î¼ÎµÎ¯Î± Î® Î±Ï€Î­Ï„Ï…Ï‡Îµ Î· Î±Î½Î¬Î»Ï…ÏƒÎ·.")
                         st.markdown('</div>', unsafe_allow_html=True); return
                else:
                    st.error("Î•Ï€Î¹Î»Î­Î¾Î±Ï„Îµ Î±Î½Î­Î²Î±ÏƒÎ¼Î± KML, Î±Î»Î»Î¬ Î´ÎµÎ½ Î­Ï‡ÎµÎ¹ Î¼ÎµÏ„Î±Ï†Î¿ÏÏ„Ï‰Î¸ÎµÎ¯ Î±ÏÏ‡ÎµÎ¯Î¿.")
                    st.markdown('</div>', unsafe_allow_html=True); return
            
            if not sampling_points_to_use_for_analysis:
                st.error("Î”ÎµÎ½ Î®Ï„Î±Î½ Î´Ï…Î½Î±Ï„ÏŒÏ‚ Î¿ Î¿ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Ï„Ï‰Î½ ÏƒÎ·Î¼ÎµÎ¯Ï‰Î½ Î´ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î±Ï‚. Î— Î±Î½Î¬Î»Ï…ÏƒÎ· Î±ÎºÏ…ÏÏÎ½ÎµÏ„Î±Î¹.")
                st.markdown('</div>', unsafe_allow_html=True); return

            all_point_names_to_use_in_analysis = [pt[0] for pt in sampling_points_to_use_for_analysis]

            with st.spinner("Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Î±Î½Î±Î»ÏÏƒÎµÏ‰Î½ Î³Î¹Î± ÏŒÎ»Î¿Ï…Ï‚ Ï„Î¿Ï…Ï‚ Î´ÎµÎ¯ÎºÏ„ÎµÏ‚... Î‘Ï…Ï„ÏŒ Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î´Î¹Î±ÏÎºÎ­ÏƒÎµÎ¹ Î»Î¯Î³Î¿."):
                for i_prog, current_idx_name_iter in enumerate(indices_to_analyze):
                    progress_val = (i_prog + 1) / len(indices_to_analyze)
                    # Initialize progress_bar inside the loop if you want one per index
                    # Or update a single one:
                    if 'progress_bar_pred' not in st.session_state:
                        st.session_state.progress_bar_pred = st.progress(0, text="ÎˆÎ½Î±ÏÎ¾Î· ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ Î´ÎµÎ¹ÎºÏ„ÏÎ½...")
                    
                    st.session_state.progress_bar_pred.progress(progress_val / 2, text=f"Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î´ÎµÎ¯ÎºÏ„Î·: {current_idx_name_iter} (Ï†ÏŒÏÏ„Ï‰ÏƒÎ·)...")
                    
                    data_folder_idx = get_data_folder(waterbody, current_idx_name_iter)
                    if not data_folder_idx:
                        analysis_results_all_indices[current_idx_name_iter] = {"error": f"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï†Î¬ÎºÎµÎ»Î¿Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½."}
                        st.warning(f"Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· '{current_idx_name_iter}': Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï†Î¬ÎºÎµÎ»Î¿Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½.")
                        st.session_state.progress_bar_pred.progress(progress_val, text=f"Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· Î´ÎµÎ¯ÎºÏ„Î·: {current_idx_name_iter} (Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï†Î¬ÎºÎµÎ»Î¿Ï‚)")
                        continue

                    images_folder_idx = os.path.join(data_folder_idx, "GeoTIFFs")
                    lake_height_excel_idx = os.path.join(data_folder_idx, "lake height.xlsx")
                    
                    tif_files_idx = sorted(glob.glob(os.path.join(images_folder_idx, "*.tif")))
                    if not tif_files_idx:
                        analysis_results_all_indices[current_idx_name_iter] = {"error": "Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î±ÏÏ‡ÎµÎ¯Î± GeoTIFF."}
                        st.warning(f"Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· '{current_idx_name_iter}': Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î±ÏÏ‡ÎµÎ¯Î± GeoTIFF.")
                        st.session_state.progress_bar_pred.progress(progress_val, text=f"Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· Î´ÎµÎ¯ÎºÏ„Î·: {current_idx_name_iter} (Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ GeoTIFFs)")
                        continue

                    first_img_data_idx, first_transform_idx = None, None
                    try:
                        with rasterio.open(tif_files_idx[0]) as src:
                            if src.count < 3:
                                analysis_results_all_indices[current_idx_name_iter] = {"error": "Î— 1Î· ÎµÎ¹ÎºÏŒÎ½Î± GeoTIFF Î´ÎµÎ½ Î­Ï‡ÎµÎ¹ 3 ÎºÎ±Î½Î¬Î»Î¹Î±."}
                                st.warning(f"Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· '{current_idx_name_iter}': Î— 1Î· ÎµÎ¹ÎºÏŒÎ½Î± GeoTIFF Î´ÎµÎ½ Î­Ï‡ÎµÎ¹ 3 ÎºÎ±Î½Î¬Î»Î¹Î±.")
                                st.session_state.progress_bar_pred.progress(progress_val, text=f"Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· Î´ÎµÎ¯ÎºÏ„Î·: {current_idx_name_iter} (ÏƒÏ†Î¬Î»Î¼Î± ÎµÎ¹ÎºÏŒÎ½Î±Ï‚)")
                                continue
                            first_img_data_idx = src.read([1,2,3])
                            first_transform_idx = src.transform
                    except Exception as e:
                        analysis_results_all_indices[current_idx_name_iter] = {"error": f"Î£Ï†Î¬Î»Î¼Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ 1Î·Ï‚ ÎµÎ¹ÎºÏŒÎ½Î±Ï‚ GeoTIFF: {e}"}
                        st.warning(f"Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· '{current_idx_name_iter}': Î£Ï†Î¬Î»Î¼Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ 1Î·Ï‚ ÎµÎ¹ÎºÏŒÎ½Î±Ï‚ GeoTIFF.")
                        st.session_state.progress_bar_pred.progress(progress_val, text=f"Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· Î´ÎµÎ¯ÎºÏ„Î·: {current_idx_name_iter} (ÏƒÏ†Î¬Î»Î¼Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ ÎµÎ¹ÎºÏŒÎ½Î±Ï‚)")
                        continue
                    
                    try:
                        raw_figs_and_data = analyze_sampling_generic(
                            sampling_points=sampling_points_to_use_for_analysis,
                            first_image_data=first_img_data_idx,
                            first_transform=first_transform_idx,
                            images_folder=images_folder_idx,
                            lake_height_path=lake_height_excel_idx,
                            selected_points_names=all_point_names_to_use_in_analysis,
                            lower_thresh=lower_thresh_common,
                            upper_thresh=upper_thresh_common,
                            date_min=date_min_common,
                            date_max=date_max_common
                        )
                        analysis_results_all_indices[current_idx_name_iter] = {
                            "fig_geo": raw_figs_and_data[0], 
                            "fig_dual": raw_figs_and_data[1], 
                            "fig_colors": raw_figs_and_data[2], 
                            "fig_mg": raw_figs_and_data[3],
                            "data_results_colors": raw_figs_and_data[4],
                            "data_results_mg": raw_figs_and_data[5],    
                            "data_df_h": raw_figs_and_data[6]           
                        }
                        st.session_state.progress_bar_pred.progress(progress_val, text=f"ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ: {current_idx_name_iter}")
                    except Exception as e_analyze:
                        analysis_results_all_indices[current_idx_name_iter] = {"error": f"Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ Î±Î½Î¬Î»Ï…ÏƒÎ·: {e_analyze}"}
                        st.warning(f"Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ Î±Î½Î¬Î»Ï…ÏƒÎ· Ï„Î¿Ï… Î´ÎµÎ¯ÎºÏ„Î· '{current_idx_name_iter}'.")
                        st.session_state.progress_bar_pred.progress(progress_val, text=f"Î£Ï†Î¬Î»Î¼Î± Î±Î½Î¬Î»Ï…ÏƒÎ·Ï‚: {current_idx_name_iter}")
                if 'progress_bar_pred' in st.session_state:
                    del st.session_state.progress_bar_pred # Clean up progress bar from session

            st.session_state[f"predictive_tool_results{key_suffix_pred_section}"] = analysis_results_all_indices
            st.session_state[f"predictive_tool_selected_charts{key_suffix_pred_section}"] = selected_charts_to_display
            st.session_state[f"predictive_tool_sampling_points{key_suffix_pred_section}"] = sampling_points_to_use_for_analysis
            st.success("ÎŒÎ»ÎµÏ‚ Î¿Î¹ Î±Î½Î±Î»ÏÏƒÎµÎ¹Ï‚ Î¿Î»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎ±Î½!")


        if f"predictive_tool_results{key_suffix_pred_section}" in st.session_state:
            analysis_results = st.session_state[f"predictive_tool_results{key_suffix_pred_section}"]
            charts_to_show = st.session_state.get(f"predictive_tool_selected_charts{key_suffix_pred_section}", [])
            current_sampling_points_pred = st.session_state.get(f"predictive_tool_sampling_points{key_suffix_pred_section}", [])
            indices_to_analyze = ["Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ", "Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·", "Î˜Î¿Î»ÏŒÏ„Î·Ï„Î±"] # Define again for this block

            st.markdown("---")
            st.subheader("Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î Î±ÏÎ¬Î»Î»Î·Î»Î·Ï‚ Î‘Î½Î¬Î»Ï…ÏƒÎ·Ï‚")

            for chart_name_key_iter, fig_internal_key_iter in chart_display_options.items():
                if chart_name_key_iter not in charts_to_show:
                    continue

                st.markdown(f"#### {chart_name_key_iter}")
                common_filename_prefix_chart = f"{waterbody}_predictive_{fig_internal_key_iter}"


                if chart_name_key_iter == "Î§ÏÏÎ¼Î±Ï„Î± Pixel & Î£Ï„Î¬Î¸Î¼Î·": # Special layout for this one
                    for idx_name_iter_colors in indices_to_analyze:
                        with st.container(): # Keep full width
                            st.markdown(f"##### {idx_name_iter_colors}")
                            result_data_for_idx_colors = analysis_results.get(idx_name_iter_colors, {})
                            excel_btn_key_colors = f"excel_pred_colors_{idx_name_iter_colors}_{key_suffix_pred_section}"
                            
                            if "error" in result_data_for_idx_colors:
                                st.error(f"{idx_name_iter_colors}: {result_data_for_idx_colors['error']}")
                                continue

                            fig_colors_to_plot = result_data_for_idx_colors.get("fig_colors")
                            df_h_iter_colors = result_data_for_idx_colors.get("data_df_h")
                            results_colors_iter_data = result_data_for_idx_colors.get("data_results_colors")
                            
                            if fig_colors_to_plot:
                                fig_colors_to_plot.update_layout(height=500, uirevision=f"colors_{idx_name_iter_colors}_full{key_suffix_pred_section}")
                                st.plotly_chart(fig_colors_to_plot, use_container_width=True, key=f"chart_colors_{idx_name_iter_colors}_full{key_suffix_pred_section}")
                                
                                excel_sheets_pred_colors = {}
                                if isinstance(df_h_iter_colors, pd.DataFrame) and not df_h_iter_colors.empty:
                                    excel_sheets_pred_colors['LakeHeight'] = df_h_iter_colors.copy()
                                if results_colors_iter_data:
                                    for point_name_rc, data_list_rc in results_colors_iter_data.items():
                                        if data_list_rc:
                                            df_pt_colors = pd.DataFrame(data_list_rc, columns=['Date', 'RGB_Normalized'])
                                            df_pt_colors['R_norm'] = df_pt_colors['RGB_Normalized'].apply(lambda x: x[0])
                                            df_pt_colors['G_norm'] = df_pt_colors['RGB_Normalized'].apply(lambda x: x[1])
                                            df_pt_colors['B_norm'] = df_pt_colors['RGB_Normalized'].apply(lambda x: x[2])
                                            excel_sheets_pred_colors[f"{point_name_rc}_Colors"] = df_pt_colors[['Date', 'R_norm', 'G_norm', 'B_norm']].sort_values(by="Date")
                                if excel_sheets_pred_colors:
                                    add_excel_download_button(excel_sheets_pred_colors, f"{common_filename_prefix_chart}_{idx_name_iter_colors}", f"Pixel Colors & Height Data ({idx_name_iter_colors})", excel_btn_key_colors)
                            else:
                                st.caption(f"Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± '{chart_name_key_iter}' ({idx_name_iter_colors}).")
                        st.markdown("---" if idx_name_iter_colors != indices_to_analyze[-1] else "")
                else: # Regular 3-column layout
                    inner_cols = st.columns(len(indices_to_analyze)) 
                    for i, idx_name_iter_cols in enumerate(indices_to_analyze):
                        with inner_cols[i]:
                            st.markdown(f"##### {idx_name_iter_cols}")
                            result_data_for_idx_cols = analysis_results.get(idx_name_iter_cols, {})
                            excel_button_key_base_cols = f"excel_pred_{fig_internal_key_iter}_{idx_name_iter_cols}_{key_suffix_pred_section}"
                            
                            if "error" in result_data_for_idx_cols:
                                st.error(result_data_for_idx_cols["error"])
                                continue

                            fig_to_plot_cols = None
                            df_for_excel_pred_cols = None
                            excel_label_suffix_pred_cols = f"{chart_name_key_iter} ({idx_name_iter_cols})"
                            
                            df_h_iter_cols = result_data_for_idx_cols.get("data_df_h")
                            results_mg_iter_cols = result_data_for_idx_cols.get("data_results_mg")


                            if fig_internal_key_iter == "geo":
                                fig_to_plot_cols = result_data_for_idx_cols.get("fig_geo")
                                if current_sampling_points_pred:
                                    df_for_excel_pred_cols = pd.DataFrame(current_sampling_points_pred, columns=['PointName', 'Longitude', 'Latitude'])
                                    excel_label_suffix_pred_cols = f"Sampling Points Data ({idx_name_iter_cols})"
                            
                            elif fig_internal_key_iter == "lake_height_only":
                                if isinstance(df_h_iter_cols, pd.DataFrame) and not df_h_iter_cols.empty:
                                    df_for_excel_pred_cols = df_h_iter_cols.copy().sort_values(by="Date")
                                    excel_label_suffix_pred_cols = f"Lake Height Data ({idx_name_iter_cols})"
                                    fig_to_plot_cols = go.Figure(go.Scatter(x=df_h_iter_cols['Date'], y=df_h_iter_cols['Height'], name='Î£Ï„Î¬Î¸Î¼Î· Î›Î¯Î¼Î½Î·Ï‚'))
                                    fig_to_plot_cols.update_layout(title=f"Î£Ï„Î¬Î¸Î¼Î· Î›Î¯Î¼Î½Î·Ï‚ ({idx_name_iter_cols})")
                                else:
                                    st.caption(f"Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÏƒÏ„Î¬Î¸Î¼Î·Ï‚ Î³Î¹Î± {idx_name_iter_cols}")
                            
                            elif fig_internal_key_iter == "mg":
                                fig_to_plot_cols = result_data_for_idx_cols.get("fig_mg")
                                temp_all_mg_d_pred_cols = {}
                                if results_mg_iter_cols:
                                    for p_name_mg_iter, data_list_mg in results_mg_iter_cols.items():
                                        for d_obj_mg, val_mg_iter in data_list_mg:
                                            temp_all_mg_d_pred_cols.setdefault(d_obj_mg, []).append(val_mg_iter)
                                s_dts_mg_pred_cols = sorted(temp_all_mg_d_pred_cols.keys())
                                mean_mg_pred_cols = [np.mean(temp_all_mg_d_pred_cols[d]) for d in s_dts_mg_pred_cols if temp_all_mg_d_pred_cols[d]]
                                if s_dts_mg_pred_cols and mean_mg_pred_cols:
                                    df_for_excel_pred_cols = pd.DataFrame({'Date': s_dts_mg_pred_cols, 'Mean_mg_m3': mean_mg_pred_cols}).sort_values(by="Date")
                                    excel_label_suffix_pred_cols = f"Mean mg/mÂ³ Data ({idx_name_iter_cols})"

                            elif fig_internal_key_iter == "dual":
                                fig_to_plot_cols = result_data_for_idx_cols.get("fig_dual")
                                df_mean_mg_for_dual_pred_cols = pd.DataFrame()
                                temp_all_mg_d_pred_dual_cols = {}
                                if results_mg_iter_cols:
                                    for p_name_mg_iter_d, data_list_mg_d in results_mg_iter_cols.items():
                                        for d_obj_mg_d, val_mg_iter_d in data_list_mg_d:
                                            temp_all_mg_d_pred_dual_cols.setdefault(d_obj_mg_d, []).append(val_mg_iter_d)
                                s_dts_mg_pred_d_cols = sorted(temp_all_mg_d_pred_dual_cols.keys())
                                mean_mg_pred_d_cols = [np.mean(temp_all_mg_d_pred_dual_cols[d]) for d in s_dts_mg_pred_d_cols if temp_all_mg_d_pred_dual_cols[d]]
                                if s_dts_mg_pred_d_cols and mean_mg_pred_d_cols:
                                    df_mean_mg_for_dual_pred_cols = pd.DataFrame({'Date': s_dts_mg_pred_d_cols, 'Mean_mg_m3': mean_mg_pred_d_cols})

                                df_dual_export_pred_cols = pd.DataFrame()
                                if isinstance(df_h_iter_cols, pd.DataFrame) and not df_h_iter_cols.empty:
                                    df_dual_export_pred_cols = df_h_iter_cols.copy()
                                if not df_mean_mg_for_dual_pred_cols.empty:
                                    if not df_dual_export_pred_cols.empty:
                                        df_dual_export_pred_cols = pd.merge(df_dual_export_pred_cols, df_mean_mg_for_dual_pred_cols, on='Date', how='outer')
                                    else:
                                        df_dual_export_pred_cols = df_mean_mg_for_dual_pred_cols
                                if not df_dual_export_pred_cols.empty:
                                    df_dual_export_pred_cols.sort_values('Date', inplace=True, ignore_index=True)
                                    df_for_excel_pred_cols = df_dual_export_pred_cols
                                    excel_label_suffix_pred_cols = f"Height & Mean mg/mÂ³ Data ({idx_name_iter_cols})"
                            
                            if fig_to_plot_cols:
                                fig_to_plot_cols.update_layout(height=400, uirevision=f"{fig_internal_key_iter}_{idx_name_iter_cols}_col{key_suffix_pred_section}")
                                st.plotly_chart(fig_to_plot_cols, use_container_width=True, key=f"chart_{fig_internal_key_iter}_{idx_name_iter_cols}_col{key_suffix_pred_section}")
                                if df_for_excel_pred_cols is not None:
                                    add_excel_download_button(df_for_excel_pred_cols, f"{common_filename_prefix_chart}_{idx_name_iter_cols}", excel_label_suffix_pred_cols, excel_button_key_base_cols)
                                if fig_internal_key_iter == "geo" and idx_name_iter_cols == "Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·":
                                    st.pyplot(create_chl_legend_figure(orientation="horizontal"))
                            elif fig_internal_key_iter != "lake_height_only" and fig_internal_key_iter != "colors": # colors handled in its own block
                                 st.caption(f"Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± '{chart_name_key_iter}' ({idx_name_iter_cols}).")
                st.markdown("""<hr style="border:1px solid #444; margin-top:1.5rem; margin-bottom:1.5rem;">""", unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)

# Î’ÎµÎ²Î±Î¹Ï‰Î¸ÎµÎ¯Ï„Îµ ÏŒÏ„Î¹ Î¿Î¹ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ ÎµÎ¹ÏƒÎ±Î³Ï‰Î³Î­Ï‚ ÎµÎ¯Î½Î±Î¹ Î±Ï€Î¿ÏƒÏ‡Î¿Î»Î¹Î±ÏƒÎ¼Î­Î½ÎµÏ‚ ÏƒÏ„Î·Î½ Î±ÏÏ‡Î® Ï„Î¿Ï… Î±ÏÏ‡ÎµÎ¯Î¿Ï… ÏƒÎ±Ï‚:
# from sklearn.ensemble import IsolationForest
# from sklearn.preprocessing import StandardScaler
# from prophet import Prophet
# import ruptures as rpt
# (ÎºÎ±Î¹ Ï†Ï…ÏƒÎ¹ÎºÎ¬ Î¿Î¹ import os, np, pd, st, px, go, datetime, rasterio, ÎºÎ»Ï€. Ï€Î¿Ï… Î®Î´Î· Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½)

def run_ai_driven_analysis(waterbody: str, index_name: str):
    """
    Î•ÎºÏ„ÎµÎ»ÎµÎ¯ Ï€ÏÎ¿Î·Î³Î¼Î­Î½ÎµÏ‚ Î±Î½Î±Î»ÏÏƒÎµÎ¹Ï‚ Ï€ÏÎ¿Ï„ÏÏ€Ï‰Î½ (AI) ÏƒÏ„Î¹Ï‚ Ï‡ÏÎ¿Î½Î¿ÏƒÎµÎ¹ÏÎ­Ï‚
    Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ Ï…Î´Î¬Ï„Ï‰Î½ ÎºÎ±Î¹ ÏƒÏ„Î¬Î¸Î¼Î·Ï‚.
    """
    # Helper for debug messages (Ï„Î¿Ï€Î¹ÎºÎ® ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Î® Î¼Ï€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± Ï„Î·Î½ ÎºÎ¬Î½ÎµÏ„Îµ global)
    def _debug_ai(label, data):
        # Î“Î¹Î± Î½Î± Î¼Î·Î½ ÎµÎ¯Î½Î±Î¹ Ï€Î¿Î»Ï Ï†Î»ÏÎ±ÏÎ¿, Î¼Ï€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± Ï„Î¿ ÎµÎ»Î­Î³Ï‡ÎµÏ„Îµ Î¼Îµ Ï„Î¿ DEBUG flag
        if DEBUG: # Î¥Ï€Î¿Î¸Î­Ï„Î¿Î½Ï„Î±Ï‚ ÏŒÏ„Î¹ Î­Ï‡ÎµÏ„Îµ Î¿ÏÎ¯ÏƒÎµÎ¹ Ï„Î¿ DEBUG = True/False ÎºÎ¬Ï€Î¿Ï… global
            with st.expander(f"Debug AI: {label}", expanded=False):
                st.write(data)
                if hasattr(data, 'shape'):
                    st.write(f"Shape: {data.shape}")
                if isinstance(data, pd.DataFrame) or isinstance(data, pd.Series):
                    if not data.empty:
                        st.write("Head:", data.head())
                        try:
                            st.write("Describe:", data.describe(include='all'))
                        except: # Î‘Î½ Ï„Î¿ describe Î±Ï€Î¿Ï„ÏÏ‡ÎµÎ¹ Î³Î¹Î± ÎºÎ¬Ï€Î¿Î¹Î¿ Î»ÏŒÎ³Î¿
                            pass
                elif isinstance(data, dict):
                     st.json(data, expanded=False)


    with st.container():
        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.header(f"Î ÏÎ¿Î·Î³Î¼Î­Î½Î· Î‘Î½Î¬Î»Ï…ÏƒÎ· Î ÏÎ¿Ï„ÏÏ€Ï‰Î½ (AI): {waterbody} - {index_name}")

        # --- Î’Î—ÎœÎ‘ 1: Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î’Î±ÏƒÎ¹ÎºÏÎ½ Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ---
        _debug_ai("Î‘ÏÏ‡Î¹ÎºÎ­Ï‚ Î Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ AI", {"waterbody": waterbody, "index_name": index_name})
        data_folder = get_data_folder(waterbody, index_name) # Î¥Ï€Î¿Î¸Î­Ï„ÎµÎ¹ ÏŒÏ„Î¹ Î±Ï…Ï„Î® Î· ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Ï…Ï€Î¬ÏÏ‡ÎµÎ¹
        if not data_folder:
            st.error(f"ÎŸ Ï†Î¬ÎºÎµÎ»Î¿Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î³Î¹Î± '{waterbody} - {index_name}' Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ.")
            st.markdown('</div>', unsafe_allow_html=True); return
        _debug_ai("AI - Data Folder", data_folder)

        images_folder_path = os.path.join(data_folder, "GeoTIFFs")
        lake_height_excel_path = os.path.join(data_folder, "lake height.xlsx")
        default_sampling_kml_path = os.path.join(data_folder, "sampling.kml")

        sampling_points_list = []
        if os.path.exists(default_sampling_kml_path):
            sampling_points_list = parse_sampling_kml(default_sampling_kml_path) # Î¥Ï€Î¿Î¸Î­Ï„ÎµÎ¹ ÏŒÏ„Î¹ Î±Ï…Ï„Î® Î· ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Ï…Ï€Î¬ÏÏ‡ÎµÎ¹
        _debug_ai("AI - Sampling Points List (from KML)", sampling_points_list)
        
        if not sampling_points_list:
            st.info("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Ï€ÏÎ¿ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î± ÏƒÎ·Î¼ÎµÎ¯Î± Î´ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î±Ï‚ (sampling.kml). ÎŸÎ¹ Î±Î½Î±Î»ÏÏƒÎµÎ¹Ï‚ AI Î±Î½Î¬ ÏƒÎ·Î¼ÎµÎ¯Î¿ Î´ÎµÎ½ Î¸Î± ÎµÎ¯Î½Î±Î¹ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼ÎµÏ‚.")

        first_img_data_generic, first_transform_generic = None, None
        available_tifs_generic = {
            str(d.date()): fn for fn in (os.listdir(images_folder_path) if os.path.exists(images_folder_path) else [])
            if fn.lower().endswith(('.tif', '.tiff'))
            for _, d in [extract_date_from_filename(fn)] if d # Î¥Ï€Î¿Î¸Î­Ï„ÎµÎ¹ ÏŒÏ„Î¹ Î±Ï…Ï„Î® Î· ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Ï…Ï€Î¬ÏÏ‡ÎµÎ¹
        }
        _debug_ai("AI - Available TIFFs for Generic First Image", available_tifs_generic)

        if available_tifs_generic:
            first_available_date = sorted(available_tifs_generic.keys())[0]
            try:
                with rasterio.open(os.path.join(images_folder_path, available_tifs_generic[first_available_date])) as src:
                    if src.count >= 3:
                        first_img_data_generic = src.read([1, 2, 3])
                        first_transform_generic = src.transform
                    else:
                         debug_message(f"AI Analysis: Î— Ï€ÏÏÏ„Î· ÎµÎ¹ÎºÏŒÎ½Î± {available_tifs_generic[first_available_date]} Î­Ï‡ÎµÎ¹ {src.count} ÎºÎ±Î½Î¬Î»Î¹Î± (Ï‡ÏÎµÎ¹Î¬Î¶Î¿Î½Ï„Î±Î¹ 3 Î³Î¹Î± Ï„Î¿ first_img_data_generic). Î¤Î¿ first_img_data_generic Î¸Î± ÎµÎ¯Î½Î±Î¹ None.")
            except Exception as e:
                debug_message(f"AI Analysis: Î”ÎµÎ½ Î®Ï„Î±Î½ Î´Ï…Î½Î±Ï„Î® Î· Ï†ÏŒÏÏ„Ï‰ÏƒÎ· Ï„Î·Ï‚ Ï€ÏÏÏ„Î·Ï‚ ÎµÎ¹ÎºÏŒÎ½Î±Ï‚: {e}")
        _debug_ai("AI - First Image Data Generic (shape)", first_img_data_generic.shape if first_img_data_generic is not None else "None")

        all_point_names_from_kml = [pt[0] for pt in sampling_points_list] if sampling_points_list else []
        
        min_date_for_generic = date(1900, 1, 1)
        max_date_for_generic = date.today()

        # ÎšÎ»Î®ÏƒÎ· Ï„Î·Ï‚ analyze_sampling_generic Î³Î¹Î± Î½Î± Ï€Î¬ÏÎ¿Ï…Î¼Îµ Ï„Î± ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±
        # Î¥Ï€Î¿Î¸Î­Ï„ÎµÎ¹ ÏŒÏ„Î¹ Î· ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· analyze_sampling_generic Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ ÎºÎ±Î¹ Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³ÎµÎ¯ ÏŒÏ€Ï‰Ï‚ Î±Î½Î±Î¼Î­Î½ÎµÏ„Î±Î¹.
        _fig_geo, _fig_dual, _fig_colors, _fig_mg, results_colors, results_mg, df_h = analyze_sampling_generic(
            sampling_points=sampling_points_list,
            first_image_data=first_img_data_generic,
            first_transform=first_transform_generic,
            images_folder=images_folder_path,
            lake_height_path=lake_height_excel_path,
            selected_points_names=all_point_names_from_kml,
            date_min=min_date_for_generic,
            date_max=max_date_for_generic
        )
        _debug_ai("AI - Results MG (keys)", list(results_mg.keys()) if results_mg else "Empty")
        _debug_ai("AI - DataFrame df_h (info)", df_h.info() if not df_h.empty else "Empty")


        if not results_mg and df_h.empty:
            st.warning("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÎµÏ€Î±ÏÎºÎ® Î´ÎµÎ´Î¿Î¼Î­Î½Î± (Ï„Î¹Î¼Î­Ï‚ Î´ÎµÎ¹ÎºÏ„ÏÎ½ Î® ÏƒÏ„Î¬Î¸Î¼Î·Ï‚) Î³Î¹Î± Ï„Î·Î½ AI Î±Î½Î¬Î»Ï…ÏƒÎ· Î¼ÎµÏ„Î¬ Ï„Î·Î½ ÎºÎ»Î®ÏƒÎ· Ï„Î·Ï‚ analyze_sampling_generic.")
            st.markdown('</div>', unsafe_allow_html=True); return

        # --- Î’Î—ÎœÎ‘ 2: Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î•Ï€Î¹Î»Î¿Î³ÏÎ½ UI Î³Î¹Î± Ï„Î¿Î½ Î§ÏÎ®ÏƒÏ„Î· ---
        st.subheader("Î•Ï€Î¹Î»Î¿Î³Î­Ï‚ Î‘Î½Î¬Î»Ï…ÏƒÎ·Ï‚ AI")
        ai_task_options = ["Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î•ÏÎ³Î±ÏƒÎ¯Î± AI...", "Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ Î‘Î½Ï‰Î¼Î±Î»Î¹ÏÎ½ (Î§ÏÎ¿Î½Î¿ÏƒÎµÎ¹ÏÎ­Ï‚)", "Î ÏÏŒÎ²Î»ÎµÏˆÎ· Î§ÏÎ¿Î½Î¿ÏƒÎµÎ¹ÏÏÎ½", "Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ Î£Î·Î¼ÎµÎ¯Ï‰Î½ Î‘Î»Î»Î±Î³Î®Ï‚"]
        selected_ai_task = st.selectbox("Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î•ÏÎ³Î±ÏƒÎ¯Î± AI:", ai_task_options, key=f"ai_task_select_{waterbody}_{index_name}")

        target_data_options = ["Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î”ÎµÎ´Î¿Î¼Î­Î½Î±..."]
        df_avg_mg = pd.DataFrame()

        if results_mg:
            all_mg_by_date_for_avg = {}
            points_to_average = all_point_names_from_kml if all_point_names_from_kml else list(results_mg.keys())
            
            for point_name in points_to_average:
                if point_name in results_mg:
                    for d, v in results_mg[point_name]:
                        all_mg_by_date_for_avg.setdefault(d, []).append(v)
            
            if all_mg_by_date_for_avg:
                sorted_dates_for_avg = sorted(all_mg_by_date_for_avg.keys())
                # avg_mg_series_values = [np.mean(all_mg_by_date_for_avg[d]) for d in sorted_dates_for_avg if all_mg_by_date_for_avg[d]] # Î‘Ï€Î¿Ï†Ï…Î³Î® warning Î¼Îµ ÎºÎµÎ½Î® Î»Î¯ÏƒÏ„Î±
                avg_mg_series_values = []
                for d_val in sorted_dates_for_avg:
                    if all_mg_by_date_for_avg[d_val]: # Î‘Î½ Î· Î»Î¯ÏƒÏ„Î± Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ ÎºÎµÎ½Î®
                        avg_mg_series_values.append(np.mean(all_mg_by_date_for_avg[d_val]))
                    else: # Î‘Î½ ÎµÎ¯Î½Î±Î¹ ÎºÎµÎ½Î®, Ï€ÏÎ¿ÏƒÎ¸Î­Ï„Î¿Ï…Î¼Îµ NaN Î³Î¹Î± Î½Î± Î´Î¹Î±Ï„Î·ÏÎ®ÏƒÎ¿Ï…Î¼Îµ Ï„Î¿ Î¼Î®ÎºÎ¿Ï‚
                        avg_mg_series_values.append(np.nan)

                if any(not np.isnan(v) for v in avg_mg_series_values): # Î‘Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Ï„Î¿Ï…Î»Î¬Ï‡Î¹ÏƒÏ„Î¿Î½ Î¼Î¹Î± Î¼Î·-NaN Ï„Î¹Î¼Î®
                    target_data_options.append(f"ÎœÎ­ÏƒÎ¿Ï‚ ÎŒÏÎ¿Ï‚ {index_name} (mg/mÂ³)")
                    df_avg_mg = pd.DataFrame({'Date': pd.to_datetime(sorted_dates_for_avg), 'Value': avg_mg_series_values})
                    df_avg_mg = df_avg_mg.sort_values(by='Date').set_index('Date')
        _debug_ai("AI - Calculated df_avg_mg", df_avg_mg)

        if not df_h.empty:
            target_data_options.append("Î£Ï„Î¬Î¸Î¼Î· Î›Î¯Î¼Î½Î·Ï‚ (m)")
        
        if sampling_points_list:
             target_data_options.append("Î£Ï…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿ Î£Î·Î¼ÎµÎ¯Î¿ Î”ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î±Ï‚")

        selected_target_data_str = st.selectbox("Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î§ÏÎ¿Î½Î¿ÏƒÎµÎ¹ÏÎ¬ Î³Î¹Î± Î‘Î½Î¬Î»Ï…ÏƒÎ·:", target_data_options, key=f"ai_target_data_select_{waterbody}_{index_name}")
        _debug_ai("AI - Selected Target Data String", selected_target_data_str)

        selected_specific_point = None
        if selected_target_data_str == "Î£Ï…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿ Î£Î·Î¼ÎµÎ¯Î¿ Î”ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î±Ï‚" and sampling_points_list:
            point_names = [p[0] for p in sampling_points_list]
            selected_specific_point = st.selectbox("Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î£Î·Î¼ÎµÎ¯Î¿:", point_names, key=f"ai_specific_point_select_{waterbody}_{index_name}")
        _debug_ai("AI - Selected Specific Point", selected_specific_point)

        # --- Î’Î—ÎœÎ‘ 3: Î•Î¾Î±Î³Ï‰Î³Î® ÎºÎ±Î¹ Î ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î±ÏƒÎ¯Î± Ï„Î·Ï‚ Î•Ï€Î¹Î»ÎµÎ³Î¼Î­Î½Î·Ï‚ Î§ÏÎ¿Î½Î¿ÏƒÎµÎ¹ÏÎ¬Ï‚ ---
        df_analysis = pd.DataFrame()
        current_target_label = ""

        if selected_target_data_str == f"ÎœÎ­ÏƒÎ¿Ï‚ ÎŒÏÎ¿Ï‚ {index_name} (mg/mÂ³)":
            if not df_avg_mg.empty:
                df_analysis = df_avg_mg.copy()
                current_target_label = f"ÎœÎ­ÏƒÎ¿Ï‚ ÎŒÏÎ¿Ï‚ {index_name} (mg/mÂ³)"
        elif selected_target_data_str == "Î£Ï„Î¬Î¸Î¼Î· Î›Î¯Î¼Î½Î·Ï‚ (m)":
            if not df_h.empty:
                df_analysis = df_h.rename(columns={'Height': 'Value'}).copy()
                df_analysis['Date'] = pd.to_datetime(df_analysis['Date'])
                df_analysis = df_analysis.sort_values(by='Date').set_index('Date')
                current_target_label = "Î£Ï„Î¬Î¸Î¼Î· Î›Î¯Î¼Î½Î·Ï‚ (m)"
        elif selected_target_data_str == "Î£Ï…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿ Î£Î·Î¼ÎµÎ¯Î¿ Î”ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î±Ï‚" and selected_specific_point:
            if selected_specific_point in results_mg and results_mg[selected_specific_point]:
                point_data = results_mg[selected_specific_point]
                df_analysis = pd.DataFrame(point_data, columns=['Date', 'Value'])
                df_analysis['Date'] = pd.to_datetime(df_analysis['Date'])
                df_analysis = df_analysis.sort_values(by='Date').set_index('Date')
                current_target_label = f"Î£Î·Î¼ÎµÎ¯Î¿: {selected_specific_point} ({index_name} mg/mÂ³)"
        
        _debug_ai(f"AI - df_analysis BEFORE dropna for '{current_target_label}'", df_analysis)

        if not df_analysis.empty and 'Value' in df_analysis.columns:
            df_analysis.dropna(subset=['Value'], inplace=True)
            _debug_ai(f"AI - df_analysis AFTER dropna for '{current_target_label}'", df_analysis)
            
            if len(df_analysis) < 10: # Î•Î»Î¬Ï‡Î¹ÏƒÏ„Î¿ ÏŒÏÎ¹Î¿ Î³Î¹Î± Ï„Î¹Ï‚ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎµÏ‚ Î±Î½Î±Î»ÏÏƒÎµÎ¹Ï‚ AI
                 st.warning(f"Î— ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î· Ï‡ÏÎ¿Î½Î¿ÏƒÎµÎ¹ÏÎ¬ ('{current_target_label if current_target_label else selected_target_data_str}') Î­Ï‡ÎµÎ¹ {len(df_analysis)} Î­Î³ÎºÏ…ÏÎ± ÏƒÎ·Î¼ÎµÎ¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î¼ÎµÏ„Î¬ Ï„Î·Î½ Î±Ï†Î±Î¯ÏÎµÏƒÎ· NaN. Î¤Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± AI ÎµÎ½Î´Î­Ï‡ÎµÏ„Î±Î¹ Î½Î± Î¼Î·Î½ ÎµÎ¯Î½Î±Î¹ Î±Î¾Î¹ÏŒÏ€Î¹ÏƒÏ„Î± Î® Î´Ï…Î½Î±Ï„Î¬.")
            
            st.subheader("Î•Ï€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ· Î•Ï€Î¹Î»ÎµÎ³Î¼Î­Î½Î·Ï‚ Î§ÏÎ¿Î½Î¿ÏƒÎµÎ¹ÏÎ¬Ï‚")
            if not df_analysis.empty:
                fig_selected_ts = px.line(df_analysis.reset_index(), x='Date', y='Value', title=f"Î§ÏÎ¿Î½Î¿ÏƒÎµÎ¹ÏÎ¬: {current_target_label if current_target_label else selected_target_data_str}")
                st.plotly_chart(fig_selected_ts, use_container_width=True)
            else:
                st.info(f"Î— Ï‡ÏÎ¿Î½Î¿ÏƒÎµÎ¹ÏÎ¬ '{current_target_label if current_target_label else selected_target_data_str}' ÎµÎ¯Î½Î±Î¹ ÎºÎµÎ½Î® Î¼ÎµÏ„Î¬ Ï„Î·Î½ Î±Ï†Î±Î¯ÏÎµÏƒÎ· Î¼Î· Î­Î³ÎºÏ…ÏÏ‰Î½ Ï„Î¹Î¼ÏÎ½.")

        elif selected_target_data_str != "Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î”ÎµÎ´Î¿Î¼Î­Î½Î±..." and selected_ai_task != "Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î•ÏÎ³Î±ÏƒÎ¯Î± AI...":
             st.info(f"Î Î±ÏÎ±ÎºÎ±Î»Ï ÎµÏ€Î¹Î»Î­Î¾Ï„Îµ Î­Î³ÎºÏ…ÏÎ· Ï‡ÏÎ¿Î½Î¿ÏƒÎµÎ¹ÏÎ¬ Î³Î¹Î± Î±Î½Î¬Î»Ï…ÏƒÎ· AI. Î— Ï„ÏÎ­Ï‡Î¿Ï…ÏƒÎ± ÎµÏ€Î¹Î»Î¿Î³Î® ('{selected_target_data_str}') Î´ÎµÎ½ Ï€Î±ÏÎ®Î³Î±Î³Îµ Î´ÎµÎ´Î¿Î¼Î­Î½Î±.")
        
        _debug_ai("AI - Final df_analysis to be used for AI", df_analysis)

        # --- Î’Î—ÎœÎ‘ 4: Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Ï„Î·Ï‚ Î•Ï€Î¹Î»ÎµÎ³Î¼Î­Î½Î·Ï‚ Î•ÏÎ³Î±ÏƒÎ¯Î±Ï‚ AI ---
        execute_ai_condition = (
            not df_analysis.empty and 
            'Value' in df_analysis.columns and 
            len(df_analysis) >= 10 and 
            selected_ai_task != "Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î•ÏÎ³Î±ÏƒÎ¯Î± AI..."
        )
        _debug_ai("AI - Condition to execute AI block", execute_ai_condition)

        if execute_ai_condition:
            # Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ Ï€Î¹Î¿ ÏƒÏ„Î±Î¸ÎµÏÎ¬ ÎºÎ»ÎµÎ¹Î´Î¹Î¬ Î³Î¹Î± Ï„Î± widgets, Î±Ï€Î¿Ï†ÎµÏÎ³Î¿Î½Ï„Î±Ï‚ Ï„Î¿ timestamp Î±Î½ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Î¿ Î³Î¹Î± Î¼Î¿Î½Î±Î´Î¹ÎºÏŒÏ„Î·Ï„Î± ÎµÎ½Ï„ÏŒÏ‚ Ï„Î·Ï‚ Î¯Î´Î¹Î±Ï‚ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚
            base_key_prefix_ai = f"ai_{waterbody}_{index_name}_{selected_target_data_str.replace(' ','_').replace('/','_').replace('(','').replace(')','').replace(':','_')}_{selected_ai_task.replace(' ','_')}"

            if selected_ai_task == "Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ Î‘Î½Ï‰Î¼Î±Î»Î¹ÏÎ½ (Î§ÏÎ¿Î½Î¿ÏƒÎµÎ¹ÏÎ­Ï‚)":
                _debug_ai("AI - Entering Anomaly Detection UI Block", True)
                st.subheader("Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼Î¿Ï Î‘Î½Ï‰Î¼Î±Î»Î¹ÏÎ½")
                contamination_rate = st.slider("Î•Ï…Î±Î¹ÏƒÎ¸Î·ÏƒÎ¯Î± Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼Î¿Ï (contamination):", 0.01, 0.25, 0.05, 0.01, help="Î¤Î¿ Î±Î½Î±Î¼ÎµÎ½ÏŒÎ¼ÎµÎ½Î¿ Ï€Î¿ÏƒÎ¿ÏƒÏ„ÏŒ Î±Î½Ï‰Î¼Î±Î»Î¹ÏÎ½ ÏƒÏ„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±. ÎœÎ¹ÎºÏÏŒÏ„ÎµÏÎ· Ï„Î¹Î¼Î® ÏƒÎ·Î¼Î±Î¯Î½ÎµÎ¹ Î»Î¹Î³ÏŒÏ„ÎµÏÎµÏ‚, Ï€Î¹Î¿ Î±ÎºÏÎ±Î¯ÎµÏ‚ Î±Î½Ï‰Î¼Î±Î»Î¯ÎµÏ‚.", key=f"anomaly_contamination_{base_key_prefix_ai}")
                
                if st.button("Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼Î¿Ï Î‘Î½Ï‰Î¼Î±Î»Î¹ÏÎ½", key=f"run_anomaly_detection_{base_key_prefix_ai}"):
                    _debug_ai("AI - Anomaly Detection Button Clicked", True)
                    with st.spinner("Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ Î±Î½Ï‰Î¼Î±Î»Î¹ÏÎ½..."):
                        try:
                            model_if = IsolationForest(contamination=contamination_rate, random_state=42, n_estimators=100)
                            df_analysis_copy = df_analysis.copy() # Î”Î¿Ï…Î»ÎµÏÎ¿Ï…Î¼Îµ ÏƒÎµ Î±Î½Ï„Î¯Î³ÏÎ±Ï†Î¿ Î³Î¹Î± Î½Î± Î¼Î·Î½ Î±Î»Î»Î¬Î¾Î¿Ï…Î¼Îµ Ï„Î¿ Î±ÏÏ‡Î¹ÎºÏŒ df_analysis
                            df_analysis_copy['Anomaly_IF'] = model_if.fit_predict(df_analysis_copy[['Value']])
                            anomalies = df_analysis_copy[df_analysis_copy['Anomaly_IF'] == -1]
                            _debug_ai("AI - Anomaly Detection - Anomalies Found", anomalies)
                            
                            fig_anomalies = px.line(df_analysis_copy.reset_index(), x='Date', y='Value', title=f"Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ Î‘Î½Ï‰Î¼Î±Î»Î¹ÏÎ½: {current_target_label}")
                            if not anomalies.empty:
                                fig_anomalies.add_trace(go.Scatter(x=anomalies.index, y=anomalies['Value'], mode='markers',
                                                                marker=dict(color='red', size=10, symbol='x'), name='Î‘Î½Ï‰Î¼Î±Î»Î¯ÎµÏ‚'))
                                st.write(f"Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(anomalies)} Ï€Î¹Î¸Î±Î½Î­Ï‚ Î±Î½Ï‰Î¼Î±Î»Î¯ÎµÏ‚.")
                                st.dataframe(anomalies.reset_index()[['Date', 'Value']])
                                add_excel_download_button(anomalies.reset_index()[['Date', 'Value']], f"{waterbody}_{index_name}_anomalies", f"Anomalies_{current_target_label.replace(':','_').replace('/','_')}", f"excel_anomalies_{base_key_prefix_ai}")
                            else:
                                st.success("Î”ÎµÎ½ ÎµÎ½Ï„Î¿Ï€Î¯ÏƒÏ„Î·ÎºÎ±Î½ Î±Î½Ï‰Î¼Î±Î»Î¯ÎµÏ‚ Î¼Îµ Ï„Î¹Ï‚ Ï„ÏÎ­Ï‡Î¿Ï…ÏƒÎµÏ‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚.")
                            st.plotly_chart(fig_anomalies, use_container_width=True)
                        except Exception as e:
                            st.error(f"Î Î±ÏÎ¿Ï…ÏƒÎ¹Î¬ÏƒÏ„Î·ÎºÎµ ÏƒÏ†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î¿Î½ ÎµÎ½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒ Î±Î½Ï‰Î¼Î±Î»Î¹ÏÎ½: {e}")
                            st.error("Î’ÎµÎ²Î±Î¹Ï‰Î¸ÎµÎ¯Ï„Îµ ÏŒÏ„Î¹ Î· Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ· scikit-learn ÎµÎ¯Î½Î±Î¹ ÎµÎ³ÎºÎ±Ï„ÎµÏƒÏ„Î·Î¼Î­Î½Î· ÎºÎ±Î¹ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÎµÎ¯Î½Î±Î¹ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î±.")

            elif selected_ai_task == "Î ÏÏŒÎ²Î»ÎµÏˆÎ· Î§ÏÎ¿Î½Î¿ÏƒÎµÎ¹ÏÏÎ½":
                _debug_ai("AI - Entering Forecasting UI Block", True)
                st.subheader("Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î ÏÏŒÎ²Î»ÎµÏˆÎ·Ï‚ Î§ÏÎ¿Î½Î¿ÏƒÎµÎ¹ÏÏÎ½")
                if len(df_analysis) < 5: 
                     st.warning(f"Î Î¿Î»Ï Î»Î¯Î³Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ({len(df_analysis)} ÏƒÎ·Î¼ÎµÎ¯Î±) Î³Î¹Î± Î±Î¾Î¹ÏŒÏ€Î¹ÏƒÏ„Î· Ï€ÏÏŒÎ²Î»ÎµÏˆÎ· Î¼Îµ Prophet.")
                else:
                    forecast_periods = st.number_input("Î ÎµÏÎ¯Î¿Î´Î¿Î¹ Î ÏÏŒÎ²Î»ÎµÏˆÎ·Ï‚ (Ï€.Ï‡., Î·Î¼Î­ÏÎµÏ‚):", min_value=1, max_value=365, value=30, key=f"forecast_periods_{base_key_prefix_ai}")
                    
                    if st.button("Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Î ÏÏŒÎ²Î»ÎµÏˆÎ·Ï‚", key=f"run_forecasting_{base_key_prefix_ai}"):
                        _debug_ai("AI - Forecasting Button Clicked", True)
                        with st.spinner("Î“Î¯Î½ÎµÏ„Î±Î¹ Ï€ÏÏŒÎ²Î»ÎµÏˆÎ·..."):
                            try:
                                df_prophet = df_analysis.reset_index().rename(columns={'Date': 'ds', 'Value': 'y'})
                                df_prophet.dropna(subset=['y'], inplace=True)
                                _debug_ai("AI - DataFrame for Prophet (df_prophet)", df_prophet)
                                if len(df_prophet) < 2:
                                     st.error(f"Î Î¿Î»Ï Î»Î¯Î³Î± ÏƒÎ·Î¼ÎµÎ¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ({len(df_prophet)}) Î³Î¹Î± Ï„Î·Î½ Prophet Î¼ÎµÏ„Î¬ Ï„Î·Î½ Î±Ï†Î±Î¯ÏÎµÏƒÎ· NaNs Î±Ï€ÏŒ Ï„Î¹Ï‚ Ï„Î¹Î¼Î­Ï‚ 'y'.")
                                else:
                                    model_prophet = Prophet()
                                    model_prophet.fit(df_prophet)
                                    future = model_prophet.make_future_dataframe(periods=forecast_periods)
                                    forecast = model_prophet.predict(future)
                                    _debug_ai("AI - Prophet Forecast Output (tail)", forecast.tail())
                                    
                                    # Î§ÏÎ®ÏƒÎ· make_subplots Î³Î¹Î± ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ Î­Î»ÎµÎ³Ï‡Î¿ Ï„Î¿Ï… Î¼ÎµÎ³Î­Î¸Î¿Ï…Ï‚ Ï„Î¿Ï… Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î¿Ï‚ Ï„Î·Ï‚ Prophet
                                    fig_prophet_streamlit = go.Figure()
                                    fig_prophet_streamlit.add_trace(go.Scatter(x=forecast['ds'], y=forecast['yhat'], mode='lines', name='Î ÏÏŒÎ²Î»ÎµÏˆÎ· (yhat)', line=dict(color='blue')))
                                    fig_prophet_streamlit.add_trace(go.Scatter(x=forecast['ds'], y=forecast['yhat_upper'], mode='lines', name='Î†Î½Ï‰ ÎŒÏÎ¹Î¿ CI', line=dict(color='rgba(0,114,178,0.2)')))
                                    fig_prophet_streamlit.add_trace(go.Scatter(x=forecast['ds'], y=forecast['yhat_lower'], mode='lines', name='ÎšÎ¬Ï„Ï‰ ÎŒÏÎ¹Î¿ CI', line=dict(color='rgba(0,114,178,0.2)'), fill='tonexty', fillcolor='rgba(0,114,178,0.2)'))
                                    fig_prophet_streamlit.add_trace(go.Scatter(x=df_prophet['ds'], y=df_prophet['y'], mode='markers', name='Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Î¤Î¹Î¼Î­Ï‚', marker=dict(color='black', size=5)))
                                    fig_prophet_streamlit.update_layout(title=f"Î ÏÏŒÎ²Î»ÎµÏˆÎ· Î§ÏÎ¿Î½Î¿ÏƒÎµÎ¹ÏÎ¬Ï‚ Î¼Îµ Prophet: {current_target_label}", xaxis_title="Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±", yaxis_title="Î¤Î¹Î¼Î®")
                                    st.plotly_chart(fig_prophet_streamlit, use_container_width=True)
                                    
                                    st.write("Î›ÎµÏ€Ï„Î¿Î¼Î­ÏÎµÎ¹ÎµÏ‚ Î ÏÏŒÎ²Î»ÎµÏˆÎ·Ï‚ (Prophet):")
                                    forecast_to_show = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].copy()
                                    forecast_to_show.rename(columns={'ds':'Date', 'yhat':'Predicted', 'yhat_lower':'Lower_CI', 'yhat_upper':'Upper_CI'}, inplace=True)
                                    st.dataframe(forecast_to_show.tail(forecast_periods))
                                    add_excel_download_button(forecast_to_show, f"{waterbody}_{index_name}_forecast", f"Forecast_{current_target_label.replace(':','_').replace('/','_')}", f"excel_forecast_ai_{base_key_prefix_ai}")

                            except Exception as e:
                                st.error(f"Î Î±ÏÎ¿Ï…ÏƒÎ¹Î¬ÏƒÏ„Î·ÎºÎµ ÏƒÏ†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ Ï€ÏÏŒÎ²Î»ÎµÏˆÎ·: {e}")
                                st.error("Î’ÎµÎ²Î±Î¹Ï‰Î¸ÎµÎ¯Ï„Îµ ÏŒÏ„Î¹ Î· Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ· Prophet ÎµÎ¯Î½Î±Î¹ ÎµÎ³ÎºÎ±Ï„ÎµÏƒÏ„Î·Î¼Î­Î½Î· ÎºÎ±Î¹ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÎµÎ¯Î½Î±Î¹ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î±.")
            
            elif selected_ai_task == "Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ Î£Î·Î¼ÎµÎ¯Ï‰Î½ Î‘Î»Î»Î±Î³Î®Ï‚":
                _debug_ai("AI - Entering Change Point Detection UI Block", True)
                st.subheader("Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼Î¿Ï Î£Î·Î¼ÎµÎ¯Ï‰Î½ Î‘Î»Î»Î±Î³Î®Ï‚")
                if len(df_analysis) < 3: 
                    st.warning(f"Î Î¿Î»Ï Î»Î¯Î³Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ({len(df_analysis)} ÏƒÎ·Î¼ÎµÎ¯Î±) Î³Î¹Î± ÎµÎ½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒ ÏƒÎ·Î¼ÎµÎ¯Ï‰Î½ Î±Î»Î»Î±Î³Î®Ï‚.")
                else:
                    model_rpt_options = ["L1", "L2", "Rbf", "Normal", "Rank"]
                    selected_model_rpt = st.selectbox("ÎœÎ¿Î½Ï„Î­Î»Î¿ ÎšÏŒÏƒÏ„Î¿Ï…Ï‚ (Ruptures):", model_rpt_options, index=2, key=f"rpt_model_{base_key_prefix_ai}")
                    
                    default_pen = max(1.0, np.log(len(df_analysis)) * np.nanstd(df_analysis['Value']) * 1.5 if len(df_analysis) > 1 and not np.all(np.isnan(df_analysis['Value'])) else 3.0)
                    if np.isnan(default_pen) or default_pen <= 0: default_pen = 3.0

                    pen_value = st.number_input("Î¤Î¹Î¼Î® Penalty (Ruptures):", min_value=0.1, value=float(default_pen), format="%.2f", key=f"rpt_pen_{base_key_prefix_ai}", help="ÎœÎµÎ³Î±Î»ÏÏ„ÎµÏÎ· Ï„Î¹Î¼Î® Î¿Î´Î·Î³ÎµÎ¯ ÏƒÎµ Î»Î¹Î³ÏŒÏ„ÎµÏÎ± ÏƒÎ·Î¼ÎµÎ¯Î± Î±Î»Î»Î±Î³Î®Ï‚.")

                    if st.button("Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼Î¿Ï Î£Î·Î¼ÎµÎ¯Ï‰Î½ Î‘Î»Î»Î±Î³Î®Ï‚", key=f"run_changepoint_{base_key_prefix_ai}"):
                        _debug_ai("AI - Change Point Detection Button Clicked", True)
                        with st.spinner("Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ ÏƒÎ·Î¼ÎµÎ¯Ï‰Î½ Î±Î»Î»Î±Î³Î®Ï‚..."):
                            try:
                                points_for_rpt = df_analysis['Value'].values # Î ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎµÎ¯Î½Î±Î¹ numpy array Î³Î¹Î± Ï„Î¿ ruptures
                                _debug_ai("AI - Points for Ruptures (first 10)", points_for_rpt[:10])
                                algo = rpt.Pelt(model=selected_model_rpt.lower()).fit(points_for_rpt)
                                result_bkps_indices = algo.predict(pen=pen_value) 
                                _debug_ai("AI - Ruptures - Breakpoint Indices", result_bkps_indices)
                                
                                fig_changepoints_plotly = px.line(df_analysis.reset_index(), x='Date', y='Value', title=f"Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ Î£Î·Î¼ÎµÎ¯Ï‰Î½ Î‘Î»Î»Î±Î³Î®Ï‚: {current_target_label}")
                                bkpt_dates_list = []
                                for bkpt_idx in result_bkps_indices:
                                    if 0 < bkpt_idx < len(points_for_rpt):
                                        change_date = df_analysis.index[bkpt_idx-1]
                                        bkpt_dates_list.append(change_date)
                                        fig_changepoints_plotly.add_vline(x=change_date, line_width=2, line_dash="dash", line_color="red", annotation_text=f"Î‘Î»Î»Î±Î³Î® {change_date.strftime('%Y-%m-%d')}", annotation_position="top left")
                                
                                st.plotly_chart(fig_changepoints_plotly, use_container_width=True)

                                if bkpt_dates_list:
                                    st.write(f"Î•Î½Ï„Î¿Ï€Î¯ÏƒÏ„Î·ÎºÎ±Î½ {len(bkpt_dates_list)} ÏƒÎ·Î¼ÎµÎ¯Î± Î±Î»Î»Î±Î³Î®Ï‚.")
                                    df_bkpts = pd.DataFrame({'Change_Point_Date': sorted(list(set(bkpt_dates_list)))})
                                    st.dataframe(df_bkpts)
                                    add_excel_download_button(df_bkpts, f"{waterbody}_{index_name}_changepoints", f"ChangePoints_{current_target_label.replace(':','_').replace('/','_')}", f"excel_changepoints_ai_{base_key_prefix_ai}")
                                else:
                                    st.success("Î”ÎµÎ½ ÎµÎ½Ï„Î¿Ï€Î¯ÏƒÏ„Î·ÎºÎ±Î½ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÎ¬ ÏƒÎ·Î¼ÎµÎ¯Î± Î±Î»Î»Î±Î³Î®Ï‚ Î¼Îµ Ï„Î¹Ï‚ Ï„ÏÎ­Ï‡Î¿Ï…ÏƒÎµÏ‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚.")
                            except Exception as e:
                                st.error(f"Î Î±ÏÎ¿Ï…ÏƒÎ¹Î¬ÏƒÏ„Î·ÎºÎµ ÏƒÏ†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î¿Î½ ÎµÎ½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒ ÏƒÎ·Î¼ÎµÎ¯Ï‰Î½ Î±Î»Î»Î±Î³Î®Ï‚: {e}")
                                st.error("Î’ÎµÎ²Î±Î¹Ï‰Î¸ÎµÎ¯Ï„Îµ ÏŒÏ„Î¹ Î· Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ· ruptures ÎµÎ¯Î½Î±Î¹ ÎµÎ³ÎºÎ±Ï„ÎµÏƒÏ„Î·Î¼Î­Î½Î· ÎºÎ±Î¹ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÎµÎ¯Î½Î±Î¹ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î±.")
        
        elif selected_ai_task == "Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î•ÏÎ³Î±ÏƒÎ¯Î± AI..." and selected_target_data_str != "Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î”ÎµÎ´Î¿Î¼Î­Î½Î±...":
            st.info("Î Î±ÏÎ±ÎºÎ±Î»Ï ÎµÏ€Î¹Î»Î­Î¾Ï„Îµ Î¼Î¹Î± ÎµÏÎ³Î±ÏƒÎ¯Î± AI Î±Ï€ÏŒ Ï„Î·Î½ Ï€Î±ÏÎ±Ï€Î¬Î½Ï‰ Î»Î¯ÏƒÏ„Î± Î³Î¹Î± Î½Î± ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¹Î·Î¸Î¿ÏÎ½ Î¿Î¹ ÎµÏ€Î¹Î»Î¿Î³Î­Ï‚ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚.")
        
        elif selected_target_data_str != "Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î”ÎµÎ´Î¿Î¼Î­Î½Î±..." and (df_analysis.empty or 'Value' not in df_analysis.columns or len(df_analysis) < 10) :
             if df_analysis.empty or 'Value' not in df_analysis.columns :
                st.warning(f"Î— ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î· Ï‡ÏÎ¿Î½Î¿ÏƒÎµÎ¹ÏÎ¬ '{current_target_label if current_target_label else selected_target_data_str}' Î´ÎµÎ½ Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ Î­Î³ÎºÏ…ÏÎ± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± Î±Î½Î¬Î»Ï…ÏƒÎ· AI.")
             elif len(df_analysis) < 10 :
                st.warning(f"Î— ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î· Ï‡ÏÎ¿Î½Î¿ÏƒÎµÎ¹ÏÎ¬ '{current_target_label if current_target_label else selected_target_data_str}' Î­Ï‡ÎµÎ¹ Î»Î¹Î³ÏŒÏ„ÎµÏÎ± Î±Ï€ÏŒ 10 Î­Î³ÎºÏ…ÏÎ± ÏƒÎ·Î¼ÎµÎ¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ({len(df_analysis)}). Î— Î±Î½Î¬Î»Ï…ÏƒÎ· AI Î´ÎµÎ½ Î¸Î± ÎµÎºÏ„ÎµÎ»ÎµÏƒÏ„ÎµÎ¯.")

        st.markdown('</div>', unsafe_allow_html=True)

def main_app():
    inject_custom_css() 
    run_intro_page_custom() 
    run_custom_sidebar_ui_custom() 

    selected_wb = st.session_state.get(SESSION_KEY_WATERBODY)
    selected_idx = st.session_state.get(SESSION_KEY_INDEX)
    selected_an = st.session_state.get(SESSION_KEY_ANALYSIS)

    if not all([selected_wb, selected_idx, selected_an]):
        render_footer() 
        return 

    if selected_wb == "Î“Î±Î´Î¿Ï…ÏÎ¬" and selected_idx in ["Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·", "Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ", "Î˜Î¿Î»ÏŒÏ„Î·Ï„Î±"]:
        if selected_an == "Î•Ï€Î¹Ï†Î±Î½ÎµÎ¹Î±ÎºÎ® Î‘Ï€Î¿Ï„ÏÏ€Ï‰ÏƒÎ·":
            run_lake_processing_app(selected_wb, selected_idx)
        elif selected_an == "Î ÏÎ¿Ï†Î¯Î» Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ ÎºÎ±Î¹ ÏƒÏ„Î¬Î¸Î¼Î·Ï‚":
            run_water_quality_dashboard(selected_wb, selected_idx)
        elif selected_an == "EÏÎ³Î±Î»ÎµÎ¯Î± Î ÏÏŒÎ²Î»ÎµÏˆÎ·Ï‚ ÎºÎ±Î¹ Î­Î³ÎºÎ±Î¹ÏÎ·Ï‚ ÎµÎ½Î·Î¼Î­ÏÏ‰ÏƒÎ·Ï‚":
            run_predictive_tools(selected_wb, selected_idx)
        elif selected_an == "Î ÏÎ¿Î·Î³Î¼Î­Î½Î· Î‘Î½Î¬Î»Ï…ÏƒÎ· Î ÏÎ¿Ï„ÏÏ€Ï‰Î½ (AI)": # <--- Î— ÎÎ•Î‘ ÎšÎ›Î—Î£Î—
            run_ai_driven_analysis(selected_wb, selected_idx)
    else:
        st.warning(f"Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼ÎµÏ‚ Î±Î½Î±Î»ÏÏƒÎµÎ¹Ï‚ Î® Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± Ï„Î¿Î½ ÏƒÏ…Î½Î´Ï…Î±ÏƒÎ¼ÏŒ: "
                   f"Î¥Î´Î¬Ï„Î¹Î½Î¿ Î£ÏÎ¼Î± '{selected_wb}' ÎºÎ±Î¹ Î”ÎµÎ¯ÎºÏ„Î·Ï‚ '{selected_idx}'. "
                   f"Î Î±ÏÎ±ÎºÎ±Î»Ï Î´Î¿ÎºÎ¹Î¼Î¬ÏƒÏ„Îµ Î­Î½Î±Î½ Î¬Î»Î»Î¿ ÏƒÏ…Î½Î´Ï…Î±ÏƒÎ¼ÏŒ.")
    
    render_footer() 

if __name__ == "__main__":
    # --- RENDER LOGIN UI ---
    # The authenticator.login() method will render the login form,
    # process login attempts, and update st.session_state.
    authenticator.login('main') # You can use 'sidebar' instead of 'main'

    # Check authentication status from st.session_state
    # Use .get() for safer access to session_state keys
    auth_status = st.session_state.get("authentication_status")

    if auth_status: # Checks if True
        # If user is authenticated, run the main application
        main_app()
    elif auth_status is False: # Explicitly checks for False
        st.error('Î¤Î¿ ÏŒÎ½Î¿Î¼Î± Ï‡ÏÎ®ÏƒÏ„Î· Î® Î¿ ÎºÏ‰Î´Î¹ÎºÏŒÏ‚ Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ·Ï‚ ÎµÎ¯Î½Î±Î¹ Î»Î±Î½Î¸Î±ÏƒÎ¼Î­Î½Î¿Ï‚ (Username/password is incorrect)')
    elif auth_status is None: # Explicitly checks for None (before first login attempt)
        st.warning('Î Î±ÏÎ±ÎºÎ±Î»Ï ÎµÎ¹ÏƒÎ¬Î³ÎµÏ„Îµ Ï„Î¿ ÏŒÎ½Î¿Î¼Î± Ï‡ÏÎ®ÏƒÏ„Î· ÎºÎ±Î¹ Ï„Î¿Î½ ÎºÏ‰Î´Î¹ÎºÏŒ Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ®Ï‚ ÏƒÎ±Ï‚ (Please enter your username and password)')

    # Optional: Add a small footer that's always visible, even on login page
    # if not st.session_state.get("authentication_status"): # Check if not logged in
    #    current_year = datetime.now().year
    #    st.markdown(f"<div style='text-align:center; padding:10px; position:fixed; bottom:0; width:100%; background: #161b22; color: #7a828e;'>Â© {current_year} EYATH SA</div>", unsafe_allow_html=True)