#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Water Quality App (Enterprise-Grade UI)
-----------------------------------------
Œ¶ŒπŒªŒπŒ∫œå, ŒµœÄŒ±Œ≥Œ≥ŒµŒªŒºŒ±œÑŒπŒ∫œå œÄŒµœÅŒπŒ≤Œ¨ŒªŒªŒøŒΩ Œ±ŒΩŒ¨ŒªœÖœÉŒ∑œÇ Œ¥ŒøœÅœÖœÜŒøœÅŒπŒ∫œéŒΩ Œ¥ŒµŒ¥ŒøŒºŒ≠ŒΩœâŒΩ œÖŒ¥Œ¨œÑœâŒΩ.
"""

import os
import glob
import re
from datetime import datetime, date
import xml.etree.ElementTree as ET
import io

import numpy as np
import pandas as pd
import rasterio
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

from rasterio.errors import NotGeoreferencedWarning
import warnings
warnings.filterwarnings("ignore", category=NotGeoreferencedWarning)

import matplotlib.pyplot as plt
import matplotlib.colors as mcolors

import streamlit_authenticator as stauth # <--- Œ†œÅŒøœÉŒ∏ŒÆŒ∫Œ∑ Œ≥ŒπŒ± Œ±œÖŒ∏ŒµŒΩœÑŒπŒ∫ŒøœÄŒøŒØŒ∑œÉŒ∑

# --- PAGE CONFIGURATION (MUST BE THE FIRST STREAMLIT COMMAND) ---
st.set_page_config(layout="wide", page_title="ŒëŒΩŒ¨ŒªœÖœÉŒ∑ Œ†ŒøŒπœåœÑŒ∑œÑŒ±œÇ ŒïœÄŒπœÜŒ±ŒΩŒµŒπŒ±Œ∫œéŒΩ Œ•Œ¥Œ¨œÑœâŒΩ Œ§Œ±ŒºŒπŒµœÖœÑŒÆœÅœâŒΩ ŒïŒ•ŒëŒò ŒëŒï", page_icon="üíß")
# --------------------------------------------------------------------

# --- AUTHENTICATION SETUP ---

# --- STEP 1: Temporarily uncomment the following lines to generate your REAL hashed passwords. ---
# --- After running ONCE and copying the output, COMMENT THEM OUT AGAIN or DELETE THEM. ---
# --- Make sure 'streamlit' (st) and 'streamlit_authenticator' (stauth) are imported above. ---
# =======================================================================================
# import streamlit_authenticator as stauth # Already imported above
# import streamlit as st              # Already imported above

# # CHOOSE YOUR ACTUAL PASSWORDS HERE (MAKE SURE THEY ARE STRONG):
# passwords_for_users = ['your_actual_password_for_jsmith', 'your_actual_password_for_jdoe'] 
# # Example: passwords_for_users = ['P@sswordJS123!', 'P@sswordJD456$'] # Use your own strong passwords

# hashed_passwords_for_script = stauth.Hasher(passwords_for_users).generate()
# st.write("--- IMPORTANT: HASHED PASSWORD GENERATION (Temporary) ---")
# st.write("1. Copy this entire list (including the square brackets and quotes).")
# st.write("2. Paste it to replace the 'hashed_passwords_list' variable below (in STEP 3).")
# st.write("3. After pasting, comment out or delete this entire 'STEP 1' debug block.")
# st.write("4. Re-run the Streamlit app with STEP 1 commented out.")
# st.write("Generated Hashes:", hashed_passwords_for_script)
# st.stop() # Stops the app here after printing, so you can copy the hashes
# =======================================================================================

# --- STEP 2: Define your users and their credentials ---
names = ["John Smith", "Jane Doe"]  # Display names for your users
usernames = ["jsmith", "jdoe"]      # Usernames for login

# --- STEP 3: PASTE THE REAL HASHED PASSWORDS YOU GENERATED FROM STEP 1 HERE. ---
# It MUST be a list of strings, where each string is a valid bcrypt hash.
# For example, if Step 1 printed: ['$2b$12$A1bC2dE3fG...', '$2b$12$H4iJ5kL6mN...']
# Then this line should look like:
# hashed_passwords_list = ['$2b$12$A1bC2dE3fG...', '$2b$12$H4iJ5kL6mN...']
#
# **** YOU MUST REPLACE THESE PLACEHOLDERS WITH YOUR ACTUAL GENERATED HASHES ****
# **** AFTER FOLLOWING STEP 1 AND STEP 2 ABOVE ****
hashed_passwords_list = [
    '$2b$12$REPLACE_THIS_WITH_YOUR_FIRST_ACTUAL_HASH_XXXXXXX', # REPLACE THIS WITH YOUR FIRST ACTUAL HASH
    '$2b$12$REPLACE_THIS_WITH_YOUR_SECOND_ACTUAL_HASH_YYYYYY' # REPLACE THIS WITH YOUR SECOND ACTUAL HASH
]

# --- Create credentials dictionary ---
credentials = {"usernames": {}}
if len(names) == len(usernames) == len(hashed_passwords_list): # Basic check
    for i in range(len(usernames)):
        credentials["usernames"][usernames[i]] = {
            "name": names[i],
            "password": hashed_passwords_list[i]
        }
else:
    st.error("Error: The lists for names, usernames, and hashed_passwords_list must have the same number of items.")
    st.error("Please ensure you have defined users and pasted the correct number of hashed passwords.")
    st.stop()

# --- Optional Debugging: Uncomment if you still face issues after pasting real hashes ---
# st.write("--- Debug: Initial Credential Data (Post-User-Update) ---")
# st.write(f"Names (type: {type(names)}): {names}")
# st.write(f"Usernames (type: {type(usernames)}): {usernames}")
# st.write(f"Hashed Passwords List (type: {type(hashed_passwords_list)}): {hashed_passwords_list}")
# st.write(f"Constructed credentials dictionary: {credentials}")
# st.write("--- End Debug: Initial Credential Data ---")

# --- STEP 4: Initialize the Authenticator ---
authenticator = None # Initialize to None in case of error below
try:
    authenticator = stauth.Authenticate(
        credentials,
        "water_quality_app_cookie_v5",      # Changed cookie name slightly for freshness
        "a_very_random_secret_key_v5",  # Changed key slightly for freshness
        cookie_expiry_days=30,
    )
except Exception as e:
    st.error(f"Error during stauth.Authenticate initialization: {e}")
    st.error("This often happens if the 'credentials' dictionary is malformed or password hashes are not valid bcrypt hashes.")
    st.error("Please double-check STEP 3 and ensure you have pasted valid hashes generated from STEP 1.")
    st.stop()

# --- Optional Debugging: Uncomment if you still face issues after pasting real hashes ---
# st.write("--- Debug: Authenticator Object Inspection (Post-User-Update) ---")
# st.write(f"Authenticator object after initialization: {authenticator}")
# if authenticator:
#     if hasattr(authenticator, 'credentials'):
#         st.write(f"Authenticator.credentials (internal): {authenticator.credentials}")
#     else:
#         st.write("Authenticator object does NOT have a 'credentials' attribute after init.")
# 
#     if hasattr(authenticator, 'key'):
#         st.write(f"Authenticator.key (signature key internal): {authenticator.key}")
#     else:
#         st.write("Authenticator object does NOT have a 'key' attribute after init.")
# else:
#     st.write("Authenticator object is None after initialization attempt.")
# st.write("--- End Debug: Authenticator Object Inspection ---")
# --- END OF AUTHENTICATION SETUP ---


# --- Global Configuration & Constants ---
DEBUG = False
APP_BASE_DIR = os.path.dirname(os.path.abspath(__file__)) if "__file__" in locals() else os.getcwd()
LOGO_PATH = os.path.join(APP_BASE_DIR, "logo.jpg")

WATERBODY_FOLDERS = {
    "ŒìŒ±Œ¥ŒøœÖœÅŒ¨": "Gadoura",
}

SESSION_KEY_WATERBODY = "waterbody_choice_main"
SESSION_KEY_INDEX = "index_choice_main"
SESSION_KEY_ANALYSIS = "analysis_choice_main"
SESSION_KEY_DEFAULT_RESULTS_DASHBOARD = "dashboard_default_sampling_results"
SESSION_KEY_UPLOAD_RESULTS_DASHBOARD = "dashboard_upload_sampling_results"
SESSION_KEY_CURRENT_IMAGE_INDEX_DASH_DEF = "dash_def_current_image_idx"
SESSION_KEY_CURRENT_IMAGE_INDEX_DASH_UPL = "dash_upl_current_image_idx"

def debug_message(*args, **kwargs):
    if DEBUG:
        with st.expander("Debug Messages", expanded=False):
            st.write(*args, **kwargs)

def inject_custom_css():
    custom_css = """
    <link href="https://fonts.googleapis.com/css?family=Roboto:400,500,700&display=swap" rel="stylesheet">
    <style>
        html, body, [class*="css"] { font-family: 'Roboto', sans-serif; }
        .block-container { background: #161b22; color: #e0e0e0; padding: 1.2rem; }
        .stSidebar > div:first-child { background: #23272f; border-right: 1px solid #3a3f47; }
        .card {
            background: #1a1a1d; padding: 2rem 2.5rem; border-radius: 16px;
            box-shadow: 0 4px 16px rgba(0,0,0,0.25); margin-bottom: 2rem;
            animation: fadein 1.0s ease-in-out;
        }
        @keyframes fadein {
            0% {opacity:0; transform: translateY(10px);}
            100%{opacity:1; transform: translateY(0px);}
        }
        .header-title {
            color: #ffd600; margin-bottom: 1.5rem; font-size: 2.2rem;
            text-align: center; letter-spacing: 0.5px; font-weight: 700;
        }
        .nav-section {
            padding: 1rem 1.2rem; background: #2c2f36; border-radius: 10px;
            margin-bottom: 1.2rem; border-left: 4px solid #ffd600;
        }
        .nav-section h4 { margin: 0; color: #ffd600; font-weight: 500; font-size: 1.1rem; }
        .stButton button {
            background-color: #009688; color: #ffffff; border-radius: 8px;
            padding: 10px 22px; border: none; box-shadow: 0 3px 8px rgba(0,0,0,0.15);
            font-size: 1.05rem; transition: background-color 0.2s, box-shadow 0.2s, transform 0.2s;
            cursor: pointer;
        }
        .stButton button:hover {
            background-color: #00796b; box-shadow: 0 4px 12px rgba(0,0,0,0.2);
            transform: translateY(-1px);
        }
        .stButton button:active { background-color: #00695c; transform: translateY(0px); }
        .plotly-graph-div { border: 1px solid #2a2e37; border-radius: 10px; }
        .footer {
            text-align:center; color: #7a828e; font-size:0.85rem;
            padding: 2rem 0 0.5rem 0; border-top: 1px solid #2a2e37;
        }
        .footer a { color: #009688; text-decoration: none; }
        .footer a:hover { text-decoration: underline; }
    </style>
    """
    st.markdown(custom_css, unsafe_allow_html=True)

def add_excel_download_button(df_or_dict_of_dfs, filename_prefix: str, button_label_suffix: str, plot_key: str):
    if df_or_dict_of_dfs is None:
        debug_message(f"No data provided for Excel export: {button_label_suffix}")
        return

    is_empty_df = isinstance(df_or_dict_of_dfs, pd.DataFrame) and df_or_dict_of_dfs.empty
    is_empty_dict = False
    if isinstance(df_or_dict_of_dfs, dict):
        if not df_or_dict_of_dfs:
            is_empty_dict = True
        else:
            all_dfs_in_dict_empty = True
            for df_item in df_or_dict_of_dfs.values():
                if isinstance(df_item, pd.DataFrame) and not df_item.empty:
                    all_dfs_in_dict_empty = False
                    break
            if all_dfs_in_dict_empty:
                is_empty_dict = True

    if is_empty_df or is_empty_dict:
        debug_message(f"Empty data provided for Excel export: {button_label_suffix}")
        return

    output = io.BytesIO()
    try:
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            if isinstance(df_or_dict_of_dfs, pd.DataFrame):
                df_or_dict_of_dfs.to_excel(writer, index=False, sheet_name='Data')
            elif isinstance(df_or_dict_of_dfs, dict):
                for sheet_name, data_df in df_or_dict_of_dfs.items():
                    if isinstance(data_df, pd.DataFrame) and not data_df.empty:
                        sane_sheet_name = re.sub(r'[\[\]\*\/\\?\:\']', '_', str(sheet_name))[:31]
                        data_df.to_excel(writer, index=False, sheet_name=sane_sheet_name)
                    elif isinstance(data_df, pd.DataFrame) and data_df.empty:
                        debug_message(f"Empty DataFrame for sheet '{sheet_name}' in Excel export: {button_label_suffix}")
        excel_data = output.getvalue()
        if not excel_data:
            debug_message(f"No data written to Excel buffer for: {button_label_suffix}")
            return

        file_name_suffix = button_label_suffix.lower().replace(' ', '_').replace('/', '_').replace('&', 'and').replace('(', '').replace(')', '')
        st.download_button(
            label=f"üì• Save {button_label_suffix} to Excel",
            data=excel_data,
            file_name=f"{filename_prefix}_{file_name_suffix}.xlsx",
            mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            key=f"download_{plot_key}"
        )
    except Exception as e:
        st.warning(f"Could not generate Excel file for {button_label_suffix}: {e}")
        debug_message(f"Excel generation error for {button_label_suffix}: {e}")

def render_footer():
    st.markdown(f"""
        <hr style="border-color: #2a2e37;">
        <div class='footer'>
            ¬© {datetime.now().year} EYATH SA ‚Ä¢ Powered by Google Gemini & Streamlit | Contact: <a href='mailto:ilioumbas@eyath.gr'>ilioumbas@eyath.gr</a>
        </div>
    """, unsafe_allow_html=True)

def run_intro_page_custom():
    with st.container():
        st.markdown('<div class="card">', unsafe_allow_html=True)
        col_logo, col_text = st.columns([0.3, 0.7], gap="large")
        with col_logo:
            if os.path.exists(LOGO_PATH):
                st.image(LOGO_PATH, width=240, output_format="auto")
            else:
                st.markdown("üíß", help="ŒõŒøŒ≥œåœÑœÖœÄŒø ŒïŒ•ŒëŒò")
        with col_text:
            user_name_display = st.session_state.get("name", "ŒïœÄŒπœÉŒ∫Œ≠œÄœÑŒ∑")
            st.markdown(f"""
                <h2 class='header-title'>ŒïœÜŒ±œÅŒºŒøŒ≥ŒÆ ŒëŒΩŒ¨ŒªœÖœÉŒ∑œÇ Œ†ŒøŒπœåœÑŒ∑œÑŒ±œÇ ŒïœÄŒπœÜŒ±ŒΩŒµŒπŒ±Œ∫œéŒΩ Œ•Œ¥Œ¨œÑœâŒΩ Œ§Œ±ŒºŒπŒµœÖœÑŒÆœÅœâŒΩ ŒïŒ•ŒëŒò ŒëŒï</h2>
                <p style='font-size:1.15rem;text-align:center; line-height:1.6;'>
                ŒöŒ±ŒªœâœÉŒÆœÅŒ∏Œ±œÑŒµ, <strong>{user_name_display}</strong>!<br>
                ŒïŒæŒµœÅŒµœÖŒΩŒÆœÉœÑŒµ œÑŒ± Œ¥ŒµŒ¥ŒøŒºŒ≠ŒΩŒ± œÄŒøŒπœåœÑŒ∑œÑŒ±œÇ ŒºŒµ ŒµœÖŒ∫ŒøŒªŒØŒ±.<br>
                ŒïœÄŒπŒªŒ≠ŒæœÑŒµ œÑŒπ Œ∏Œ≠ŒªŒµœÑŒµ ŒΩŒ± Œ¥ŒµŒØœÑŒµ Œ±œÄœå œÑŒø œÄŒªŒ¨Œπ œÄŒ±œÅŒ¨Œ≥ŒøŒΩœÑŒ±œÇ Œ¥œÖŒΩŒ±ŒºŒπŒ∫Œ¨, Œ¥ŒπŒ±Œ¥œÅŒ±œÉœÑŒπŒ∫Œ¨ Œ≥œÅŒ±œÜŒÆŒºŒ±œÑŒ±
                </p>
                """, unsafe_allow_html=True)
        with st.expander("üî∞ ŒüŒ¥Œ∑Œ≥ŒØŒµœÇ ŒßœÅŒÆœÉŒ∑œÇ", expanded=False):
            st.markdown("""
                - **ŒïœÄŒπŒªŒøŒ≥ŒÆ Œ†Œ±œÅŒ±ŒºŒ≠œÑœÅœâŒΩ:** Œ£œÑŒ∑ŒΩ œÄŒªŒ±œäŒΩŒÆ ŒºœÄŒ¨œÅŒ± (Œ±œÅŒπœÉœÑŒµœÅŒ¨), ŒµœÄŒπŒªŒ≠ŒæœÑŒµ œÑŒø œÖŒ¥Œ¨œÑŒπŒΩŒø œÉœéŒºŒ±, œÑŒøŒΩ Œ¥ŒµŒØŒ∫œÑŒ∑ œÄŒøŒπœåœÑŒ∑œÑŒ±œÇ Œ∫Œ±Œπ œÑŒø ŒµŒØŒ¥ŒøœÇ œÑŒ∑œÇ Œ±ŒΩŒ¨ŒªœÖœÉŒ∑œÇ œÄŒøœÖ ŒµœÄŒπŒ∏œÖŒºŒµŒØœÑŒµ.
                - **Œ†ŒªŒøŒÆŒ≥Œ∑œÉŒ∑ œÉœÑŒ± ŒëœÄŒøœÑŒµŒªŒ≠œÉŒºŒ±œÑŒ±:** ŒúŒµœÑŒ¨ œÑŒ∑ŒΩ ŒµœÄŒπŒªŒøŒ≥ŒÆ, œÑŒ± Œ±œÄŒøœÑŒµŒªŒ≠œÉŒºŒ±œÑŒ± Œ∫Œ±Œπ œÑŒ± Œ¥ŒπŒ±Œ¥œÅŒ±œÉœÑŒπŒ∫Œ¨ Œ≥œÅŒ±œÜŒÆŒºŒ±œÑŒ± Œ∏Œ± ŒµŒºœÜŒ±ŒΩŒπœÉœÑŒøœçŒΩ œÉœÑŒ∑ŒΩ Œ∫œçœÅŒπŒ± œÄŒµœÅŒπŒøœáŒÆ. ŒßœÅŒ∑œÉŒπŒºŒøœÄŒøŒπŒÆœÉœÑŒµ œÑŒπœÇ Œ∫Œ±œÅœÑŒ≠ŒªŒµœÇ (tabs) Œ≥ŒπŒ± ŒΩŒ± Œ¥ŒµŒØœÑŒµ Œ¥ŒπŒ±œÜŒøœÅŒµœÑŒπŒ∫Œ≠œÇ ŒøœÄœÑŒπŒ∫ŒøœÄŒøŒπŒÆœÉŒµŒπœÇ.
                - **Œ†œÅŒøœÉŒ±œÅŒºŒøœÉŒºŒ≠ŒΩŒ∑ ŒîŒµŒπŒ≥ŒºŒ±œÑŒøŒªŒ∑œàŒØŒ±:** Œ£œÑŒ∑ŒΩ ŒµŒΩœåœÑŒ∑œÑŒ± "Œ†œÅŒøœÜŒØŒª œÄŒøŒπœåœÑŒ∑œÑŒ±œÇ Œ∫Œ±Œπ œÉœÑŒ¨Œ∏ŒºŒ∑œÇ", ŒºœÄŒøœÅŒµŒØœÑŒµ ŒΩŒ± Œ±ŒΩŒµŒ≤Œ¨œÉŒµœÑŒµ œÑŒø Œ¥ŒπŒ∫œå œÉŒ±œÇ Œ±œÅœáŒµŒØŒø KML Œ≥ŒπŒ± Œ±ŒΩŒ¨ŒªœÖœÉŒ∑ œÉŒµ œÉœÖŒ≥Œ∫ŒµŒ∫œÅŒπŒºŒ≠ŒΩŒ± œÉŒ∑ŒºŒµŒØŒ± ŒµŒΩŒ¥ŒπŒ±œÜŒ≠œÅŒøŒΩœÑŒøœÇ.
                - **Œ¶ŒØŒªœÑœÅŒ±:** Œ£Œµ ŒøœÅŒπœÉŒºŒ≠ŒΩŒµœÇ Œ±ŒΩŒ±ŒªœçœÉŒµŒπœÇ, Œ∏Œ± Œ≤œÅŒµŒØœÑŒµ ŒµœÄŒπœÄŒªŒ≠ŒøŒΩ œÜŒØŒªœÑœÅŒ± œÉœÑŒ∑ŒΩ œÄŒªŒ±œäŒΩŒÆ ŒºœÄŒ¨œÅŒ± (œÄ.œá., ŒµœçœÅŒøœÇ Œ∑ŒºŒµœÅŒøŒºŒ∑ŒΩŒπœéŒΩ, œÑŒπŒºŒ≠œÇ pixel) Œ≥ŒπŒ± ŒΩŒ± œÄœÅŒøœÉŒ±œÅŒºœåœÉŒµœÑŒµ œÑŒ± Œ±œÄŒøœÑŒµŒªŒ≠œÉŒºŒ±œÑŒ±.
                - **ŒïœÄŒµŒæŒ∑Œ≥ŒÆœÉŒµŒπœÇ:** ŒöŒ¨ŒΩœÑŒµ Œ∫ŒªŒπŒ∫ œÉœÑŒ± ŒµŒπŒ∫ŒøŒΩŒØŒ¥ŒπŒ± ‚ÑπÔ∏è ŒÆ œÉœÑŒ± expanders Œ≥ŒπŒ± œÄŒµœÅŒπœÉœÉœåœÑŒµœÅŒµœÇ œÄŒªŒ∑œÅŒøœÜŒøœÅŒØŒµœÇ œÉœáŒµœÑŒπŒ∫Œ¨ ŒºŒµ Œ∫Œ¨Œ∏Œµ Œ≥œÅŒ¨œÜŒ∑ŒºŒ± ŒÆ ŒµœÄŒπŒªŒøŒ≥ŒÆ.
                - **ŒëœÉœÜŒ¨ŒªŒµŒπŒ± ŒîŒµŒ¥ŒøŒºŒ≠ŒΩœâŒΩ:** ŒåŒªŒ± œÑŒ± Œ¥ŒµŒ¥ŒøŒºŒ≠ŒΩŒ± Œ∫Œ±Œπ œÑŒ± Œ±œÅœáŒµŒØŒ± œÄŒøœÖ Œ±ŒΩŒµŒ≤Œ¨Œ∂ŒµœÑŒµ ŒµœÄŒµŒæŒµœÅŒ≥Œ¨Œ∂ŒøŒΩœÑŒ±Œπ œÑŒøœÄŒπŒ∫Œ¨ œÉœÑŒøŒΩ œÄŒµœÅŒπŒ∑Œ≥Œ∑œÑŒÆ œÉŒ±œÇ Œ∫Œ±Œπ Œ¥ŒµŒΩ ŒºŒµœÑŒ±œÜŒøœÅœÑœéŒΩŒøŒΩœÑŒ±Œπ œÉŒµ ŒµŒæœâœÑŒµœÅŒπŒ∫ŒøœçœÇ Œ¥ŒπŒ±Œ∫ŒøŒºŒπœÉœÑŒ≠œÇ.
                """)
        st.markdown('</div>', unsafe_allow_html=True)

def run_custom_sidebar_ui_custom():
    global authenticator # Access the globally defined authenticator
    if authenticator and st.session_state.get("authentication_status"): # Check if authenticator is valid and user is logged in
        st.sidebar.success(f"Œ£œÖŒΩŒ¥ŒµŒ∏ŒÆŒ∫Œ±œÑŒµ œâœÇ: {st.session_state.get('name', 'N/A')}")
        authenticator.logout("ŒëœÄŒøœÉœçŒΩŒ¥ŒµœÉŒ∑", "sidebar", key='unique_logout_button_key')
        st.sidebar.markdown("<hr>", unsafe_allow_html=True)

    st.sidebar.markdown("<div class='nav-section'><h4>üõ†Ô∏è ŒïœÄŒπŒªŒøŒ≥Œ≠œÇ ŒëŒΩŒ¨ŒªœÖœÉŒ∑œÇ</h4></div>", unsafe_allow_html=True)
    st.sidebar.info("‚ùî ŒïœÄŒπŒªŒ≠ŒæœÑŒµ œÑŒπœÇ œÅœÖŒ∏ŒºŒØœÉŒµŒπœÇ œÉŒ±œÇ Œ∫Œ±Œπ œÄœÅŒøœáœâœÅŒÆœÉœÑŒµ œÉœÑŒ± Œ±œÄŒøœÑŒµŒªŒ≠œÉŒºŒ±œÑŒ±!")

    waterbody_options = list(WATERBODY_FOLDERS.keys())
    default_wb_idx = 0 if waterbody_options else None

    waterbody = st.sidebar.selectbox("üåä Œ•Œ¥Œ¨œÑŒπŒΩŒø œÉœéŒºŒ±", waterbody_options, index=default_wb_idx, key=SESSION_KEY_WATERBODY)
    index_name = st.sidebar.selectbox("üî¨ ŒîŒµŒØŒ∫œÑŒ∑œÇ", ["Œ†œÅŒ±Œ≥ŒºŒ±œÑŒπŒ∫œå", "ŒßŒªœâœÅŒøœÜœçŒªŒªŒ∑", "ŒòŒøŒªœåœÑŒ∑œÑŒ±"], key=SESSION_KEY_INDEX)
    analysis_type = st.sidebar.selectbox( "üìä ŒïŒØŒ¥ŒøœÇ ŒëŒΩŒ¨ŒªœÖœÉŒ∑œÇ",
        ["ŒïœÄŒπœÜŒ±ŒΩŒµŒπŒ±Œ∫ŒÆ ŒëœÄŒøœÑœçœÄœâœÉŒ∑", "Œ†œÅŒøœÜŒØŒª œÄŒøŒπœåœÑŒ∑œÑŒ±œÇ Œ∫Œ±Œπ œÉœÑŒ¨Œ∏ŒºŒ∑œÇ", "EœÅŒ≥Œ±ŒªŒµŒØŒ± Œ†œÅœåŒ≤ŒªŒµœàŒ∑œÇ Œ∫Œ±Œπ Œ≠Œ≥Œ∫Œ±ŒπœÅŒ∑œÇ ŒµŒΩŒ∑ŒºŒ≠œÅœâœÉŒ∑œÇ"],
        key=SESSION_KEY_ANALYSIS
    )
    st.sidebar.markdown(
        f"""<div style="padding: 0.7rem; background:#2c2f36; border-radius:8px; margin-top:1.2rem;">
        <strong>üåä Œ•Œ¥Œ¨œÑŒπŒΩŒø œÉœéŒºŒ±:</strong> {waterbody or "<i>-</i>"}<br>
        <strong>üî¨ ŒîŒµŒØŒ∫œÑŒ∑œÇ:</strong> {index_name or "<i>-</i>"}<br>
        <strong>üìä ŒëŒΩŒ¨ŒªœÖœÉŒ∑:</strong> {analysis_type or "<i>-</i>"}
        </div>""",
        unsafe_allow_html=True
    )
    st.sidebar.markdown("---")

@st.cache_data
def parse_sampling_kml(kml_source) -> list:
    try:
        if hasattr(kml_source, "seek"): kml_source.seek(0)
        tree = ET.parse(kml_source) if hasattr(kml_source, "read") else ET.parse(str(kml_source))
        root = tree.getroot()
        ns = {'kml': 'http://www.opengis.net/kml/2.2'}
        points = []
        for i_ls, ls in enumerate(root.findall('.//kml:LineString', ns)):
            coords_text_elem = ls.find('kml:coordinates', ns)
            if coords_text_elem is not None and coords_text_elem.text:
                coords = coords_text_elem.text.strip().split()
                for i_coord, coord_str in enumerate(coords):
                    try:
                        lon, lat, *_ = coord_str.split(',')
                        point_name = f"LS{i_ls+1}_P{i_coord+1}"
                        points.append((point_name, float(lon), float(lat)))
                    except ValueError: debug_message(f"Warning: KML: Œ†Œ±œÅŒ¨ŒªŒµŒπœàŒ∑ œÉœÖŒΩœÑŒµœÑŒ±Œ≥ŒºŒ≠ŒΩŒ∑œÇ '{coord_str}'")
        if not points and kml_source: # Check if kml_source was provided but no points found
                st.warning("ŒîŒµŒΩ Œ≤œÅŒ≠Œ∏Œ∑Œ∫Œ±ŒΩ œÉŒ∑ŒºŒµŒØŒ± LineString œÉœÑŒø KML.")
        return points
    except FileNotFoundError:
        debug_message(f"Œ†œÅŒøŒµŒπŒ¥ŒøœÄŒøŒØŒ∑œÉŒ∑: Œ§Œø Œ±œÅœáŒµŒØŒø KML '{kml_source}' Œ¥ŒµŒΩ Œ≤œÅŒ≠Œ∏Œ∑Œ∫Œµ.")
        return []
    except Exception as e:
        st.error(f"Œ£œÜŒ¨ŒªŒºŒ± Œ±ŒΩŒ¨ŒªœÖœÉŒ∑œÇ KML '{kml_source}': {e}")
        return []

def analyze_sampling_generic(sampling_points, first_image_data, first_transform,
                                images_folder, lake_height_path, selected_points_names,
                                lower_thresh=0, upper_thresh=255, date_min=None, date_max=None):
    results_colors = {name: [] for name, _, _ in sampling_points}
    results_mg = {name: [] for name, _, _ in sampling_points}

    if not os.path.isdir(images_folder):
        st.error(f"Œü œÜŒ¨Œ∫ŒµŒªŒøœÇ ŒµŒπŒ∫œåŒΩœâŒΩ '{images_folder}' Œ¥ŒµŒΩ Œ≤œÅŒ≠Œ∏Œ∑Œ∫Œµ."); return go.Figure(), go.Figure(), go.Figure(), go.Figure(), {}, {}, pd.DataFrame()

    for filename in sorted(os.listdir(images_folder)):
        if not filename.lower().endswith(('.tif', '.tiff')): continue
        m = re.search(r'(\d{4})[_-]?(\d{2})[_-]?(\d{2})', filename)
        if not m: continue
        try: date_obj = datetime(int(m.group(1)), int(m.group(2)), int(m.group(3)))
        except ValueError: debug_message(f"Œ†Œ±œÅŒ¨ŒªŒµŒπœàŒ∑ {filename}: ŒºŒ∑ Œ≠Œ≥Œ∫œÖœÅŒ∑ Œ∑ŒºŒµœÅŒøŒºŒ∑ŒΩŒØŒ±."); continue

        if (date_min and date_obj.date() < date_min) or \
           (date_max and date_obj.date() > date_max): continue

        try:
            with rasterio.open(os.path.join(images_folder, filename)) as src:
                if src.count < 3: debug_message(f"Œ†Œ±œÅŒ¨ŒªŒµŒπœàŒ∑ {filename}: <3 Œ∫Œ±ŒΩŒ¨ŒªŒπŒ±."); continue
                for name, lon, lat in sampling_points:
                    if name not in selected_points_names: continue
                    col, row = map(int, (~src.transform) * (lon, lat))
                    if not (0 <= col < src.width and 0 <= row < src.height): continue
                    win = rasterio.windows.Window(col,row,1,1)
                    try:
                        r,g,b = src.read(1,window=win)[0,0], src.read(2,window=win)[0,0], src.read(3,window=win)[0,0]
                        mg_val = (g / 255.0) * 2.0 # Placeholder conversion
                        results_mg[name].append((date_obj, mg_val))
                        results_colors[name].append((date_obj, (r/255., g/255., b/255.)))
                    except IndexError: debug_message(f"Œ£œÜŒ¨ŒªŒºŒ± Index pixel Œ≥ŒπŒ± {name} œÉœÑŒø {filename}.")
        except Exception as e: st.warning(f"Œ£œÜŒ¨ŒªŒºŒ± ŒµœÄŒµŒæŒµœÅŒ≥Œ±œÉŒØŒ±œÇ {filename}: {e}")

    # Ensure first_image_data is suitable for px.imshow (e.g., 3 bands, normalized)
    if first_image_data is None or first_image_data.ndim != 3 or first_image_data.shape[0] < 3:
        st.error("ŒúŒ∑ Œ≠Œ≥Œ∫œÖœÅŒ± Œ¥ŒµŒ¥ŒøŒºŒ≠ŒΩŒ± œÄœÅœéœÑŒ∑œÇ ŒµŒπŒ∫œåŒΩŒ±œÇ Œ≥ŒπŒ± ŒµŒºœÜŒ¨ŒΩŒπœÉŒ∑.")
        return go.Figure(), go.Figure(), go.Figure(), go.Figure(), {}, {}, pd.DataFrame()

    rgb_disp = first_image_data[:3, :, :].transpose((1,2,0)) # Use first 3 bands
    if rgb_disp.max() > 1.0: # Normalize if not already in 0-1 range
        rgb_disp = rgb_disp / 255.0
    rgb_disp = np.clip(rgb_disp, 0, 1)


    fig_geo = px.imshow(rgb_disp, title='ŒïŒπŒ∫œåŒΩŒ± ŒëŒΩŒ±œÜŒøœÅŒ¨œÇ & Œ£Œ∑ŒºŒµŒØŒ±'); fig_geo.update_layout(height=600, uirevision='geo')
    if first_transform: # Ensure transform is available
        for n,lon,lat in sampling_points:
            if n in selected_points_names:
                col,row = map(int, (~first_transform) * (lon,lat))
                fig_geo.add_trace(go.Scatter(x=[col],y=[row],mode='markers+text',marker=dict(color='red',size=10,symbol='x'),name=n,text=n,textposition="top right"))
    fig_geo.update_xaxes(visible=False); fig_geo.update_yaxes(visible=False,scaleanchor="x",scaleratio=1)

    df_h = pd.DataFrame(columns=['Date','Height'])
    if os.path.exists(str(lake_height_path)):
        try:
            df_h_temp = pd.read_excel(lake_height_path)
            if not df_h_temp.empty and len(df_h_temp.columns) >=2:
                df_h['Date']=pd.to_datetime(df_h_temp.iloc[:,0],errors='coerce'); df_h['Height']=pd.to_numeric(df_h_temp.iloc[:,1],errors='coerce')
                df_h.dropna(inplace=True); df_h.sort_values('Date',inplace=True)
        except Exception: df_h = pd.DataFrame(columns=['Date','Height'])

    fig_colors = make_subplots(specs=[[{"secondary_y":True}]]); pt_y_map={n:i for i,n in enumerate(selected_points_names)}
    for n_iter in selected_points_names:
        if n_iter in results_colors and results_colors[n_iter]:
            dts,cols=zip(*sorted(results_colors[n_iter],key=lambda x:x[0])) if results_colors[n_iter] else ([],[])
            c_rgb=[f"rgb({int(c[0]*255)},{int(c[1]*255)},{int(c[2]*255)})" for c in cols]
            fig_colors.add_trace(go.Scatter(x=list(dts),y=[pt_y_map.get(n_iter,-1)]*len(dts),mode='markers',marker=dict(color=c_rgb,size=10),name=n_iter),secondary_y=False)
    if not df_h.empty: fig_colors.add_trace(go.Scatter(x=df_h['Date'],y=df_h['Height'],name='Œ£œÑŒ¨Œ∏ŒºŒ∑',mode='lines',line=dict(color='blue')),secondary_y=True)
    fig_colors.update_layout(title='ŒßœÅœéŒºŒ±œÑŒ± Pixel & Œ£œÑŒ¨Œ∏ŒºŒ∑',yaxis=dict(tickmode='array',tickvals=list(pt_y_map.values()),ticktext=list(pt_y_map.keys())),yaxis2=dict(title='Œ£œÑŒ¨Œ∏ŒºŒ∑ (m)'), uirevision='colors')

    all_mg_by_d={};
    for p_name in selected_points_names:
        if p_name in results_mg:
            for d,v in results_mg[p_name]: all_mg_by_d.setdefault(d,[]).append(v)
    s_dts_mg=sorted(all_mg_by_d.keys()); mean_mg=[np.mean(all_mg_by_d[d]) for d in s_dts_mg if all_mg_by_d[d]]
    fig_mg=go.Figure();
    if s_dts_mg and mean_mg: fig_mg.add_trace(go.Scatter(x=s_dts_mg,y=mean_mg,mode='lines+markers',marker=dict(color=mean_mg,colorscale='Viridis',colorbar=dict(title='mg/m¬≥'),size=8)))
    fig_mg.update_layout(title='ŒúŒ≠œÉŒø mg/m¬≥', uirevision='mg')

    fig_dual=make_subplots(specs=[[{"secondary_y":True}]])
    if not df_h.empty: fig_dual.add_trace(go.Scatter(x=df_h['Date'],y=df_h['Height'],name='Œ£œÑŒ¨Œ∏ŒºŒ∑ ŒõŒØŒºŒΩŒ∑œÇ',mode='lines'),secondary_y=False)
    if s_dts_mg and mean_mg: fig_dual.add_trace(go.Scatter(x=s_dts_mg,y=mean_mg,name='ŒúŒ≠œÉŒø mg/m¬≥',mode='lines+markers', marker=dict(color=mean_mg, colorscale='Viridis', showscale=False)),secondary_y=True)
    fig_dual.update_layout(title='Œ£œÑŒ¨Œ∏ŒºŒ∑ & ŒúŒ≠œÉŒø mg/m¬≥', uirevision='dual',
                            yaxis=dict(title=dict(text="Œ£œÑŒ¨Œ∏ŒºŒ∑ (m)",font=dict(color="deepskyblue")), tickfont=dict(color="deepskyblue"), side='left'),
                            yaxis2=dict(title=dict(text="ŒúŒ≠œÉŒø mg/m¬≥",font=dict(color="lightgreen")), tickfont=dict(color="lightgreen"), overlaying='y', side='right'))
    return fig_geo,fig_dual,fig_colors,fig_mg,results_colors,results_mg,df_h

@st.cache_resource
def create_chl_legend_figure(orientation="horizontal", theme_bg_color=None, theme_text_color=None):
    levels = [0, 6, 12, 20, 30, 50]
    colors = ["#496FF2", "#82D35F", "#FEFD05", "#FD0004", "#8E2026", "#D97CF5"]
    cmap = mcolors.LinearSegmentedColormap.from_list("ChlLegend", list(zip(np.linspace(0, 1, len(levels)), colors)))
    norm = mcolors.Normalize(vmin=levels[0], vmax=levels[-1])

    if orientation == "horizontal":
        fig, ax = plt.subplots(figsize=(7, 1.2))
        fig.subplots_adjust(bottom=0.45, top=0.9, left=0.05, right=0.95)
        cbar_orientation = "horizontal"
    else:
        fig, ax = plt.subplots(figsize=(1.8, 6))
        fig.subplots_adjust(left=0.3, right=0.7, top=0.95, bottom=0.05)
        cbar_orientation = "vertical"

    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
    sm.set_array([])
    cbar = fig.colorbar(sm, cax=ax, orientation=cbar_orientation, ticks=levels, aspect=30 if orientation=="horizontal" else 20, shrink=0.95)

    label_text = "Œ£œÖŒ≥Œ∫Œ≠ŒΩœÑœÅœâœÉŒ∑ ŒßŒªœâœÅŒøœÜœçŒªŒªŒ∑œÇ-Œ± (mg/m¬≥)"
    tick_labels = [str(l) for l in levels]

    if orientation == "horizontal":
        ax.set_xlabel(label_text, fontsize=10)
        ax.set_xticklabels(tick_labels, fontsize=9)
    else:
        ax.set_ylabel(label_text, fontsize=10)
        ax.set_yticklabels(tick_labels, fontsize=9)

    # Apply theme colors if provided
    if theme_bg_color:
        fig.patch.set_facecolor(theme_bg_color)
        ax.set_facecolor(theme_bg_color)
    if theme_text_color:
        ax.xaxis.label.set_color(theme_text_color)
        ax.yaxis.label.set_color(theme_text_color)
        ax.tick_params(axis='x', colors=theme_text_color)
        ax.tick_params(axis='y', colors=theme_text_color)
        cbar.ax.xaxis.label.set_color(theme_text_color) # Colorbar label for x-axis
        cbar.ax.yaxis.label.set_color(theme_text_color) # Colorbar label for y-axis
        cbar.ax.tick_params(axis='x', colors=theme_text_color) # Colorbar tick labels for x-axis
        cbar.ax.tick_params(axis='y', colors=theme_text_color) # Colorbar tick labels for y-axis


    plt.tight_layout(pad=0.5)
    return fig

@st.cache_data
def get_data_folder(waterbody: str, index_name: str) -> str | None:
    waterbody_folder_name = WATERBODY_FOLDERS.get(waterbody)
    if not waterbody_folder_name:
        st.error(f"ŒîŒµŒΩ Œ≠œáŒµŒπ ŒøœÅŒπœÉœÑŒµŒØ Œ±ŒΩœÑŒπœÉœÑŒøŒØœáŒπœÉŒ∑ œÜŒ±Œ∫Œ≠ŒªŒøœÖ Œ≥ŒπŒ± œÑŒø œÖŒ¥Œ¨œÑŒπŒΩŒø œÉœéŒºŒ±: '{waterbody}'.")
        return None

    index_specific_folder = ""
    if index_name == "Œ†œÅŒ±Œ≥ŒºŒ±œÑŒπŒ∫œå":
        # Assuming a general case now, remove specific "Koroneia" logic if not needed elsewhere
        index_specific_folder = "Œ†œÅŒ±Œ≥ŒºŒ±œÑŒπŒ∫œå"
    elif index_name == "ŒßŒªœâœÅŒøœÜœçŒªŒªŒ∑":
        index_specific_folder = "Chlorophyll"
    elif index_name == "ŒòŒøŒªœåœÑŒ∑œÑŒ±":
        index_specific_folder = "ŒòŒøŒªœåœÑŒ∑œÑŒ±"
    else:
        index_specific_folder = index_name # Fallback

    data_folder = os.path.join(APP_BASE_DIR, waterbody_folder_name, index_specific_folder)
    debug_message(f"DEBUG: ŒëŒΩŒ±Œ∂ŒÆœÑŒ∑œÉŒ∑ œÜŒ±Œ∫Œ≠ŒªŒøœÖ Œ¥ŒµŒ¥ŒøŒºŒ≠ŒΩœâŒΩ: {data_folder}")

    if not os.path.exists(data_folder) or not os.path.isdir(data_folder):
        # This message is deferred to the calling function to avoid premature errors
        return None
    return data_folder

@st.cache_data
def extract_date_from_filename(filename: str) -> tuple[int | None, datetime | None]:
    basename = os.path.basename(filename)
    match = re.search(r'(\d{4})[_-]?(\d{2})[_-]?(\d{2})', basename)

    if match:
        year, month, day = map(int, match.groups())
        try:
            date_obj = datetime(year, month, day)
            day_of_year = date_obj.timetuple().tm_yday
            return day_of_year, date_obj
        except ValueError as e:
            debug_message(f"DEBUG: Œ£œÜŒ¨ŒªŒºŒ± ŒºŒµœÑŒ±œÑœÅŒøœÄŒÆœÇ Œ∑ŒºŒµœÅŒøŒºŒ∑ŒΩŒØŒ±œÇ Œ±œÄœå '{basename}': {e}")
            return None, None
    return None, None

@st.cache_data
def load_lake_shape_from_xml(xml_file_path: str, bounds: tuple = None,
                                xml_width: float = 518.0, xml_height: float = 505.0):
    debug_message(f"DEBUG: Œ¶œåœÅœÑœâœÉŒ∑ œÄŒµœÅŒπŒ≥œÅŒ¨ŒºŒºŒ±œÑŒøœÇ Œ±œÄœå: {xml_file_path}")
    try:
        tree = ET.parse(xml_file_path)
        root = tree.getroot()
        points_xml = []
        for point_elem in root.findall("point"):
            x_str, y_str = point_elem.get("x"), point_elem.get("y")
            if x_str and y_str: points_xml.append([float(x_str), float(y_str)])

        if not points_xml:
            st.warning(f"ŒîŒµŒΩ Œ≤œÅŒ≠Œ∏Œ∑Œ∫Œ±ŒΩ œÉŒ∑ŒºŒµŒØŒ± œÉœÑŒø XML: {os.path.basename(xml_file_path)}"); return None

        points_to_return = points_xml
        if bounds:
            minx, miny, maxx, maxy = bounds
            points_to_return = [[minx + (x/xml_width)*(maxx-minx), maxy - (y/xml_height)*(maxy-miny)] for x,y in points_xml]

        if points_to_return and (points_to_return[0] != points_to_return[-1]):
            points_to_return.append(points_to_return[0]) # Close the polygon

        debug_message(f"DEBUG: Œ¶ŒøœÅœÑœéŒ∏Œ∑Œ∫Œ±ŒΩ {len(points_to_return)} œÉŒ∑ŒºŒµŒØŒ± œÄŒµœÅŒπŒ≥œÅŒ¨ŒºŒºŒ±œÑŒøœÇ.")
        return {"type": "Polygon", "coordinates": [points_to_return]}
    except FileNotFoundError:
        st.error(f"Œ§Œø Œ±œÅœáŒµŒØŒø XML œÄŒµœÅŒπŒ≥œÅŒ¨ŒºŒºŒ±œÑŒøœÇ Œ¥ŒµŒΩ Œ≤œÅŒ≠Œ∏Œ∑Œ∫Œµ: {xml_file_path}"); return None
    except Exception as e:
        st.error(f"Œ£œÜŒ¨ŒªŒºŒ± œÜœåœÅœÑœâœÉŒ∑œÇ œÄŒµœÅŒπŒ≥œÅŒ¨ŒºŒºŒ±œÑŒøœÇ Œ±œÄœå {os.path.basename(xml_file_path)}: {e}"); return None

@st.cache_data
def read_image(file_path: str, lake_shape: dict = None):
    debug_message(f"DEBUG: ŒëŒΩŒ¨Œ≥ŒΩœâœÉŒ∑ ŒµŒπŒ∫œåŒΩŒ±œÇ: {file_path}")
    try:
        with rasterio.open(file_path) as src:
            img = src.read(1).astype(np.float32)
            profile = src.profile.copy(); profile.update(dtype="float32")

            if src.nodata is not None: img = np.where(img == src.nodata, np.nan, img)
            img = np.where(img == 0, np.nan, img) # Treat 0 as NaN if appropriate

            if lake_shape:
                from rasterio.features import geometry_mask
                poly_mask = geometry_mask([lake_shape], transform=src.transform, invert=True, out_shape=img.shape) # Invert=True to keep data INSIDE
                img = np.where(poly_mask, img, np.nan)
            return img, profile
    except Exception as e:
        st.warning(f"Œ†œÅŒøŒµŒπŒ¥ŒøœÄŒøŒØŒ∑œÉŒ∑: Œ£œÜŒ¨ŒªŒºŒ± Œ±ŒΩŒ¨Œ≥ŒΩœâœÉŒ∑œÇ ŒµŒπŒ∫œåŒΩŒ±œÇ {os.path.basename(file_path)}: {e}. Œ†Œ±œÅŒ±ŒªŒµŒØœÄŒµœÑŒ±Œπ."); return None, None

@st.cache_data
def load_data_for_lake_processing(input_folder: str, shapefile_name="shapefile.xml"):
    debug_message(f"DEBUG: load_data_for_lake_processing Œ≥ŒπŒ±: {input_folder}")
    if not os.path.exists(input_folder):
        st.error(f"Œü œÜŒ¨Œ∫ŒµŒªŒøœÇ ŒµŒπœÉœåŒ¥ŒøœÖ Œ¥ŒµŒΩ œÖœÄŒ¨œÅœáŒµŒπ: {input_folder}"); return None, None, None, None

    shape_file_path = next((sp for sp in [os.path.join(input_folder, shapefile_name), os.path.join(input_folder, "shapefile.txt")] if os.path.exists(sp)), None)
    if shape_file_path: debug_message(f"ŒíœÅŒ≠Œ∏Œ∑Œ∫Œµ Œ±œÅœáŒµŒØŒø œÄŒµœÅŒπŒ≥œÅŒ¨ŒºŒºŒ±œÑŒøœÇ: {shape_file_path}")

    tif_files = sorted([fp for fp in glob.glob(os.path.join(input_folder, "*.tif")) if os.path.basename(fp).lower() != "mask.tif"])
    if not tif_files:
        st.warning(f"ŒîŒµŒΩ Œ≤œÅŒ≠Œ∏Œ∑Œ∫Œ±ŒΩ GeoTIFF Œ±œÅœáŒµŒØŒ± œÉœÑŒøŒΩ œÜŒ¨Œ∫ŒµŒªŒø: {input_folder}"); return None, None, None, None

    first_profile, lake_geom = None, None
    try:
        with rasterio.open(tif_files[0]) as src_first:
            first_profile = src_first.profile.copy()
            if shape_file_path: lake_geom = load_lake_shape_from_xml(shape_file_path, bounds=src_first.bounds)
    except Exception as e:
        st.error(f"Œ£œÜŒ¨ŒªŒºŒ± œÄœÅŒøŒµœÑŒøŒπŒºŒ±œÉŒØŒ±œÇ œÜœåœÅœÑœâœÉŒ∑œÇ (œÄœÅœéœÑŒ∑ ŒµŒπŒ∫œåŒΩŒ±/shapefile): {e}"); return None, None, None, None

    images, days, dates_list = [], [], []
    for fp_iter in tif_files:
        day_yr, date_obj = extract_date_from_filename(fp_iter)
        if day_yr is None: continue
        img_data, _ = read_image(fp_iter, lake_shape=lake_geom)
        if img_data is not None: images.append(img_data); days.append(day_yr); dates_list.append(date_obj)

    if not images:
        st.warning(f"ŒîŒµŒΩ œÜŒøœÅœÑœéŒ∏Œ∑Œ∫Œ±ŒΩ Œ≠Œ≥Œ∫œÖœÅŒµœÇ ŒµŒπŒ∫œåŒΩŒµœÇ Œ±œÄœå œÑŒøŒΩ œÜŒ¨Œ∫ŒµŒªŒø: {input_folder}."); return None, None, None, None
    return np.stack(images, axis=0), np.array(days), dates_list, first_profile


def run_lake_processing_app(waterbody: str, index_name: str):
    with st.container():
        st.markdown('<div class="card">', unsafe_allow_html=True) # Changed from custom-card to card
        st.header(f"ŒïœÄŒπœÜŒ±ŒΩŒµŒπŒ±Œ∫ŒÆ ŒëœÄŒøœÑœçœÄœâœÉŒ∑: {waterbody} - {index_name}")

        data_folder = get_data_folder(waterbody, index_name)
        if not data_folder:
            expected_folder_name = ""
            if index_name == "Œ†œÅŒ±Œ≥ŒºŒ±œÑŒπŒ∫œå": expected_folder_name = "Œ†œÅŒ±Œ≥ŒºŒ±œÑŒπŒ∫œå"
            elif index_name == "ŒßŒªœâœÅŒøœÜœçŒªŒªŒ∑": expected_folder_name = "Chlorophyll"
            elif index_name == "ŒòŒøŒªœåœÑŒ∑œÑŒ±": expected_folder_name = "ŒòŒøŒªœåœÑŒ∑œÑŒ±"
            else: expected_folder_name = index_name
            
            waterbody_actual_folder = WATERBODY_FOLDERS.get(waterbody, 'ŒúŒó_ŒöŒëŒòŒüŒ°ŒôŒ£ŒúŒïŒùŒü_Œ¶ŒëŒöŒïŒõŒü')
            st.error(f"Œü œÜŒ¨Œ∫ŒµŒªŒøœÇ Œ¥ŒµŒ¥ŒøŒºŒ≠ŒΩœâŒΩ Œ≥ŒπŒ± '{waterbody} - {index_name}' Œ¥ŒµŒΩ Œ≤œÅŒ≠Œ∏Œ∑Œ∫Œµ. "
                        f"ŒïŒªŒ≠Œ≥ŒæœÑŒµ œåœÑŒπ Œø œÜŒ¨Œ∫ŒµŒªŒøœÇ '{expected_folder_name}' "
                        f"œÖœÄŒ¨œÅœáŒµŒπ ŒºŒ≠œÉŒ± œÉœÑŒøŒΩ Œ∫Œ±œÑŒ¨ŒªŒøŒ≥Œø '{os.path.join(APP_BASE_DIR, waterbody_actual_folder)}'.")
            st.markdown('</div>', unsafe_allow_html=True); return

        input_folder_geotiffs = os.path.join(data_folder, "GeoTIFFs")
        
        with st.spinner(f"Œ¶œåœÅœÑœâœÉŒ∑ Œ¥ŒµŒ¥ŒøŒºŒ≠ŒΩœâŒΩ Œ≥ŒπŒ± {waterbody} - {index_name}..."):
            STACK, DAYS, DATES, _ = load_data_for_lake_processing(input_folder_geotiffs)

        if STACK is None or not DATES:
            st.markdown('</div>', unsafe_allow_html=True); return

        st.sidebar.subheader(f"Œ¶ŒØŒªœÑœÅŒ± ŒïœÄŒµŒæŒµœÅŒ≥Œ±œÉŒØŒ±œÇ ({index_name})") # Simplified title
        min_avail_date = min(DATES).date() if DATES else date.today()
        max_avail_date = max(DATES).date() if DATES else date.today()
        unique_years_avail = sorted(list(set(d.year for d in DATES if d))) if DATES else []

        clean_index_name_for_key = re.sub(r'[^a-zA-Z0-9_]', '', index_name) 
        key_suffix = f"_lp_{waterbody}_{clean_index_name_for_key}"
        common_filename_prefix = f"{waterbody}_{index_name}_surface_map"

        threshold_range_val = st.sidebar.slider("ŒïœçœÅŒøœÇ œÑŒπŒºœéŒΩ pixel:", 0, 255, (0, 255), 
                                                key=f"thresh{key_suffix}", 
                                                help="ŒüœÅŒØœÉœÑŒµ œÑŒø Œ∫Œ±œÑœéœÜŒªŒπ Œ∫Œ±Œπ Œ±ŒΩœéœÜŒªŒπ Œ≥ŒπŒ± œÑŒπœÇ œÑŒπŒºŒ≠œÇ pixel.")
        
        col_start_lp, col_end_lp = st.sidebar.columns(2)
        refined_start_val = col_start_lp.date_input("ŒàŒΩŒ±œÅŒæŒ∑ œÄŒµœÅŒπœåŒ¥ŒøœÖ:", value=min_avail_date, 
                                                    min_value=min_avail_date, max_value=max_avail_date, 
                                                    key=f"refined_start{key_suffix}")
        refined_end_val = col_end_lp.date_input("ŒõŒÆŒæŒ∑ œÄŒµœÅŒπœåŒ¥ŒøœÖ:", value=max_avail_date, 
                                                min_value=min_avail_date, max_value=max_avail_date, 
                                                key=f"refined_end{key_suffix}")
        
        if refined_start_val > refined_end_val:
            st.sidebar.error("Œó Œ∑ŒºŒµœÅŒøŒºŒ∑ŒΩŒØŒ± Œ≠ŒΩŒ±œÅŒæŒ∑œÇ œÄœÅŒ≠œÄŒµŒπ ŒΩŒ± ŒµŒØŒΩŒ±Œπ œÄœÅŒπŒΩ ŒÆ ŒØŒ¥ŒπŒ± ŒºŒµ œÑŒ∑ŒΩ Œ∑ŒºŒµœÅŒøŒºŒ∑ŒΩŒØŒ± ŒªŒÆŒæŒ∑œÇ.")
            st.markdown('</div>', unsafe_allow_html=True); return
            
        display_option_val = st.sidebar.radio("ŒïŒºœÜŒ¨ŒΩŒπœÉŒ∑ ŒúŒ≠œÉŒøœÖ ŒîŒµŒØŒ≥ŒºŒ±œÑŒøœÇ:", 
                                            options=["Thresholded", "Original"], index=0, 
                                            key=f"display_opt{key_suffix}", horizontal=True)

        month_options_map = {i: datetime(2000, i, 1).strftime('%B') for i in range(1, 13)}
        
        default_months = st.session_state.get(f"sel_months{key_suffix}", list(month_options_map.keys()))
        selected_months_val = st.sidebar.multiselect("ŒïœÄŒπŒªŒøŒ≥ŒÆ ŒúŒ∑ŒΩœéŒΩ:",
                                                    options=list(month_options_map.keys()),
                                                    format_func=lambda x: month_options_map[x],
                                                    default=default_months,
                                                    key=f"sel_months{key_suffix}")
        
        default_years = st.session_state.get(f"sel_years{key_suffix}", unique_years_avail)
        selected_years_val = st.sidebar.multiselect("ŒïœÄŒπŒªŒøŒ≥ŒÆ ŒïœÑœéŒΩ:", 
                                                    options=unique_years_avail,
                                                    default=default_years,
                                                    key=f"sel_years{key_suffix}")
        
        start_dt_conv = datetime.combine(refined_start_val, datetime.min.time())
        end_dt_conv = datetime.combine(refined_end_val, datetime.max.time())

        indices_to_keep = [
            i for i, dt_obj in enumerate(DATES)
            if (start_dt_conv <= dt_obj <= end_dt_conv and
                (not selected_months_val or dt_obj.month in selected_months_val) and
                (not selected_years_val or dt_obj.year in selected_years_val))
        ]

        if not indices_to_keep:
            st.info("ŒîŒµŒΩ œÖœÄŒ¨œÅœáŒøœÖŒΩ Œ¥ŒµŒ¥ŒøŒºŒ≠ŒΩŒ± Œ≥ŒπŒ± œÑŒ∑ŒΩ ŒµœÄŒπŒªŒµŒ≥ŒºŒ≠ŒΩŒ∑ œÄŒµœÅŒØŒøŒ¥Œø/ŒºŒÆŒΩŒµœÇ/Œ≠œÑŒ∑. Œ†Œ±œÅŒ±Œ∫Œ±Œªœé œÄœÅŒøœÉŒ±œÅŒºœåœÉœÑŒµ œÑŒ± œÜŒØŒªœÑœÅŒ±.")
            st.markdown('</div>', unsafe_allow_html=True); return

        with st.spinner("ŒïœÄŒµŒæŒµœÅŒ≥Œ±œÉŒØŒ± œÜŒπŒªœÑœÅŒ±œÅŒπœÉŒºŒ≠ŒΩœâŒΩ Œ¥ŒµŒ¥ŒøŒºŒ≠ŒΩœâŒΩ Œ∫Œ±Œπ Œ¥Œ∑ŒºŒπŒøœÖœÅŒ≥ŒØŒ± Œ≥œÅŒ±œÜŒ∑ŒºŒ¨œÑœâŒΩ..."):
            stack_filt = STACK[indices_to_keep, :, :]
            days_filt = DAYS[indices_to_keep]
            filtered_dates_objects = [DATES[i] for i in indices_to_keep]

            lower_t, upper_t = threshold_range_val
            in_range_bool_mask = np.logical_and(stack_filt >= lower_t, stack_filt <= upper_t)
            
            st.subheader("ŒëŒΩŒ¨ŒªœÖœÉŒ∑ ŒßŒ±œÅœÑœéŒΩ")
            expander_col1, expander_col2 = st.columns(2)

            with expander_col1:
                with st.expander("ŒßŒ¨œÅœÑŒ∑œÇ: ŒóŒºŒ≠œÅŒµœÇ ŒµŒΩœÑœåœÇ ŒïœçœÅŒøœÖœÇ Œ§ŒπŒºœéŒΩ", expanded=True):
                    days_in_range_map = np.nansum(in_range_bool_mask, axis=0)
                    fig_days = px.imshow(days_in_range_map, color_continuous_scale="plasma", labels={"color": "ŒóŒºŒ≠œÅŒµœÇ"})
                    st.plotly_chart(fig_days, use_container_width=True, key=f"fig_days_map{key_suffix}")
                    df_days_in_range = pd.DataFrame(days_in_range_map)
                    add_excel_download_button(df_days_in_range, common_filename_prefix, "Days_in_Range_Map", f"excel_days_map{key_suffix}")
                    st.caption("ŒîŒµŒØœáŒΩŒµŒπ œÄœåœÉŒµœÇ Œ∑ŒºŒ≠œÅŒµœÇ Œ∫Œ¨Œ∏Œµ pixel ŒÆœÑŒ±ŒΩ ŒµŒΩœÑœåœÇ œÑŒøœÖ ŒµœÄŒπŒªŒµŒ≥ŒºŒ≠ŒΩŒøœÖ ŒµœçœÅŒøœÖœÇ œÑŒπŒºœéŒΩ.")

            tick_vals_days = [1,32,60,91,121,152,182,213,244,274,305,335,365]
            tick_text_days = ["ŒôŒ±ŒΩ","Œ¶ŒµŒ≤","ŒúŒ±œÅ","ŒëœÄœÅ","ŒúŒ±Œê","ŒôŒøœÖŒΩ","ŒôŒøœÖŒª","ŒëœÖŒ≥","Œ£ŒµœÄ","ŒüŒ∫œÑ","ŒùŒøŒµ","ŒîŒµŒ∫",""]

            with expander_col2:
                with st.expander("ŒßŒ¨œÅœÑŒ∑œÇ: ŒúŒ≠œÉŒ∑ ŒóŒºŒ≠œÅŒ± ŒïŒºœÜŒ¨ŒΩŒπœÉŒ∑œÇ ŒµŒΩœÑœåœÇ ŒïœçœÅŒøœÖœÇ", expanded=True):
                    days_array_expanded = days_filt.reshape((-1, 1, 1))
                    sum_days_in_range = np.nansum(days_array_expanded * in_range_bool_mask, axis=0)
                    count_pixels_in_range = np.nansum(in_range_bool_mask, axis=0)
                    mean_day_map = np.divide(sum_days_in_range, count_pixels_in_range, 
                                            out=np.full(sum_days_in_range.shape, np.nan), 
                                            where=(count_pixels_in_range != 0))
                    fig_mean_day = px.imshow(mean_day_map, color_continuous_scale="RdBu", 
                                            labels={"color": "ŒúŒ≠œÉŒ∑ ŒóŒºŒ≠œÅŒ± (1-365)"},
                                            color_continuous_midpoint=182)
                    fig_mean_day.update_layout(coloraxis_colorbar=dict(tickmode='array', tickvals=tick_vals_days, ticktext=tick_text_days))
                    st.plotly_chart(fig_mean_day, use_container_width=True, key=f"fig_mean_day_map{key_suffix}")
                    df_mean_day_map = pd.DataFrame(mean_day_map)
                    add_excel_download_button(df_mean_day_map, common_filename_prefix, "Mean_Day_Map", f"excel_mean_day_map{key_suffix}")
                    st.caption("ŒîŒµŒØœáŒΩŒµŒπ œÑŒ∑ ŒºŒ≠œÉŒ∑ Œ∑ŒºŒ≠œÅŒ± œÑŒøœÖ Œ≠œÑŒøœÖœÇ œÄŒøœÖ Œ≠ŒΩŒ± pixel ŒÆœÑŒ±ŒΩ ŒµŒΩœÑœåœÇ œÑŒøœÖ ŒµœçœÅŒøœÖœÇ œÑŒπŒºœéŒΩ.")

            st.subheader("ŒëŒΩŒ¨ŒªœÖœÉŒ∑ ŒîŒµŒØŒ≥ŒºŒ±œÑŒøœÇ ŒïŒπŒ∫œåŒΩŒ±œÇ")
            expander_col3, expander_col4 = st.columns(2)

            with expander_col3:
                with st.expander("ŒßŒ¨œÅœÑŒ∑œÇ: ŒúŒ≠œÉŒø ŒîŒµŒØŒ≥ŒºŒ± ŒïŒπŒ∫œåŒΩŒ±œÇ", expanded=True):
                    average_sample_img_display = None
                    if display_option_val.lower() == "thresholded":
                        filtered_stack_for_avg = np.where(in_range_bool_mask, stack_filt, np.nan)
                        average_sample_img_display = np.nanmean(filtered_stack_for_avg, axis=0)
                    else: # Original
                        average_sample_img_display = np.nanmean(stack_filt, axis=0)

                    if average_sample_img_display is not None and not np.all(np.isnan(average_sample_img_display)):
                        avg_min_disp = float(np.nanmin(average_sample_img_display))
                        avg_max_disp = float(np.nanmax(average_sample_img_display))
                        fig_sample_disp = px.imshow(average_sample_img_display, color_continuous_scale="jet",
                                                    range_color=[avg_min_disp, avg_max_disp] if avg_min_disp < avg_max_disp else None,
                                                    labels={"color": "Œ§ŒπŒºŒÆ Pixel"})
                        st.plotly_chart(fig_sample_disp, use_container_width=True, key=f"fig_sample_map{key_suffix}")
                        df_avg_sample_display = pd.DataFrame(average_sample_img_display)
                        add_excel_download_button(df_avg_sample_display, common_filename_prefix, "Average_Sample_Map", f"excel_avg_sample_map{key_suffix}")
                        st.caption(f"ŒúŒ≠œÉŒ∑ œÑŒπŒºŒÆ pixel (ŒµŒºœÜŒ¨ŒΩŒπœÉŒ∑: {display_option_val}).")
                    else:
                        st.caption("ŒîŒµŒΩ œÖœÄŒ¨œÅœáŒøœÖŒΩ Œ¥ŒµŒ¥ŒøŒºŒ≠ŒΩŒ± Œ≥ŒπŒ± œÑŒø 'ŒúŒ≠œÉŒø ŒîŒµŒØŒ≥ŒºŒ± ŒïŒπŒ∫œåŒΩŒ±œÇ'.")
            
            with expander_col4:
                with st.expander("ŒßŒ¨œÅœÑŒ∑œÇ: ŒßœÅœåŒΩŒøœÇ ŒúŒ≠Œ≥ŒπœÉœÑŒ∑œÇ ŒïŒºœÜŒ¨ŒΩŒπœÉŒ∑œÇ ŒµŒΩœÑœåœÇ ŒïœçœÅŒøœÖœÇ", expanded=True):
                    stack_for_time_max = np.where(in_range_bool_mask, stack_filt, np.nan) 
                    time_max_map = np.full(stack_for_time_max.shape[1:], np.nan, dtype=float)
                    valid_pixels_mask = ~np.all(np.isnan(stack_for_time_max), axis=0)
                    
                    if np.any(valid_pixels_mask) and filtered_dates_objects: 
                        max_indices_flat = np.nanargmax(stack_for_time_max[:, valid_pixels_mask], axis=0)
                        days_for_time_max = np.array([d.timetuple().tm_yday for d in filtered_dates_objects])
                        if len(days_for_time_max) > 0: 
                            valid_max_indices = np.clip(max_indices_flat, 0, len(days_for_time_max) - 1)
                            time_max_map[valid_pixels_mask] = days_for_time_max[valid_max_indices]

                    fig_time_max = px.imshow(time_max_map, color_continuous_scale="RdBu", 
                                            labels={"color": "ŒóŒºŒ≠œÅŒ± ŒúŒ≠Œ≥ŒπœÉœÑŒ∑œÇ (1-365)"},
                                            color_continuous_midpoint=182,
                                            range_color=[1,365])
                    fig_time_max.update_layout(coloraxis_colorbar=dict(tickmode='array', tickvals=tick_vals_days, ticktext=tick_text_days))
                    st.plotly_chart(fig_time_max, use_container_width=True, key=f"fig_time_max_map{key_suffix}")
                    df_time_max_map = pd.DataFrame(time_max_map)
                    add_excel_download_button(df_time_max_map, common_filename_prefix, "Time_Max_Value_Map", f"excel_time_max_map{key_suffix}")
                    st.caption("ŒîŒµŒØœáŒΩŒµŒπ œÑŒ∑ŒΩ Œ∑ŒºŒ≠œÅŒ± œÑŒøœÖ Œ≠œÑŒøœÖœÇ œÄŒøœÖ Œ∫Œ¨Œ∏Œµ pixel ŒµŒØœáŒµ œÑŒ∑ ŒºŒ≠Œ≥ŒπœÉœÑŒ∑ œÑŒπŒºŒÆ (ŒµŒΩœÑœåœÇ œÑŒøœÖ ŒµœçœÅŒøœÖœÇ).")

            st.subheader("Œ†œÅœåœÉŒ∏ŒµœÑŒ∑ ŒëŒΩŒ¨ŒªœÖœÉŒ∑ ŒöŒ±œÑŒ±ŒΩŒøŒºŒÆœÇ ŒóŒºŒµœÅœéŒΩ ŒµŒΩœÑœåœÇ ŒïœçœÅŒøœÖœÇ")
            stack_full_in_range = (STACK >= lower_t) & (STACK <= upper_t)
            num_cols_display = 3
            
            with st.expander("ŒúŒ∑ŒΩŒπŒ±ŒØŒ± ŒöŒ±œÑŒ±ŒΩŒøŒºŒÆ ŒóŒºŒµœÅœéŒΩ ŒµŒΩœÑœåœÇ ŒïœçœÅŒøœÖœÇ", expanded=False):
                st.caption("ŒïŒºœÜŒ±ŒΩŒØŒ∂ŒøŒΩœÑŒ±Œπ ŒºœåŒΩŒø ŒøŒπ ŒºŒÆŒΩŒµœÇ œÄŒøœÖ Œ≠œáŒøœÖŒΩ ŒµœÄŒπŒªŒµŒ≥ŒµŒØ œÄŒ±œÅŒ±œÄŒ¨ŒΩœâ.")
                months_to_show = [m for m in range(1, 13) if m in selected_months_val]
                if not months_to_show:
                    st.info("ŒîŒµŒΩ Œ≠œáŒøœÖŒΩ ŒµœÄŒπŒªŒµŒ≥ŒµŒØ ŒºŒÆŒΩŒµœÇ Œ≥ŒπŒ± œÑŒ∑ŒΩ ŒºŒ∑ŒΩŒπŒ±ŒØŒ± Œ±ŒΩŒ¨ŒªœÖœÉŒ∑.")
                else:
                    cols_monthly = st.columns(num_cols_display)
                    col_idx_monthly = 0
                    for month_num in months_to_show:
                        indices_for_month_all_years = [
                            i for i, dt_obj in enumerate(DATES)
                            if dt_obj.month == month_num and (not selected_years_val or dt_obj.year in selected_years_val)
                        ]
                        if indices_for_month_all_years:
                            monthly_sum_in_range = np.sum(stack_full_in_range[indices_for_month_all_years, :, :], axis=0)
                            month_name_disp = month_options_map[month_num]
                            fig_month_disp = px.imshow(monthly_sum_in_range, color_continuous_scale="plasma", title=month_name_disp, labels={"color": "ŒóŒºŒ≠œÅŒµœÇ"})
                            fig_month_disp.update_layout(margin=dict(l=0,r=0,t=30,b=0), height=350)
                            fig_month_disp.update_coloraxes(showscale=False)
                            cols_monthly[col_idx_monthly].plotly_chart(fig_month_disp, use_container_width=True, key=f"fig_month_{month_num}{key_suffix}")
                            df_monthly_sum = pd.DataFrame(monthly_sum_in_range)
                            add_excel_download_button(df_monthly_sum, common_filename_prefix, f"Monthly_Dist_{month_name_disp}", f"excel_month_{month_num}{key_suffix}")
                            col_idx_monthly = (col_idx_monthly + 1) % num_cols_display
            
            with st.expander("ŒïœÑŒÆœÉŒπŒ± ŒöŒ±œÑŒ±ŒΩŒøŒºŒÆ ŒóŒºŒµœÅœéŒΩ ŒµŒΩœÑœåœÇ ŒïœçœÅŒøœÖœÇ", expanded=False):
                st.caption("ŒïŒºœÜŒ±ŒΩŒØŒ∂ŒøŒΩœÑŒ±Œπ ŒºœåŒΩŒø œÑŒ± Œ≠œÑŒ∑ œÄŒøœÖ Œ≠œáŒøœÖŒΩ ŒµœÄŒπŒªŒµŒ≥ŒµŒØ œÄŒ±œÅŒ±œÄŒ¨ŒΩœâ.")
                years_to_show = [y for y in unique_years_avail if y in selected_years_val]
                if not years_to_show:
                    st.info("ŒîŒµŒΩ Œ≠œáŒøœÖŒΩ ŒµœÄŒπŒªŒµŒ≥ŒµŒØ Œ≠œÑŒ∑ Œ≥ŒπŒ± œÑŒ∑ŒΩ ŒµœÑŒÆœÉŒπŒ± Œ±ŒΩŒ¨ŒªœÖœÉŒ∑.")
                else:
                    cols_yearly = st.columns(num_cols_display)
                    col_idx_yearly = 0
                    for year_val in years_to_show:
                        indices_for_year_selected_months = [
                            i for i, dt_obj in enumerate(DATES)
                            if dt_obj.year == year_val and (not selected_months_val or dt_obj.month in selected_months_val)
                        ]
                        if indices_for_year_selected_months:
                            yearly_sum_in_range = np.sum(stack_full_in_range[indices_for_year_selected_months, :, :], axis=0)
                            fig_year_disp = px.imshow(yearly_sum_in_range, color_continuous_scale="plasma", title=f"ŒàœÑŒøœÇ: {year_val}", labels={"color": "ŒóŒºŒ≠œÅŒµœÇ"})
                            fig_year_disp.update_layout(margin=dict(l=0,r=0,t=30,b=0), height=350)
                            fig_year_disp.update_coloraxes(showscale=False)
                            cols_yearly[col_idx_yearly].plotly_chart(fig_year_disp, use_container_width=True, key=f"fig_year_{year_val}{key_suffix}")
                            df_yearly_sum = pd.DataFrame(yearly_sum_in_range)
                            add_excel_download_button(df_yearly_sum, common_filename_prefix, f"Yearly_Dist_Year_{year_val}", f"excel_year_{year_val}{key_suffix}")
                            col_idx_yearly = (col_idx_yearly + 1) % num_cols_display
        st.markdown('</div>', unsafe_allow_html=True)

def image_navigation_ui(images_folder: str, available_dates_map: dict, 
                        session_state_key_for_idx: str, key_prefix: str,
                        show_legend: bool = False, index_name_for_legend: str = ""):
    if not available_dates_map:
        st.info("ŒîŒµŒΩ œÖœÄŒ¨œÅœáŒøœÖŒΩ Œ¥ŒπŒ±Œ∏Œ≠œÉŒπŒºŒµœÇ ŒµŒπŒ∫œåŒΩŒµœÇ ŒºŒµ Œ∑ŒºŒµœÅŒøŒºŒ∑ŒΩŒØŒ±."); return None

    sorted_date_strings = sorted(available_dates_map.keys())
    
    if session_state_key_for_idx not in st.session_state:
        st.session_state[session_state_key_for_idx] = 0

    current_idx = st.session_state[session_state_key_for_idx]
    if current_idx >= len(sorted_date_strings): # Handle empty or out-of-bounds index
        current_idx = 0
        st.session_state[session_state_key_for_idx] = current_idx


    col_prev, col_select, col_next = st.columns([1,2,1])
    if col_prev.button("<< Œ†œÅŒøŒ∑Œ≥.", key=f"{key_prefix}_prev", help="Œ†œÅŒøŒ∑Œ≥ŒøœçŒºŒµŒΩŒ∑ ŒµŒπŒ∫œåŒΩŒ±", use_container_width=True):
        current_idx = max(0, current_idx - 1)
        st.session_state[session_state_key_for_idx] = current_idx; st.rerun()

    if col_next.button("ŒïœÄœåŒº. >>", key=f"{key_prefix}_next", help="ŒïœÄœåŒºŒµŒΩŒ∑ ŒµŒπŒ∫œåŒΩŒ±", use_container_width=True):
        current_idx = min(len(sorted_date_strings) - 1, current_idx + 1)
        st.session_state[session_state_key_for_idx] = current_idx; st.rerun()
            
    def update_idx_from_select_nav(): 
        selected_val = st.session_state[f"{key_prefix}_select_nav"]
        if selected_val in sorted_date_strings:
                st.session_state[session_state_key_for_idx] = sorted_date_strings.index(selected_val)

    col_select.selectbox("ŒïœÄŒπŒªŒøŒ≥ŒÆ ŒóŒºŒµœÅŒøŒºŒ∑ŒΩŒØŒ±œÇ:", options=sorted_date_strings, index=current_idx, 
                        key=f"{key_prefix}_select_nav", on_change=update_idx_from_select_nav,
                        label_visibility="collapsed")
    
    current_idx = st.session_state[session_state_key_for_idx] 
    actual_selected_date_str = sorted_date_strings[current_idx]

    st.caption(f"ŒïŒºœÜŒ±ŒΩŒØŒ∂ŒµœÑŒ±Œπ ŒµŒπŒ∫œåŒΩŒ± Œ≥ŒπŒ±: {actual_selected_date_str}")
    image_filename = available_dates_map[actual_selected_date_str]
    image_full_path = os.path.join(images_folder, image_filename)

    if os.path.exists(image_full_path):
        st.image(image_full_path, caption=f"{image_filename}", use_column_width=True)
        if show_legend and index_name_for_legend == "ŒßŒªœâœÅŒøœÜœçŒªŒªŒ∑":
            try: # Use Streamlit's theme colors if available
                theme_bg = st.get_option("theme.backgroundColor")
                theme_text = st.get_option("theme.textColor")
                legend_fig = create_chl_legend_figure(orientation="horizontal", theme_bg_color=theme_bg, theme_text_color=theme_text)
            except: # Fallback if theme options are not accessible (e.g., older Streamlit version)
                legend_fig = create_chl_legend_figure(orientation="horizontal")
            st.pyplot(legend_fig)
    else:
        st.error(f"Œ§Œø Œ±œÅœáŒµŒØŒø ŒµŒπŒ∫œåŒΩŒ±œÇ Œ¥ŒµŒΩ Œ≤œÅŒ≠Œ∏Œ∑Œ∫Œµ: {image_full_path}")
    return image_full_path


def analyze_sampling_for_dashboard(sampling_points: list, first_image_data_rgb, first_image_transform,
                                    images_folder_path: str, lake_height_excel_path: str, 
                                    selected_point_names_for_plot: list | None = None):
    def _geographic_to_pixel(lon: float, lat: float, transform_matrix) -> tuple[int, int]:
        inv_transform = ~transform_matrix; px, py = inv_transform * (lon, lat); return int(px), int(py)

    def _map_rgb_to_mg(r_val: float, g_val: float, b_val: float, mg_factor: float = 2.0) -> float:
        return (g_val / 255.0) * mg_factor 

    results_colors_dash, results_mg_dash = {n:[] for n,_,_ in sampling_points}, {n:[] for n,_,_ in sampling_points}
    if not os.path.isdir(images_folder_path):
        st.error(f"Œü œÜŒ¨Œ∫ŒµŒªŒøœÇ ŒµŒπŒ∫œåŒΩœâŒΩ '{images_folder_path}' Œ¥ŒµŒΩ Œ≤œÅŒ≠Œ∏Œ∑Œ∫Œµ Œ≥ŒπŒ± dashboard."); return go.Figure(),go.Figure(),go.Figure(),go.Figure(),{},{},pd.DataFrame()

    for filename in sorted(os.listdir(images_folder_path)):
        if not filename.lower().endswith(('.tif', '.tiff')): continue
        m = re.search(r'(\d{4})[_-]?(\d{2})[_-]?(\d{2})', filename)
        if not m: continue
        try: date_obj = datetime(int(m.groups()[0]), int(m.groups()[1]), int(m.groups()[2]))
        except ValueError: continue

        try:
            with rasterio.open(os.path.join(images_folder_path, filename)) as src:
                if src.count < 3: continue
                for name, lon, lat in sampling_points:
                    col, row = _geographic_to_pixel(lon, lat, src.transform)
                    if 0 <= col < src.width and 0 <= row < src.height:
                        win = rasterio.windows.Window(col,row,1,1)
                        pixel_data = src.read([1,2,3], window=win)
                        r,g,b = pixel_data[0,0,0], pixel_data[1,0,0], pixel_data[2,0,0]
                        
                        mg_v = _map_rgb_to_mg(r,g,b)
                        results_mg_dash[name].append((date_obj, mg_v))
                        results_colors_dash[name].append((date_obj, (r/255.,g/255.,b/255.)))
        except Exception as e: debug_message(f"Œ£œÜŒ¨ŒªŒºŒ± {filename} Œ≥ŒπŒ± dashboard: {e}"); continue
            
    if first_image_data_rgb is None or first_image_transform is None:
        st.error("ŒîŒµŒ¥ŒøŒºŒ≠ŒΩŒ± ŒµŒπŒ∫œåŒΩŒ±œÇ Œ±ŒΩŒ±œÜŒøœÅŒ¨œÇ (first_image_data_rgb / first_image_transform) Œ¥ŒµŒΩ ŒµŒØŒΩŒ±Œπ Œ¥ŒπŒ±Œ∏Œ≠œÉŒπŒºŒ±.")
        return go.Figure(),go.Figure(),go.Figure(),go.Figure(),{},{},pd.DataFrame()

    rgb_disp_data = first_image_data_rgb.transpose((1,2,0))
    if rgb_disp_data.max() > 1:
        rgb_disp_data = rgb_disp_data / 255.0
    rgb_disp_data = np.clip(rgb_disp_data, 0, 1)

    fig_geo_d = px.imshow(rgb_disp_data, title='ŒïŒπŒ∫œåŒΩŒ± ŒëŒΩŒ±œÜŒøœÅŒ¨œÇ & Œ£Œ∑ŒºŒµŒØŒ± ŒîŒµŒπŒ≥ŒºŒ±œÑŒøŒªŒ∑œàŒØŒ±œÇ')
    for n,lon,lat in sampling_points:
        col,row=_geographic_to_pixel(lon,lat,first_image_transform)
        fig_geo_d.add_trace(go.Scatter(x=[col],y=[row],mode='markers+text', marker=dict(color='red',size=10,symbol='x'),name=n,text=n,textposition="top right", hovertemplate=f'<b>{n}</b><br>Lon:{lon:.4f}<br>Lat:{lat:.4f}<extra></extra>'))
    fig_geo_d.update_xaxes(visible=False); fig_geo_d.update_yaxes(visible=False,scaleanchor="x",scaleratio=1); fig_geo_d.update_layout(height=600,showlegend=True,legend_title_text="Œ£Œ∑ŒºŒµŒØŒ±",uirevision='dashboard_geo')

    df_h_d = pd.DataFrame(columns=['Date', 'Height']) 
    if os.path.exists(str(lake_height_excel_path)):
        try:
            df_tmp=pd.read_excel(lake_height_excel_path)
            if not df_tmp.empty and len(df_tmp.columns)>=2:
                df_h_d['Date']=pd.to_datetime(df_tmp.iloc[:,0],errors='coerce'); df_h_d['Height']=pd.to_numeric(df_tmp.iloc[:,1],errors='coerce')
                df_h_d.dropna(inplace=True); df_h_d.sort_values('Date',inplace=True)
        except Exception as e: st.warning(f"Œ£œÜŒ¨ŒªŒºŒ± Œ±ŒΩŒ¨Œ≥ŒΩœâœÉŒ∑œÇ œÉœÑŒ¨Œ∏ŒºŒ∑œÇ (dashboard): {e}")
            
    fig_colors_d=make_subplots(specs=[[{"secondary_y":True}]])
    pts_plot = selected_point_names_for_plot if selected_point_names_for_plot else [p[0] for p in sampling_points]
    pt_y_idx={n:i for i,n in enumerate(pts_plot)}

    for n_iter in pts_plot:
        if n_iter in results_colors_dash and results_colors_dash[n_iter]:
            d_list=sorted(results_colors_dash[n_iter],key=lambda x:x[0])
            if d_list:
                dts_c,cols_c_norm=zip(*d_list)
                cols_rgb_s=[f"rgb({int(c[0]*255)},{int(c[1]*255)},{int(c[2]*255)})" for c in cols_c_norm]
                y_p=pt_y_idx.get(n_iter,-1)
                if y_p != -1:
                    fig_colors_d.add_trace(go.Scatter(x=list(dts_c),y=[y_p]*len(dts_c),mode='markers',marker=dict(color=cols_rgb_s,size=10),name=n_iter,legendgroup=n_iter),secondary_y=False)
    
    if not df_h_d.empty: fig_colors_d.add_trace(go.Scatter(x=df_h_d['Date'],y=df_h_d['Height'],name='Œ£œÑŒ¨Œ∏ŒºŒ∑',mode='lines',line=dict(color='blue',width=2),legendgroup="h_grp"),secondary_y=True)
    fig_colors_d.update_layout(title='ŒßœÅœéŒºŒ±œÑŒ± Pixel & Œ£œÑŒ¨Œ∏ŒºŒ∑',xaxis_title='ŒóŒºŒµœÅŒøŒºŒ∑ŒΩŒØŒ±',
                                yaxis=dict(title='Œ£Œ∑ŒºŒµŒØŒ±',tickmode='array',tickvals=list(pt_y_idx.values()),ticktext=list(pt_y_idx.keys()),showgrid=False),
                                yaxis2=dict(title='Œ£œÑŒ¨Œ∏ŒºŒ∑ (m)',showgrid=True,gridcolor='rgba(128,128,128,0.2)'),showlegend=True,uirevision='dashboard_colors')

    all_mg_vals_date_d={};
    for p_n in pts_plot: 
        if p_n in results_mg_dash:
            for d_obj,val_mg in results_mg_dash[p_n]: all_mg_vals_date_d.setdefault(d_obj,[]).append(val_mg)
    s_dates_mg_d=sorted(all_mg_vals_date_d.keys())
    avg_mg_d=[np.mean(all_mg_vals_date_d[d_obj]) for d_obj in s_dates_mg_d if all_mg_vals_date_d[d_obj]]
    
    fig_mg_d=go.Figure()
    if s_dates_mg_d and avg_mg_d: fig_mg_d.add_trace(go.Scatter(x=s_dates_mg_d,y=avg_mg_d,mode='lines+markers',name='ŒúŒ≠œÉŒø mg/m¬≥',marker=dict(color=avg_mg_d,colorscale='Viridis',reversescale=True,colorbar=dict(title='mg/m¬≥',thickness=15),size=10),line=dict(color='grey')))
    fig_mg_d.update_layout(title='ŒúŒ≠œÉŒø mg/m¬≥ (ŒïœÄŒπŒªŒµŒ≥ŒºŒ≠ŒΩŒ± Œ£Œ∑ŒºŒµŒØŒ±)',xaxis_title='ŒóŒºŒµœÅŒøŒºŒ∑ŒΩŒØŒ±',yaxis_title='mg/m¬≥',uirevision='dashboard_mg')

    fig_dual_d=make_subplots(specs=[[{"secondary_y":True}]])
    if not df_h_d.empty: 
        fig_dual_d.add_trace(go.Scatter(x=df_h_d['Date'],y=df_h_d['Height'],name='Œ£œÑŒ¨Œ∏ŒºŒ∑',mode='lines',line=dict(color='deepskyblue')),secondary_y=False)
    if s_dates_mg_d and avg_mg_d: 
        fig_dual_d.add_trace(go.Scatter(x=s_dates_mg_d,y=avg_mg_d,name='ŒúŒ≠œÉŒø mg/m¬≥',mode='lines+markers',marker=dict(color=avg_mg_d,colorscale='Viridis',reversescale=True,size=10,showscale=False),line=dict(color='lightgreen')),secondary_y=True)
    
    fig_dual_d.update_layout(
        title='Œ£œÑŒ¨Œ∏ŒºŒ∑ & ŒúŒ≠œÉŒø mg/m¬≥',
        xaxis_title='ŒóŒºŒµœÅŒøŒºŒ∑ŒΩŒØŒ±',
        uirevision='dashboard_dual', 
        yaxis=dict(title=dict(text="Œ£œÑŒ¨Œ∏ŒºŒ∑ (m)", font=dict(color="deepskyblue")), tickfont=dict(color="deepskyblue"),side='left'),
        yaxis2=dict(title=dict(text="mg/m¬≥", font=dict(color="lightgreen")), tickfont=dict(color="lightgreen"),overlaying='y', side='right')
    )
    
    return fig_geo_d,fig_dual_d,fig_colors_d,fig_mg_d,results_colors_dash,results_mg_dash,df_h_d


def run_water_quality_dashboard(waterbody: str, index_name: str):
    with st.container():
        st.markdown('<div class="card">', unsafe_allow_html=True) # Changed to card
        st.header(f"Œ†œÅŒøœÜŒØŒª Œ†ŒøŒπœåœÑŒ∑œÑŒ±œÇ Œ∫Œ±Œπ Œ£œÑŒ¨Œ∏ŒºŒ∑œÇ: {waterbody} - {index_name}")
        
        clean_index_name_for_key = re.sub(r'[^a-zA-Z0-9_]', '', index_name)
        key_suffix_dash = f"_dash_{waterbody}_{clean_index_name_for_key}"
        common_filename_prefix_dash = f"{waterbody}_{index_name}" 

        data_folder = get_data_folder(waterbody, index_name)
        if not data_folder: 
            st.error(f"Œ¶Œ¨Œ∫ŒµŒªŒøœÇ Œ¥ŒµŒ¥ŒøŒºŒ≠ŒΩœâŒΩ Œ≥ŒπŒ± '{waterbody} - {index_name}' Œ¥ŒµŒΩ Œ≤œÅŒ≠Œ∏Œ∑Œ∫Œµ. Œ†Œ±œÅŒ±Œ∫Œ±Œªœé ŒµŒªŒ≠Œ≥ŒæœÑŒµ œÑŒπœÇ œÅœÖŒ∏ŒºŒØœÉŒµŒπœÇ Œ∫Œ±Œπ œÑŒ∑ Œ¥ŒøŒºŒÆ œÑœâŒΩ œÜŒ±Œ∫Œ≠ŒªœâŒΩ œÉŒ±œÇ.")
            st.markdown('</div>', unsafe_allow_html=True); return

        images_folder_path = os.path.join(data_folder,"GeoTIFFs")
        lake_height_excel_path = os.path.join(data_folder,"lake height.xlsx")
        default_sampling_kml_path = os.path.join(data_folder,"sampling.kml")
        vid_path = next((p for n in ["timelapse.mp4","timelapse.gif","Sentinel-2_L1C-202307221755611-timelapse.gif"] for p in [os.path.join(data_folder,n), os.path.join(images_folder_path,n)] if os.path.exists(p)), None)
        
        st.sidebar.subheader(f"Œ°œÖŒ∏ŒºŒØœÉŒµŒπœÇ Œ†ŒØŒΩŒ±Œ∫Œ± ({index_name})")
        available_tifs = {str(d.date()):fn for fn in (os.listdir(images_folder_path) if os.path.exists(images_folder_path) else []) if fn.lower().endswith(('.tif','.tiff')) for _,d in [extract_date_from_filename(fn)] if d}
        
        first_img_rgb, first_img_transform = None, None
        if available_tifs:
            sel_bg_date_options = sorted(available_tifs.keys(),reverse=True)
            sel_bg_date_index = 0 if sel_bg_date_options else None

            sel_bg_date = st.sidebar.selectbox("ŒïŒπŒ∫œåŒΩŒ± ŒëŒΩŒ±œÜŒøœÅŒ¨œÇ:", sel_bg_date_options, index=sel_bg_date_index, key=f"bg_date{key_suffix_dash}")
            if sel_bg_date and available_tifs.get(sel_bg_date):
                try:
                    with rasterio.open(os.path.join(images_folder_path,available_tifs[sel_bg_date])) as src:
                        if src.count>=3: first_img_rgb,first_img_transform = src.read([1,2,3]),src.transform
                        else: st.sidebar.error("ŒïŒπŒ∫œåŒΩŒ± < 3 Œ∫Œ±ŒΩŒ¨ŒªŒπŒ±.")
                except Exception as e: st.sidebar.error(f"Œ£œÜŒ¨ŒªŒºŒ± œÜœåœÅœÑœâœÉŒ∑œÇ Œ±ŒΩŒ±œÜŒøœÅŒ¨œÇ: {e}")
        else: st.sidebar.warning("ŒîŒµŒΩ Œ≤œÅŒ≠Œ∏Œ∑Œ∫Œ±ŒΩ GeoTIFF Œ≥ŒπŒ± ŒµŒπŒ∫œåŒΩŒ± Œ±ŒΩŒ±œÜŒøœÅŒ¨œÇ.")

        if first_img_rgb is None: 
            st.error("ŒëœÄŒ±ŒπœÑŒµŒØœÑŒ±Œπ Œ≠Œ≥Œ∫œÖœÅŒ∑ ŒµŒπŒ∫œåŒΩŒ± Œ±ŒΩŒ±œÜŒøœÅŒ¨œÇ GeoTIFF (œÑŒøœÖŒªŒ¨œáŒπœÉœÑŒøŒΩ 3 Œ∫Œ±ŒΩŒ¨ŒªŒπŒ±) Œ≥ŒπŒ± œÑŒ∑ œÉœÖŒΩŒ≠œáŒµŒπŒ± œÑŒ∑œÇ Œ±ŒΩŒ¨ŒªœÖœÉŒ∑œÇ.")
            st.markdown('</div>', unsafe_allow_html=True); return

        tabs_ctrl = st.tabs(["ŒîŒµŒπŒ≥ŒºŒ±œÑŒøŒªŒ∑œàŒØŒ± 1 (Œ†œÅŒøŒµœÄŒπŒªŒøŒ≥ŒÆ)", "ŒîŒµŒπŒ≥ŒºŒ±œÑŒøŒªŒ∑œàŒØŒ± 2 (ŒëŒΩŒ≠Œ≤Œ±œÉŒºŒ± KML)"])
        
        with tabs_ctrl[0]: # Default Sampling
            st.markdown("##### ŒëŒΩŒ¨ŒªœÖœÉŒ∑ ŒºŒµ Œ†œÅŒøŒµœÄŒπŒªŒµŒ≥ŒºŒ≠ŒΩŒ± Œ£Œ∑ŒºŒµŒØŒ±")
            def_pts_list = parse_sampling_kml(default_sampling_kml_path) if os.path.exists(default_sampling_kml_path) else []
            st.session_state[f"def_pts_list{key_suffix_dash}"] = def_pts_list 
            
            if def_pts_list:
                all_def_point_names = [n for n,_,_ in def_pts_list]
                default_selection = all_def_point_names[:] 

                sel_pts_def_names = st.multiselect("Œ£Œ∑ŒºŒµŒØŒ± (Œ†œÅŒøŒµœÄŒπŒªŒøŒ≥ŒÆ):", all_def_point_names, default=default_selection, key=f"sel_def{key_suffix_dash}")
                st.session_state[f"sel_pts_def_names{key_suffix_dash}"] = sel_pts_def_names 
                if st.button("ŒïŒ∫œÑŒ≠ŒªŒµœÉŒ∑ (Œ†œÅŒøŒµœÄŒπŒªŒøŒ≥ŒÆ)", key=f"run_def{key_suffix_dash}", type="primary", use_container_width=True):
                    with st.spinner("ŒïŒ∫œÑŒ≠ŒªŒµœÉŒ∑ Œ±ŒΩŒ¨ŒªœÖœÉŒ∑œÇ Œ≥ŒπŒ± œÄœÅŒøŒµœÄŒπŒªŒµŒ≥ŒºŒ≠ŒΩŒ± œÉŒ∑ŒºŒµ