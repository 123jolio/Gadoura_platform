#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Water Quality App (Enterprise-Grade UI)
-----------------------------------------
Î¦Î¹Î»Î¹ÎºÏŒ, ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÏŒ Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½ Î±Î½Î¬Î»Ï…ÏƒÎ·Ï‚ Î´Î¿ÏÏ…Ï†Î¿ÏÎ¹ÎºÏÎ½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Ï…Î´Î¬Ï„Ï‰Î½.
"""

import os
import glob
import re
from datetime import datetime, date
import xml.etree.ElementTree as ET
import io

import numpy as np
import pandas as pd
import rasterio
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

from rasterio.errors import NotGeoreferencedWarning
import warnings
warnings.filterwarnings("ignore", category=NotGeoreferencedWarning)

import matplotlib.pyplot as plt
import matplotlib.colors as mcolors

import streamlit_authenticator as stauth # <--- Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Î³Î¹Î± Î±Ï…Î¸ÎµÎ½Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·

# --- PAGE CONFIGURATION (MUST BE THE FIRST STREAMLIT COMMAND) ---
st.set_page_config(layout="wide", page_title="Î‘Î½Î¬Î»Ï…ÏƒÎ· Î Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ Î•Ï€Î¹Ï†Î±Î½ÎµÎ¹Î±ÎºÏÎ½ Î¥Î´Î¬Ï„Ï‰Î½ Î¤Î±Î¼Î¹ÎµÏ…Ï„Î®ÏÏ‰Î½ Î•Î¥Î‘Î˜ Î‘Î•", page_icon="ğŸ’§")
# --------------------------------------------------------------------

# --- AUTHENTICATION SETUP ---

# --- STEP 1: Temporarily uncomment the following lines to generate your REAL hashed passwords. ---
# --- After running ONCE and copying the output, COMMENT THEM OUT AGAIN or DELETE THEM. ---
# --- Make sure 'streamlit' (st) and 'streamlit_authenticator' (stauth) are imported above. ---
# =======================================================================================
# import streamlit_authenticator as stauth # Already imported above
# import streamlit as st              # Already imported above

# # CHOOSE YOUR ACTUAL PASSWORDS HERE (MAKE SURE THEY ARE STRONG):
# passwords_for_users = ['your_actual_password_for_jsmith', 'your_actual_password_for_jdoe'] 
# # Example: passwords_for_users = ['P@sswordJS123!', 'P@sswordJD456$'] # Use your own strong passwords

# hashed_passwords_for_script = stauth.Hasher(passwords_for_users).generate()
# st.write("--- IMPORTANT: HASHED PASSWORD GENERATION (Temporary) ---")
# st.write("1. Copy this entire list (including the square brackets and quotes).")
# st.write("2. Paste it to replace the 'hashed_passwords_list' variable below (in STEP 3).")
# st.write("3. After pasting, comment out or delete this entire 'STEP 1' debug block.")
# st.write("4. Re-run the Streamlit app with STEP 1 commented out.")
# st.write("Generated Hashes:", hashed_passwords_for_script)
# st.stop() # Stops the app here after printing, so you can copy the hashes
# =======================================================================================

# --- STEP 2: Define your users and their credentials ---
names = ["John Smith", "Jane Doe"]  # Display names for your users
usernames = ["jsmith", "jdoe"]      # Usernames for login

# --- STEP 3: PASTE THE REAL HASHED PASSWORDS YOU GENERATED FROM STEP 1 HERE. ---
# It MUST be a list of strings, where each string is a valid bcrypt hash.
# For example, if Step 1 printed: ['$2b$12$A1bC2dE3fG...', '$2b$12$H4iJ5kL6mN...']
# Then this line should look like:
# hashed_passwords_list = ['$2b$12$A1bC2dE3fG...', '$2b$12$H4iJ5kL6mN...']
#
# **** YOU MUST REPLACE THESE PLACEHOLDERS WITH YOUR ACTUAL GENERATED HASHES ****
# **** AFTER FOLLOWING STEP 1 AND STEP 2 ABOVE ****
hashed_passwords_list = [
    '$2b$12$REPLACE_THIS_WITH_YOUR_FIRST_ACTUAL_HASH_XXXXXXX', # REPLACE THIS WITH YOUR FIRST ACTUAL HASH
    '$2b$12$REPLACE_THIS_WITH_YOUR_SECOND_ACTUAL_HASH_YYYYYY' # REPLACE THIS WITH YOUR SECOND ACTUAL HASH
]

# --- Create credentials dictionary ---
credentials = {"usernames": {}}
if len(names) == len(usernames) == len(hashed_passwords_list): # Basic check
    for i in range(len(usernames)):
        credentials["usernames"][usernames[i]] = {
            "name": names[i],
            "password": hashed_passwords_list[i]
        }
else:
    st.error("Error: The lists for names, usernames, and hashed_passwords_list must have the same number of items.")
    st.error("Please ensure you have defined users and pasted the correct number of hashed passwords.")
    st.stop()

# --- Optional Debugging: Uncomment if you still face issues after pasting real hashes ---
# st.write("--- Debug: Initial Credential Data (Post-User-Update) ---")
# st.write(f"Names (type: {type(names)}): {names}")
# st.write(f"Usernames (type: {type(usernames)}): {usernames}")
# st.write(f"Hashed Passwords List (type: {type(hashed_passwords_list)}): {hashed_passwords_list}")
# st.write(f"Constructed credentials dictionary: {credentials}")
# st.write("--- End Debug: Initial Credential Data ---")

# --- STEP 4: Initialize the Authenticator ---
authenticator = None # Initialize to None in case of error below
try:
    authenticator = stauth.Authenticate(
        credentials,
        "water_quality_app_cookie_v5",      # Changed cookie name slightly for freshness
        "a_very_random_secret_key_v5",  # Changed key slightly for freshness
        cookie_expiry_days=30,
    )
except Exception as e:
    st.error(f"Error during stauth.Authenticate initialization: {e}")
    st.error("This often happens if the 'credentials' dictionary is malformed or password hashes are not valid bcrypt hashes.")
    st.error("Please double-check STEP 3 and ensure you have pasted valid hashes generated from STEP 1.")
    st.stop()

# --- Optional Debugging: Uncomment if you still face issues after pasting real hashes ---
# st.write("--- Debug: Authenticator Object Inspection (Post-User-Update) ---")
# st.write(f"Authenticator object after initialization: {authenticator}")
# if authenticator:
#     if hasattr(authenticator, 'credentials'):
#         st.write(f"Authenticator.credentials (internal): {authenticator.credentials}")
#     else:
#         st.write("Authenticator object does NOT have a 'credentials' attribute after init.")
# 
#     if hasattr(authenticator, 'key'):
#         st.write(f"Authenticator.key (signature key internal): {authenticator.key}")
#     else:
#         st.write("Authenticator object does NOT have a 'key' attribute after init.")
# else:
#     st.write("Authenticator object is None after initialization attempt.")
# st.write("--- End Debug: Authenticator Object Inspection ---")
# --- END OF AUTHENTICATION SETUP ---


# --- Global Configuration & Constants ---
DEBUG = False
APP_BASE_DIR = os.path.dirname(os.path.abspath(__file__)) if "__file__" in locals() else os.getcwd()
LOGO_PATH = os.path.join(APP_BASE_DIR, "logo.jpg")

WATERBODY_FOLDERS = {
    "Î“Î±Î´Î¿Ï…ÏÎ¬": "Gadoura",
}

SESSION_KEY_WATERBODY = "waterbody_choice_main"
SESSION_KEY_INDEX = "index_choice_main"
SESSION_KEY_ANALYSIS = "analysis_choice_main"
SESSION_KEY_DEFAULT_RESULTS_DASHBOARD = "dashboard_default_sampling_results"
SESSION_KEY_UPLOAD_RESULTS_DASHBOARD = "dashboard_upload_sampling_results"
SESSION_KEY_CURRENT_IMAGE_INDEX_DASH_DEF = "dash_def_current_image_idx"
SESSION_KEY_CURRENT_IMAGE_INDEX_DASH_UPL = "dash_upl_current_image_idx"

def debug_message(*args, **kwargs):
    if DEBUG:
        with st.expander("Debug Messages", expanded=False):
            st.write(*args, **kwargs)

def inject_custom_css():
    custom_css = """
    <link href="https://fonts.googleapis.com/css?family=Roboto:400,500,700&display=swap" rel="stylesheet">
    <style>
        html, body, [class*="css"] { font-family: 'Roboto', sans-serif; }
        .block-container { background: #161b22; color: #e0e0e0; padding: 1.2rem; }
        .stSidebar > div:first-child { background: #23272f; border-right: 1px solid #3a3f47; }
        .card {
            background: #1a1a1d; padding: 2rem 2.5rem; border-radius: 16px;
            box-shadow: 0 4px 16px rgba(0,0,0,0.25); margin-bottom: 2rem;
            animation: fadein 1.0s ease-in-out;
        }
        @keyframes fadein {
            0% {opacity:0; transform: translateY(10px);}
            100%{opacity:1; transform: translateY(0px);}
        }
        .header-title {
            color: #ffd600; margin-bottom: 1.5rem; font-size: 2.2rem;
            text-align: center; letter-spacing: 0.5px; font-weight: 700;
        }
        .nav-section {
            padding: 1rem 1.2rem; background: #2c2f36; border-radius: 10px;
            margin-bottom: 1.2rem; border-left: 4px solid #ffd600;
        }
        .nav-section h4 { margin: 0; color: #ffd600; font-weight: 500; font-size: 1.1rem; }
        .stButton button {
            background-color: #009688; color: #ffffff; border-radius: 8px;
            padding: 10px 22px; border: none; box-shadow: 0 3px 8px rgba(0,0,0,0.15);
            font-size: 1.05rem; transition: background-color 0.2s, box-shadow 0.2s, transform 0.2s;
            cursor: pointer;
        }
        .stButton button:hover {
            background-color: #00796b; box-shadow: 0 4px 12px rgba(0,0,0,0.2);
            transform: translateY(-1px);
        }
        .stButton button:active { background-color: #00695c; transform: translateY(0px); }
        .plotly-graph-div { border: 1px solid #2a2e37; border-radius: 10px; }
        .footer {
            text-align:center; color: #7a828e; font-size:0.85rem;
            padding: 2rem 0 0.5rem 0; border-top: 1px solid #2a2e37;
        }
        .footer a { color: #009688; text-decoration: none; }
        .footer a:hover { text-decoration: underline; }
    </style>
    """
    st.markdown(custom_css, unsafe_allow_html=True)

def add_excel_download_button(df_or_dict_of_dfs, filename_prefix: str, button_label_suffix: str, plot_key: str):
    if df_or_dict_of_dfs is None:
        debug_message(f"No data provided for Excel export: {button_label_suffix}")
        return

    is_empty_df = isinstance(df_or_dict_of_dfs, pd.DataFrame) and df_or_dict_of_dfs.empty
    is_empty_dict = False
    if isinstance(df_or_dict_of_dfs, dict):
        if not df_or_dict_of_dfs:
            is_empty_dict = True
        else:
            all_dfs_in_dict_empty = True
            for df_item in df_or_dict_of_dfs.values():
                if isinstance(df_item, pd.DataFrame) and not df_item.empty:
                    all_dfs_in_dict_empty = False
                    break
            if all_dfs_in_dict_empty:
                is_empty_dict = True

    if is_empty_df or is_empty_dict:
        debug_message(f"Empty data provided for Excel export: {button_label_suffix}")
        return

    output = io.BytesIO()
    try:
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            if isinstance(df_or_dict_of_dfs, pd.DataFrame):
                df_or_dict_of_dfs.to_excel(writer, index=False, sheet_name='Data')
            elif isinstance(df_or_dict_of_dfs, dict):
                for sheet_name, data_df in df_or_dict_of_dfs.items():
                    if isinstance(data_df, pd.DataFrame) and not data_df.empty:
                        sane_sheet_name = re.sub(r'[\[\]\*\/\\?\:\']', '_', str(sheet_name))[:31]
                        data_df.to_excel(writer, index=False, sheet_name=sane_sheet_name)
                    elif isinstance(data_df, pd.DataFrame) and data_df.empty:
                        debug_message(f"Empty DataFrame for sheet '{sheet_name}' in Excel export: {button_label_suffix}")
        excel_data = output.getvalue()
        if not excel_data:
            debug_message(f"No data written to Excel buffer for: {button_label_suffix}")
            return

        file_name_suffix = button_label_suffix.lower().replace(' ', '_').replace('/', '_').replace('&', 'and').replace('(', '').replace(')', '')
        st.download_button(
            label=f"ğŸ“¥ Save {button_label_suffix} to Excel",
            data=excel_data,
            file_name=f"{filename_prefix}_{file_name_suffix}.xlsx",
            mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            key=f"download_{plot_key}"
        )
    except Exception as e:
        st.warning(f"Could not generate Excel file for {button_label_suffix}: {e}")
        debug_message(f"Excel generation error for {button_label_suffix}: {e}")

def render_footer():
    st.markdown(f"""
        <hr style="border-color: #2a2e37;">
        <div class='footer'>
            Â© {datetime.now().year} EYATH SA â€¢ Powered by Google Gemini & Streamlit | Contact: <a href='mailto:ilioumbas@eyath.gr'>ilioumbas@eyath.gr</a>
        </div>
    """, unsafe_allow_html=True)

def run_intro_page_custom():
    with st.container():
        st.markdown('<div class="card">', unsafe_allow_html=True)
        col_logo, col_text = st.columns([0.3, 0.7], gap="large")
        with col_logo:
            if os.path.exists(LOGO_PATH):
                st.image(LOGO_PATH, width=240, output_format="auto")
            else:
                st.markdown("ğŸ’§", help="Î›Î¿Î³ÏŒÏ„Ï…Ï€Î¿ Î•Î¥Î‘Î˜")
        with col_text:
            user_name_display = st.session_state.get("name", "Î•Ï€Î¹ÏƒÎºÎ­Ï€Ï„Î·")
            st.markdown(f"""
                <h2 class='header-title'>Î•Ï†Î±ÏÎ¼Î¿Î³Î® Î‘Î½Î¬Î»Ï…ÏƒÎ·Ï‚ Î Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ Î•Ï€Î¹Ï†Î±Î½ÎµÎ¹Î±ÎºÏÎ½ Î¥Î´Î¬Ï„Ï‰Î½ Î¤Î±Î¼Î¹ÎµÏ…Ï„Î®ÏÏ‰Î½ Î•Î¥Î‘Î˜ Î‘Î•</h2>
                <p style='font-size:1.15rem;text-align:center; line-height:1.6;'>
                ÎšÎ±Î»Ï‰ÏƒÎ®ÏÎ¸Î±Ï„Îµ, <strong>{user_name_display}</strong>!<br>
                Î•Î¾ÎµÏÎµÏ…Î½Î®ÏƒÏ„Îµ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ Î¼Îµ ÎµÏ…ÎºÎ¿Î»Î¯Î±.<br>
                Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Ï„Î¹ Î¸Î­Î»ÎµÏ„Îµ Î½Î± Î´ÎµÎ¯Ï„Îµ Î±Ï€ÏŒ Ï„Î¿ Ï€Î»Î¬Î¹ Ï€Î±ÏÎ¬Î³Î¿Î½Ï„Î±Ï‚ Î´Ï…Î½Î±Î¼Î¹ÎºÎ¬, Î´Î¹Î±Î´ÏÎ±ÏƒÏ„Î¹ÎºÎ¬ Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î±
                </p>
                """, unsafe_allow_html=True)
        with st.expander("ğŸ”° ÎŸÎ´Î·Î³Î¯ÎµÏ‚ Î§ÏÎ®ÏƒÎ·Ï‚", expanded=False):
            st.markdown("""
                - **Î•Ï€Î¹Î»Î¿Î³Î® Î Î±ÏÎ±Î¼Î­Ï„ÏÏ‰Î½:** Î£Ï„Î·Î½ Ï€Î»Î±ÏŠÎ½Î® Î¼Ï€Î¬ÏÎ± (Î±ÏÎ¹ÏƒÏ„ÎµÏÎ¬), ÎµÏ€Î¹Î»Î­Î¾Ï„Îµ Ï„Î¿ Ï…Î´Î¬Ï„Î¹Î½Î¿ ÏƒÏÎ¼Î±, Ï„Î¿Î½ Î´ÎµÎ¯ÎºÏ„Î· Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ ÎºÎ±Î¹ Ï„Î¿ ÎµÎ¯Î´Î¿Ï‚ Ï„Î·Ï‚ Î±Î½Î¬Î»Ï…ÏƒÎ·Ï‚ Ï€Î¿Ï… ÎµÏ€Î¹Î¸Ï…Î¼ÎµÎ¯Ï„Îµ.
                - **Î Î»Î¿Î®Î³Î·ÏƒÎ· ÏƒÏ„Î± Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±:** ÎœÎµÏ„Î¬ Ï„Î·Î½ ÎµÏ€Î¹Î»Î¿Î³Î®, Ï„Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± ÎºÎ±Î¹ Ï„Î± Î´Î¹Î±Î´ÏÎ±ÏƒÏ„Î¹ÎºÎ¬ Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î± Î¸Î± ÎµÎ¼Ï†Î±Î½Î¹ÏƒÏ„Î¿ÏÎ½ ÏƒÏ„Î·Î½ ÎºÏÏÎ¹Î± Ï€ÎµÏÎ¹Î¿Ï‡Î®. Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï„Î¹Ï‚ ÎºÎ±ÏÏ„Î­Î»ÎµÏ‚ (tabs) Î³Î¹Î± Î½Î± Î´ÎµÎ¯Ï„Îµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ Î¿Ï€Ï„Î¹ÎºÎ¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚.
                - **Î ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÎ¼Î­Î½Î· Î”ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î±:** Î£Ï„Î·Î½ ÎµÎ½ÏŒÏ„Î·Ï„Î± "Î ÏÎ¿Ï†Î¯Î» Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ ÎºÎ±Î¹ ÏƒÏ„Î¬Î¸Î¼Î·Ï‚", Î¼Ï€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± Î±Î½ÎµÎ²Î¬ÏƒÎµÏ„Îµ Ï„Î¿ Î´Î¹ÎºÏŒ ÏƒÎ±Ï‚ Î±ÏÏ‡ÎµÎ¯Î¿ KML Î³Î¹Î± Î±Î½Î¬Î»Ï…ÏƒÎ· ÏƒÎµ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î± ÏƒÎ·Î¼ÎµÎ¯Î± ÎµÎ½Î´Î¹Î±Ï†Î­ÏÎ¿Î½Ï„Î¿Ï‚.
                - **Î¦Î¯Î»Ï„ÏÎ±:** Î£Îµ Î¿ÏÎ¹ÏƒÎ¼Î­Î½ÎµÏ‚ Î±Î½Î±Î»ÏÏƒÎµÎ¹Ï‚, Î¸Î± Î²ÏÎµÎ¯Ï„Îµ ÎµÏ€Î¹Ï€Î»Î­Î¿Î½ Ï†Î¯Î»Ï„ÏÎ± ÏƒÏ„Î·Î½ Ï€Î»Î±ÏŠÎ½Î® Î¼Ï€Î¬ÏÎ± (Ï€.Ï‡., ÎµÏÏÎ¿Ï‚ Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¹ÏÎ½, Ï„Î¹Î¼Î­Ï‚ pixel) Î³Î¹Î± Î½Î± Ï€ÏÎ¿ÏƒÎ±ÏÎ¼ÏŒÏƒÎµÏ„Îµ Ï„Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±.
                - **Î•Ï€ÎµÎ¾Î·Î³Î®ÏƒÎµÎ¹Ï‚:** ÎšÎ¬Î½Ï„Îµ ÎºÎ»Î¹Îº ÏƒÏ„Î± ÎµÎ¹ÎºÎ¿Î½Î¯Î´Î¹Î± â„¹ï¸ Î® ÏƒÏ„Î± expanders Î³Î¹Î± Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎµÏ‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ ÏƒÏ‡ÎµÏ„Î¹ÎºÎ¬ Î¼Îµ ÎºÎ¬Î¸Îµ Î³ÏÎ¬Ï†Î·Î¼Î± Î® ÎµÏ€Î¹Î»Î¿Î³Î®.
                - **Î‘ÏƒÏ†Î¬Î»ÎµÎ¹Î± Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½:** ÎŒÎ»Î± Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÎºÎ±Î¹ Ï„Î± Î±ÏÏ‡ÎµÎ¯Î± Ï€Î¿Ï… Î±Î½ÎµÎ²Î¬Î¶ÎµÏ„Îµ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î¬Î¶Î¿Î½Ï„Î±Î¹ Ï„Î¿Ï€Î¹ÎºÎ¬ ÏƒÏ„Î¿Î½ Ï€ÎµÏÎ¹Î·Î³Î·Ï„Î® ÏƒÎ±Ï‚ ÎºÎ±Î¹ Î´ÎµÎ½ Î¼ÎµÏ„Î±Ï†Î¿ÏÏ„ÏÎ½Î¿Î½Ï„Î±Î¹ ÏƒÎµ ÎµÎ¾Ï‰Ï„ÎµÏÎ¹ÎºÎ¿ÏÏ‚ Î´Î¹Î±ÎºÎ¿Î¼Î¹ÏƒÏ„Î­Ï‚.
                """)
        st.markdown('</div>', unsafe_allow_html=True)

def run_custom_sidebar_ui_custom():
    global authenticator # Access the globally defined authenticator
    if authenticator and st.session_state.get("authentication_status"): # Check if authenticator is valid and user is logged in
        st.sidebar.success(f"Î£Ï…Î½Î´ÎµÎ¸Î®ÎºÎ±Ï„Îµ Ï‰Ï‚: {st.session_state.get('name', 'N/A')}")
        authenticator.logout("Î‘Ï€Î¿ÏƒÏÎ½Î´ÎµÏƒÎ·", "sidebar", key='unique_logout_button_key')
        st.sidebar.markdown("<hr>", unsafe_allow_html=True)

    st.sidebar.markdown("<div class='nav-section'><h4>ğŸ› ï¸ Î•Ï€Î¹Î»Î¿Î³Î­Ï‚ Î‘Î½Î¬Î»Ï…ÏƒÎ·Ï‚</h4></div>", unsafe_allow_html=True)
    st.sidebar.info("â” Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Ï„Î¹Ï‚ ÏÏ…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚ ÏƒÎ±Ï‚ ÎºÎ±Î¹ Ï€ÏÎ¿Ï‡Ï‰ÏÎ®ÏƒÏ„Îµ ÏƒÏ„Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±!")

    waterbody_options = list(WATERBODY_FOLDERS.keys())
    default_wb_idx = 0 if waterbody_options else None

    waterbody = st.sidebar.selectbox("ğŸŒŠ Î¥Î´Î¬Ï„Î¹Î½Î¿ ÏƒÏÎ¼Î±", waterbody_options, index=default_wb_idx, key=SESSION_KEY_WATERBODY)
    index_name = st.sidebar.selectbox("ğŸ”¬ Î”ÎµÎ¯ÎºÏ„Î·Ï‚", ["Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ", "Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·", "Î˜Î¿Î»ÏŒÏ„Î·Ï„Î±"], key=SESSION_KEY_INDEX)
    analysis_type = st.sidebar.selectbox( "ğŸ“Š Î•Î¯Î´Î¿Ï‚ Î‘Î½Î¬Î»Ï…ÏƒÎ·Ï‚",
        ["Î•Ï€Î¹Ï†Î±Î½ÎµÎ¹Î±ÎºÎ® Î‘Ï€Î¿Ï„ÏÏ€Ï‰ÏƒÎ·", "Î ÏÎ¿Ï†Î¯Î» Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ ÎºÎ±Î¹ ÏƒÏ„Î¬Î¸Î¼Î·Ï‚", "EÏÎ³Î±Î»ÎµÎ¯Î± Î ÏÏŒÎ²Î»ÎµÏˆÎ·Ï‚ ÎºÎ±Î¹ Î­Î³ÎºÎ±Î¹ÏÎ·Ï‚ ÎµÎ½Î·Î¼Î­ÏÏ‰ÏƒÎ·Ï‚"],
        key=SESSION_KEY_ANALYSIS
    )
    st.sidebar.markdown(
        f"""<div style="padding: 0.7rem; background:#2c2f36; border-radius:8px; margin-top:1.2rem;">
        <strong>ğŸŒŠ Î¥Î´Î¬Ï„Î¹Î½Î¿ ÏƒÏÎ¼Î±:</strong> {waterbody or "<i>-</i>"}<br>
        <strong>ğŸ”¬ Î”ÎµÎ¯ÎºÏ„Î·Ï‚:</strong> {index_name or "<i>-</i>"}<br>
        <strong>ğŸ“Š Î‘Î½Î¬Î»Ï…ÏƒÎ·:</strong> {analysis_type or "<i>-</i>"}
        </div>""",
        unsafe_allow_html=True
    )
    st.sidebar.markdown("---")

@st.cache_data
def parse_sampling_kml(kml_source) -> list:
    try:
        if hasattr(kml_source, "seek"): kml_source.seek(0)
        tree = ET.parse(kml_source) if hasattr(kml_source, "read") else ET.parse(str(kml_source))
        root = tree.getroot()
        ns = {'kml': 'http://www.opengis.net/kml/2.2'}
        points = []
        for i_ls, ls in enumerate(root.findall('.//kml:LineString', ns)):
            coords_text_elem = ls.find('kml:coordinates', ns)
            if coords_text_elem is not None and coords_text_elem.text:
                coords = coords_text_elem.text.strip().split()
                for i_coord, coord_str in enumerate(coords):
                    try:
                        lon, lat, *_ = coord_str.split(',')
                        point_name = f"LS{i_ls+1}_P{i_coord+1}"
                        points.append((point_name, float(lon), float(lat)))
                    except ValueError: debug_message(f"Warning: KML: Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· ÏƒÏ…Î½Ï„ÎµÏ„Î±Î³Î¼Î­Î½Î·Ï‚ '{coord_str}'")
        if not points and kml_source: # Check if kml_source was provided but no points found
                st.warning("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÏƒÎ·Î¼ÎµÎ¯Î± LineString ÏƒÏ„Î¿ KML.")
        return points
    except FileNotFoundError:
        debug_message(f"Î ÏÎ¿ÎµÎ¹Î´Î¿Ï€Î¿Î¯Î·ÏƒÎ·: Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ KML '{kml_source}' Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ.")
        return []
    except Exception as e:
        st.error(f"Î£Ï†Î¬Î»Î¼Î± Î±Î½Î¬Î»Ï…ÏƒÎ·Ï‚ KML '{kml_source}': {e}")
        return []

def analyze_sampling_generic(sampling_points, first_image_data, first_transform,
                                images_folder, lake_height_path, selected_points_names,
                                lower_thresh=0, upper_thresh=255, date_min=None, date_max=None):
    results_colors = {name: [] for name, _, _ in sampling_points}
    results_mg = {name: [] for name, _, _ in sampling_points}

    if not os.path.isdir(images_folder):
        st.error(f"ÎŸ Ï†Î¬ÎºÎµÎ»Î¿Ï‚ ÎµÎ¹ÎºÏŒÎ½Ï‰Î½ '{images_folder}' Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ."); return go.Figure(), go.Figure(), go.Figure(), go.Figure(), {}, {}, pd.DataFrame()

    for filename in sorted(os.listdir(images_folder)):
        if not filename.lower().endswith(('.tif', '.tiff')): continue
        m = re.search(r'(\d{4})[_-]?(\d{2})[_-]?(\d{2})', filename)
        if not m: continue
        try: date_obj = datetime(int(m.group(1)), int(m.group(2)), int(m.group(3)))
        except ValueError: debug_message(f"Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· {filename}: Î¼Î· Î­Î³ÎºÏ…ÏÎ· Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±."); continue

        if (date_min and date_obj.date() < date_min) or \
           (date_max and date_obj.date() > date_max): continue

        try:
            with rasterio.open(os.path.join(images_folder, filename)) as src:
                if src.count < 3: debug_message(f"Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· {filename}: <3 ÎºÎ±Î½Î¬Î»Î¹Î±."); continue
                for name, lon, lat in sampling_points:
                    if name not in selected_points_names: continue
                    col, row = map(int, (~src.transform) * (lon, lat))
                    if not (0 <= col < src.width and 0 <= row < src.height): continue
                    win = rasterio.windows.Window(col,row,1,1)
                    try:
                        r,g,b = src.read(1,window=win)[0,0], src.read(2,window=win)[0,0], src.read(3,window=win)[0,0]
                        mg_val = (g / 255.0) * 2.0 # Placeholder conversion
                        results_mg[name].append((date_obj, mg_val))
                        results_colors[name].append((date_obj, (r/255., g/255., b/255.)))
                    except IndexError: debug_message(f"Î£Ï†Î¬Î»Î¼Î± Index pixel Î³Î¹Î± {name} ÏƒÏ„Î¿ {filename}.")
        except Exception as e: st.warning(f"Î£Ï†Î¬Î»Î¼Î± ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ {filename}: {e}")

    # Ensure first_image_data is suitable for px.imshow (e.g., 3 bands, normalized)
    if first_image_data is None or first_image_data.ndim != 3 or first_image_data.shape[0] < 3:
        st.error("ÎœÎ· Î­Î³ÎºÏ…ÏÎ± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Ï€ÏÏÏ„Î·Ï‚ ÎµÎ¹ÎºÏŒÎ½Î±Ï‚ Î³Î¹Î± ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ·.")
        return go.Figure(), go.Figure(), go.Figure(), go.Figure(), {}, {}, pd.DataFrame()

    rgb_disp = first_image_data[:3, :, :].transpose((1,2,0)) # Use first 3 bands
    if rgb_disp.max() > 1.0: # Normalize if not already in 0-1 range
        rgb_disp = rgb_disp / 255.0
    rgb_disp = np.clip(rgb_disp, 0, 1)


    fig_geo = px.imshow(rgb_disp, title='Î•Î¹ÎºÏŒÎ½Î± Î‘Î½Î±Ï†Î¿ÏÎ¬Ï‚ & Î£Î·Î¼ÎµÎ¯Î±'); fig_geo.update_layout(height=600, uirevision='geo')
    if first_transform: # Ensure transform is available
        for n,lon,lat in sampling_points:
            if n in selected_points_names:
                col,row = map(int, (~first_transform) * (lon,lat))
                fig_geo.add_trace(go.Scatter(x=[col],y=[row],mode='markers+text',marker=dict(color='red',size=10,symbol='x'),name=n,text=n,textposition="top right"))
    fig_geo.update_xaxes(visible=False); fig_geo.update_yaxes(visible=False,scaleanchor="x",scaleratio=1)

    df_h = pd.DataFrame(columns=['Date','Height'])
    if os.path.exists(str(lake_height_path)):
        try:
            df_h_temp = pd.read_excel(lake_height_path)
            if not df_h_temp.empty and len(df_h_temp.columns) >=2:
                df_h['Date']=pd.to_datetime(df_h_temp.iloc[:,0],errors='coerce'); df_h['Height']=pd.to_numeric(df_h_temp.iloc[:,1],errors='coerce')
                df_h.dropna(inplace=True); df_h.sort_values('Date',inplace=True)
        except Exception: df_h = pd.DataFrame(columns=['Date','Height'])

    fig_colors = make_subplots(specs=[[{"secondary_y":True}]]); pt_y_map={n:i for i,n in enumerate(selected_points_names)}
    for n_iter in selected_points_names:
        if n_iter in results_colors and results_colors[n_iter]:
            dts,cols=zip(*sorted(results_colors[n_iter],key=lambda x:x[0])) if results_colors[n_iter] else ([],[])
            c_rgb=[f"rgb({int(c[0]*255)},{int(c[1]*255)},{int(c[2]*255)})" for c in cols]
            fig_colors.add_trace(go.Scatter(x=list(dts),y=[pt_y_map.get(n_iter,-1)]*len(dts),mode='markers',marker=dict(color=c_rgb,size=10),name=n_iter),secondary_y=False)
    if not df_h.empty: fig_colors.add_trace(go.Scatter(x=df_h['Date'],y=df_h['Height'],name='Î£Ï„Î¬Î¸Î¼Î·',mode='lines',line=dict(color='blue')),secondary_y=True)
    fig_colors.update_layout(title='Î§ÏÏÎ¼Î±Ï„Î± Pixel & Î£Ï„Î¬Î¸Î¼Î·',yaxis=dict(tickmode='array',tickvals=list(pt_y_map.values()),ticktext=list(pt_y_map.keys())),yaxis2=dict(title='Î£Ï„Î¬Î¸Î¼Î· (m)'), uirevision='colors')

    all_mg_by_d={};
    for p_name in selected_points_names:
        if p_name in results_mg:
            for d,v in results_mg[p_name]: all_mg_by_d.setdefault(d,[]).append(v)
    s_dts_mg=sorted(all_mg_by_d.keys()); mean_mg=[np.mean(all_mg_by_d[d]) for d in s_dts_mg if all_mg_by_d[d]]
    fig_mg=go.Figure();
    if s_dts_mg and mean_mg: fig_mg.add_trace(go.Scatter(x=s_dts_mg,y=mean_mg,mode='lines+markers',marker=dict(color=mean_mg,colorscale='Viridis',colorbar=dict(title='mg/mÂ³'),size=8)))
    fig_mg.update_layout(title='ÎœÎ­ÏƒÎ¿ mg/mÂ³', uirevision='mg')

    fig_dual=make_subplots(specs=[[{"secondary_y":True}]])
    if not df_h.empty: fig_dual.add_trace(go.Scatter(x=df_h['Date'],y=df_h['Height'],name='Î£Ï„Î¬Î¸Î¼Î· Î›Î¯Î¼Î½Î·Ï‚',mode='lines'),secondary_y=False)
    if s_dts_mg and mean_mg: fig_dual.add_trace(go.Scatter(x=s_dts_mg,y=mean_mg,name='ÎœÎ­ÏƒÎ¿ mg/mÂ³',mode='lines+markers', marker=dict(color=mean_mg, colorscale='Viridis', showscale=False)),secondary_y=True)
    fig_dual.update_layout(title='Î£Ï„Î¬Î¸Î¼Î· & ÎœÎ­ÏƒÎ¿ mg/mÂ³', uirevision='dual',
                            yaxis=dict(title=dict(text="Î£Ï„Î¬Î¸Î¼Î· (m)",font=dict(color="deepskyblue")), tickfont=dict(color="deepskyblue"), side='left'),
                            yaxis2=dict(title=dict(text="ÎœÎ­ÏƒÎ¿ mg/mÂ³",font=dict(color="lightgreen")), tickfont=dict(color="lightgreen"), overlaying='y', side='right'))
    return fig_geo,fig_dual,fig_colors,fig_mg,results_colors,results_mg,df_h

@st.cache_resource
def create_chl_legend_figure(orientation="horizontal", theme_bg_color=None, theme_text_color=None):
    levels = [0, 6, 12, 20, 30, 50]
    colors = ["#496FF2", "#82D35F", "#FEFD05", "#FD0004", "#8E2026", "#D97CF5"]
    cmap = mcolors.LinearSegmentedColormap.from_list("ChlLegend", list(zip(np.linspace(0, 1, len(levels)), colors)))
    norm = mcolors.Normalize(vmin=levels[0], vmax=levels[-1])

    if orientation == "horizontal":
        fig, ax = plt.subplots(figsize=(7, 1.2))
        fig.subplots_adjust(bottom=0.45, top=0.9, left=0.05, right=0.95)
        cbar_orientation = "horizontal"
    else:
        fig, ax = plt.subplots(figsize=(1.8, 6))
        fig.subplots_adjust(left=0.3, right=0.7, top=0.95, bottom=0.05)
        cbar_orientation = "vertical"

    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
    sm.set_array([])
    cbar = fig.colorbar(sm, cax=ax, orientation=cbar_orientation, ticks=levels, aspect=30 if orientation=="horizontal" else 20, shrink=0.95)

    label_text = "Î£Ï…Î³ÎºÎ­Î½Ï„ÏÏ‰ÏƒÎ· Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·Ï‚-Î± (mg/mÂ³)"
    tick_labels = [str(l) for l in levels]

    if orientation == "horizontal":
        ax.set_xlabel(label_text, fontsize=10)
        ax.set_xticklabels(tick_labels, fontsize=9)
    else:
        ax.set_ylabel(label_text, fontsize=10)
        ax.set_yticklabels(tick_labels, fontsize=9)

    # Apply theme colors if provided
    if theme_bg_color:
        fig.patch.set_facecolor(theme_bg_color)
        ax.set_facecolor(theme_bg_color)
    if theme_text_color:
        ax.xaxis.label.set_color(theme_text_color)
        ax.yaxis.label.set_color(theme_text_color)
        ax.tick_params(axis='x', colors=theme_text_color)
        ax.tick_params(axis='y', colors=theme_text_color)
        cbar.ax.xaxis.label.set_color(theme_text_color) # Colorbar label for x-axis
        cbar.ax.yaxis.label.set_color(theme_text_color) # Colorbar label for y-axis
        cbar.ax.tick_params(axis='x', colors=theme_text_color) # Colorbar tick labels for x-axis
        cbar.ax.tick_params(axis='y', colors=theme_text_color) # Colorbar tick labels for y-axis


    plt.tight_layout(pad=0.5)
    return fig

@st.cache_data
def get_data_folder(waterbody: str, index_name: str) -> str | None:
    waterbody_folder_name = WATERBODY_FOLDERS.get(waterbody)
    if not waterbody_folder_name:
        st.error(f"Î”ÎµÎ½ Î­Ï‡ÎµÎ¹ Î¿ÏÎ¹ÏƒÏ„ÎµÎ¯ Î±Î½Ï„Î¹ÏƒÏ„Î¿Î¯Ï‡Î¹ÏƒÎ· Ï†Î±ÎºÎ­Î»Î¿Ï… Î³Î¹Î± Ï„Î¿ Ï…Î´Î¬Ï„Î¹Î½Î¿ ÏƒÏÎ¼Î±: '{waterbody}'.")
        return None

    index_specific_folder = ""
    if index_name == "Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ":
        # Assuming a general case now, remove specific "Koroneia" logic if not needed elsewhere
        index_specific_folder = "Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ"
    elif index_name == "Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·":
        index_specific_folder = "Chlorophyll"
    elif index_name == "Î˜Î¿Î»ÏŒÏ„Î·Ï„Î±":
        index_specific_folder = "Î˜Î¿Î»ÏŒÏ„Î·Ï„Î±"
    else:
        index_specific_folder = index_name # Fallback

    data_folder = os.path.join(APP_BASE_DIR, waterbody_folder_name, index_specific_folder)
    debug_message(f"DEBUG: Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· Ï†Î±ÎºÎ­Î»Î¿Ï… Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½: {data_folder}")

    if not os.path.exists(data_folder) or not os.path.isdir(data_folder):
        # This message is deferred to the calling function to avoid premature errors
        return None
    return data_folder

@st.cache_data
def extract_date_from_filename(filename: str) -> tuple[int | None, datetime | None]:
    basename = os.path.basename(filename)
    match = re.search(r'(\d{4})[_-]?(\d{2})[_-]?(\d{2})', basename)

    if match:
        year, month, day = map(int, match.groups())
        try:
            date_obj = datetime(year, month, day)
            day_of_year = date_obj.timetuple().tm_yday
            return day_of_year, date_obj
        except ValueError as e:
            debug_message(f"DEBUG: Î£Ï†Î¬Î»Î¼Î± Î¼ÎµÏ„Î±Ï„ÏÎ¿Ï€Î®Ï‚ Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±Ï‚ Î±Ï€ÏŒ '{basename}': {e}")
            return None, None
    return None, None

@st.cache_data
def load_lake_shape_from_xml(xml_file_path: str, bounds: tuple = None,
                                xml_width: float = 518.0, xml_height: float = 505.0):
    debug_message(f"DEBUG: Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Ï€ÎµÏÎ¹Î³ÏÎ¬Î¼Î¼Î±Ï„Î¿Ï‚ Î±Ï€ÏŒ: {xml_file_path}")
    try:
        tree = ET.parse(xml_file_path)
        root = tree.getroot()
        points_xml = []
        for point_elem in root.findall("point"):
            x_str, y_str = point_elem.get("x"), point_elem.get("y")
            if x_str and y_str: points_xml.append([float(x_str), float(y_str)])

        if not points_xml:
            st.warning(f"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÏƒÎ·Î¼ÎµÎ¯Î± ÏƒÏ„Î¿ XML: {os.path.basename(xml_file_path)}"); return None

        points_to_return = points_xml
        if bounds:
            minx, miny, maxx, maxy = bounds
            points_to_return = [[minx + (x/xml_width)*(maxx-minx), maxy - (y/xml_height)*(maxy-miny)] for x,y in points_xml]

        if points_to_return and (points_to_return[0] != points_to_return[-1]):
            points_to_return.append(points_to_return[0]) # Close the polygon

        debug_message(f"DEBUG: Î¦Î¿ÏÏ„ÏÎ¸Î·ÎºÎ±Î½ {len(points_to_return)} ÏƒÎ·Î¼ÎµÎ¯Î± Ï€ÎµÏÎ¹Î³ÏÎ¬Î¼Î¼Î±Ï„Î¿Ï‚.")
        return {"type": "Polygon", "coordinates": [points_to_return]}
    except FileNotFoundError:
        st.error(f"Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ XML Ï€ÎµÏÎ¹Î³ÏÎ¬Î¼Î¼Î±Ï„Î¿Ï‚ Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ: {xml_file_path}"); return None
    except Exception as e:
        st.error(f"Î£Ï†Î¬Î»Î¼Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ Ï€ÎµÏÎ¹Î³ÏÎ¬Î¼Î¼Î±Ï„Î¿Ï‚ Î±Ï€ÏŒ {os.path.basename(xml_file_path)}: {e}"); return None

@st.cache_data
def read_image(file_path: str, lake_shape: dict = None):
    debug_message(f"DEBUG: Î‘Î½Î¬Î³Î½Ï‰ÏƒÎ· ÎµÎ¹ÎºÏŒÎ½Î±Ï‚: {file_path}")
    try:
        with rasterio.open(file_path) as src:
            img = src.read(1).astype(np.float32)
            profile = src.profile.copy(); profile.update(dtype="float32")

            if src.nodata is not None: img = np.where(img == src.nodata, np.nan, img)
            img = np.where(img == 0, np.nan, img) # Treat 0 as NaN if appropriate

            if lake_shape:
                from rasterio.features import geometry_mask
                poly_mask = geometry_mask([lake_shape], transform=src.transform, invert=True, out_shape=img.shape) # Invert=True to keep data INSIDE
                img = np.where(poly_mask, img, np.nan)
            return img, profile
    except Exception as e:
        st.warning(f"Î ÏÎ¿ÎµÎ¹Î´Î¿Ï€Î¿Î¯Î·ÏƒÎ·: Î£Ï†Î¬Î»Î¼Î± Î±Î½Î¬Î³Î½Ï‰ÏƒÎ·Ï‚ ÎµÎ¹ÎºÏŒÎ½Î±Ï‚ {os.path.basename(file_path)}: {e}. Î Î±ÏÎ±Î»ÎµÎ¯Ï€ÎµÏ„Î±Î¹."); return None, None

@st.cache_data
def load_data_for_lake_processing(input_folder: str, shapefile_name="shapefile.xml"):
    debug_message(f"DEBUG: load_data_for_lake_processing Î³Î¹Î±: {input_folder}")
    if not os.path.exists(input_folder):
        st.error(f"ÎŸ Ï†Î¬ÎºÎµÎ»Î¿Ï‚ ÎµÎ¹ÏƒÏŒÎ´Î¿Ï… Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹: {input_folder}"); return None, None, None, None

    shape_file_path = next((sp for sp in [os.path.join(input_folder, shapefile_name), os.path.join(input_folder, "shapefile.txt")] if os.path.exists(sp)), None)
    if shape_file_path: debug_message(f"Î’ÏÎ­Î¸Î·ÎºÎµ Î±ÏÏ‡ÎµÎ¯Î¿ Ï€ÎµÏÎ¹Î³ÏÎ¬Î¼Î¼Î±Ï„Î¿Ï‚: {shape_file_path}")

    tif_files = sorted([fp for fp in glob.glob(os.path.join(input_folder, "*.tif")) if os.path.basename(fp).lower() != "mask.tif"])
    if not tif_files:
        st.warning(f"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ GeoTIFF Î±ÏÏ‡ÎµÎ¯Î± ÏƒÏ„Î¿Î½ Ï†Î¬ÎºÎµÎ»Î¿: {input_folder}"); return None, None, None, None

    first_profile, lake_geom = None, None
    try:
        with rasterio.open(tif_files[0]) as src_first:
            first_profile = src_first.profile.copy()
            if shape_file_path: lake_geom = load_lake_shape_from_xml(shape_file_path, bounds=src_first.bounds)
    except Exception as e:
        st.error(f"Î£Ï†Î¬Î»Î¼Î± Ï€ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î±ÏƒÎ¯Î±Ï‚ Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ (Ï€ÏÏÏ„Î· ÎµÎ¹ÎºÏŒÎ½Î±/shapefile): {e}"); return None, None, None, None

    images, days, dates_list = [], [], []
    for fp_iter in tif_files:
        day_yr, date_obj = extract_date_from_filename(fp_iter)
        if day_yr is None: continue
        img_data, _ = read_image(fp_iter, lake_shape=lake_geom)
        if img_data is not None: images.append(img_data); days.append(day_yr); dates_list.append(date_obj)

    if not images:
        st.warning(f"Î”ÎµÎ½ Ï†Î¿ÏÏ„ÏÎ¸Î·ÎºÎ±Î½ Î­Î³ÎºÏ…ÏÎµÏ‚ ÎµÎ¹ÎºÏŒÎ½ÎµÏ‚ Î±Ï€ÏŒ Ï„Î¿Î½ Ï†Î¬ÎºÎµÎ»Î¿: {input_folder}."); return None, None, None, None
    return np.stack(images, axis=0), np.array(days), dates_list, first_profile


def run_lake_processing_app(waterbody: str, index_name: str):
    with st.container():
        st.markdown('<div class="card">', unsafe_allow_html=True) # Changed from custom-card to card
        st.header(f"Î•Ï€Î¹Ï†Î±Î½ÎµÎ¹Î±ÎºÎ® Î‘Ï€Î¿Ï„ÏÏ€Ï‰ÏƒÎ·: {waterbody} - {index_name}")

        data_folder = get_data_folder(waterbody, index_name)
        if not data_folder:
            expected_folder_name = ""
            if index_name == "Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ": expected_folder_name = "Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ"
            elif index_name == "Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·": expected_folder_name = "Chlorophyll"
            elif index_name == "Î˜Î¿Î»ÏŒÏ„Î·Ï„Î±": expected_folder_name = "Î˜Î¿Î»ÏŒÏ„Î·Ï„Î±"
            else: expected_folder_name = index_name
            
            waterbody_actual_folder = WATERBODY_FOLDERS.get(waterbody, 'ÎœÎ—_ÎšÎ‘Î˜ÎŸÎ¡Î™Î£ÎœÎ•ÎÎŸ_Î¦Î‘ÎšÎ•Î›ÎŸ')
            st.error(f"ÎŸ Ï†Î¬ÎºÎµÎ»Î¿Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î³Î¹Î± '{waterbody} - {index_name}' Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ. "
                        f"Î•Î»Î­Î³Î¾Ï„Îµ ÏŒÏ„Î¹ Î¿ Ï†Î¬ÎºÎµÎ»Î¿Ï‚ '{expected_folder_name}' "
                        f"Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î¼Î­ÏƒÎ± ÏƒÏ„Î¿Î½ ÎºÎ±Ï„Î¬Î»Î¿Î³Î¿ '{os.path.join(APP_BASE_DIR, waterbody_actual_folder)}'.")
            st.markdown('</div>', unsafe_allow_html=True); return

        input_folder_geotiffs = os.path.join(data_folder, "GeoTIFFs")
        
        with st.spinner(f"Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î³Î¹Î± {waterbody} - {index_name}..."):
            STACK, DAYS, DATES, _ = load_data_for_lake_processing(input_folder_geotiffs)

        if STACK is None or not DATES:
            st.markdown('</div>', unsafe_allow_html=True); return

        st.sidebar.subheader(f"Î¦Î¯Î»Ï„ÏÎ± Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ ({index_name})") # Simplified title
        min_avail_date = min(DATES).date() if DATES else date.today()
        max_avail_date = max(DATES).date() if DATES else date.today()
        unique_years_avail = sorted(list(set(d.year for d in DATES if d))) if DATES else []

        clean_index_name_for_key = re.sub(r'[^a-zA-Z0-9_]', '', index_name) 
        key_suffix = f"_lp_{waterbody}_{clean_index_name_for_key}"
        common_filename_prefix = f"{waterbody}_{index_name}_surface_map"

        threshold_range_val = st.sidebar.slider("Î•ÏÏÎ¿Ï‚ Ï„Î¹Î¼ÏÎ½ pixel:", 0, 255, (0, 255), 
                                                key=f"thresh{key_suffix}", 
                                                help="ÎŸÏÎ¯ÏƒÏ„Îµ Ï„Î¿ ÎºÎ±Ï„ÏÏ†Î»Î¹ ÎºÎ±Î¹ Î±Î½ÏÏ†Î»Î¹ Î³Î¹Î± Ï„Î¹Ï‚ Ï„Î¹Î¼Î­Ï‚ pixel.")
        
        col_start_lp, col_end_lp = st.sidebar.columns(2)
        refined_start_val = col_start_lp.date_input("ÎˆÎ½Î±ÏÎ¾Î· Ï€ÎµÏÎ¹ÏŒÎ´Î¿Ï…:", value=min_avail_date, 
                                                    min_value=min_avail_date, max_value=max_avail_date, 
                                                    key=f"refined_start{key_suffix}")
        refined_end_val = col_end_lp.date_input("Î›Î®Î¾Î· Ï€ÎµÏÎ¹ÏŒÎ´Î¿Ï…:", value=max_avail_date, 
                                                min_value=min_avail_date, max_value=max_avail_date, 
                                                key=f"refined_end{key_suffix}")
        
        if refined_start_val > refined_end_val:
            st.sidebar.error("Î— Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î± Î­Î½Î±ÏÎ¾Î·Ï‚ Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎµÎ¯Î½Î±Î¹ Ï€ÏÎ¹Î½ Î® Î¯Î´Î¹Î± Î¼Îµ Ï„Î·Î½ Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î± Î»Î®Î¾Î·Ï‚.")
            st.markdown('</div>', unsafe_allow_html=True); return
            
        display_option_val = st.sidebar.radio("Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· ÎœÎ­ÏƒÎ¿Ï… Î”ÎµÎ¯Î³Î¼Î±Ï„Î¿Ï‚:", 
                                            options=["Thresholded", "Original"], index=0, 
                                            key=f"display_opt{key_suffix}", horizontal=True)

        month_options_map = {i: datetime(2000, i, 1).strftime('%B') for i in range(1, 13)}
        
        default_months = st.session_state.get(f"sel_months{key_suffix}", list(month_options_map.keys()))
        selected_months_val = st.sidebar.multiselect("Î•Ï€Î¹Î»Î¿Î³Î® ÎœÎ·Î½ÏÎ½:",
                                                    options=list(month_options_map.keys()),
                                                    format_func=lambda x: month_options_map[x],
                                                    default=default_months,
                                                    key=f"sel_months{key_suffix}")
        
        default_years = st.session_state.get(f"sel_years{key_suffix}", unique_years_avail)
        selected_years_val = st.sidebar.multiselect("Î•Ï€Î¹Î»Î¿Î³Î® Î•Ï„ÏÎ½:", 
                                                    options=unique_years_avail,
                                                    default=default_years,
                                                    key=f"sel_years{key_suffix}")
        
        start_dt_conv = datetime.combine(refined_start_val, datetime.min.time())
        end_dt_conv = datetime.combine(refined_end_val, datetime.max.time())

        indices_to_keep = [
            i for i, dt_obj in enumerate(DATES)
            if (start_dt_conv <= dt_obj <= end_dt_conv and
                (not selected_months_val or dt_obj.month in selected_months_val) and
                (not selected_years_val or dt_obj.year in selected_years_val))
        ]

        if not indices_to_keep:
            st.info("Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± Ï„Î·Î½ ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î· Ï€ÎµÏÎ¯Î¿Î´Î¿/Î¼Î®Î½ÎµÏ‚/Î­Ï„Î·. Î Î±ÏÎ±ÎºÎ±Î»Ï Ï€ÏÎ¿ÏƒÎ±ÏÎ¼ÏŒÏƒÏ„Îµ Ï„Î± Ï†Î¯Î»Ï„ÏÎ±.")
            st.markdown('</div>', unsafe_allow_html=True); return

        with st.spinner("Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Ï†Î¹Î»Ï„ÏÎ±ÏÎ¹ÏƒÎ¼Î­Î½Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÎºÎ±Î¹ Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î³ÏÎ±Ï†Î·Î¼Î¬Ï„Ï‰Î½..."):
            stack_filt = STACK[indices_to_keep, :, :]
            days_filt = DAYS[indices_to_keep]
            filtered_dates_objects = [DATES[i] for i in indices_to_keep]

            lower_t, upper_t = threshold_range_val
            in_range_bool_mask = np.logical_and(stack_filt >= lower_t, stack_filt <= upper_t)
            
            st.subheader("Î‘Î½Î¬Î»Ï…ÏƒÎ· Î§Î±ÏÏ„ÏÎ½")
            expander_col1, expander_col2 = st.columns(2)

            with expander_col1:
                with st.expander("Î§Î¬ÏÏ„Î·Ï‚: Î—Î¼Î­ÏÎµÏ‚ ÎµÎ½Ï„ÏŒÏ‚ Î•ÏÏÎ¿Ï…Ï‚ Î¤Î¹Î¼ÏÎ½", expanded=True):
                    days_in_range_map = np.nansum(in_range_bool_mask, axis=0)
                    fig_days = px.imshow(days_in_range_map, color_continuous_scale="plasma", labels={"color": "Î—Î¼Î­ÏÎµÏ‚"})
                    st.plotly_chart(fig_days, use_container_width=True, key=f"fig_days_map{key_suffix}")
                    df_days_in_range = pd.DataFrame(days_in_range_map)
                    add_excel_download_button(df_days_in_range, common_filename_prefix, "Days_in_Range_Map", f"excel_days_map{key_suffix}")
                    st.caption("Î”ÎµÎ¯Ï‡Î½ÎµÎ¹ Ï€ÏŒÏƒÎµÏ‚ Î·Î¼Î­ÏÎµÏ‚ ÎºÎ¬Î¸Îµ pixel Î®Ï„Î±Î½ ÎµÎ½Ï„ÏŒÏ‚ Ï„Î¿Ï… ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î¿Ï… ÎµÏÏÎ¿Ï…Ï‚ Ï„Î¹Î¼ÏÎ½.")

            tick_vals_days = [1,32,60,91,121,152,182,213,244,274,305,335,365]
            tick_text_days = ["Î™Î±Î½","Î¦ÎµÎ²","ÎœÎ±Ï","Î‘Ï€Ï","ÎœÎ±Î","Î™Î¿Ï…Î½","Î™Î¿Ï…Î»","Î‘Ï…Î³","Î£ÎµÏ€","ÎŸÎºÏ„","ÎÎ¿Îµ","Î”ÎµÎº",""]

            with expander_col2:
                with st.expander("Î§Î¬ÏÏ„Î·Ï‚: ÎœÎ­ÏƒÎ· Î—Î¼Î­ÏÎ± Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ·Ï‚ ÎµÎ½Ï„ÏŒÏ‚ Î•ÏÏÎ¿Ï…Ï‚", expanded=True):
                    days_array_expanded = days_filt.reshape((-1, 1, 1))
                    sum_days_in_range = np.nansum(days_array_expanded * in_range_bool_mask, axis=0)
                    count_pixels_in_range = np.nansum(in_range_bool_mask, axis=0)
                    mean_day_map = np.divide(sum_days_in_range, count_pixels_in_range, 
                                            out=np.full(sum_days_in_range.shape, np.nan), 
                                            where=(count_pixels_in_range != 0))
                    fig_mean_day = px.imshow(mean_day_map, color_continuous_scale="RdBu", 
                                            labels={"color": "ÎœÎ­ÏƒÎ· Î—Î¼Î­ÏÎ± (1-365)"},
                                            color_continuous_midpoint=182)
                    fig_mean_day.update_layout(coloraxis_colorbar=dict(tickmode='array', tickvals=tick_vals_days, ticktext=tick_text_days))
                    st.plotly_chart(fig_mean_day, use_container_width=True, key=f"fig_mean_day_map{key_suffix}")
                    df_mean_day_map = pd.DataFrame(mean_day_map)
                    add_excel_download_button(df_mean_day_map, common_filename_prefix, "Mean_Day_Map", f"excel_mean_day_map{key_suffix}")
                    st.caption("Î”ÎµÎ¯Ï‡Î½ÎµÎ¹ Ï„Î· Î¼Î­ÏƒÎ· Î·Î¼Î­ÏÎ± Ï„Î¿Ï… Î­Ï„Î¿Ï…Ï‚ Ï€Î¿Ï… Î­Î½Î± pixel Î®Ï„Î±Î½ ÎµÎ½Ï„ÏŒÏ‚ Ï„Î¿Ï… ÎµÏÏÎ¿Ï…Ï‚ Ï„Î¹Î¼ÏÎ½.")

            st.subheader("Î‘Î½Î¬Î»Ï…ÏƒÎ· Î”ÎµÎ¯Î³Î¼Î±Ï„Î¿Ï‚ Î•Î¹ÎºÏŒÎ½Î±Ï‚")
            expander_col3, expander_col4 = st.columns(2)

            with expander_col3:
                with st.expander("Î§Î¬ÏÏ„Î·Ï‚: ÎœÎ­ÏƒÎ¿ Î”ÎµÎ¯Î³Î¼Î± Î•Î¹ÎºÏŒÎ½Î±Ï‚", expanded=True):
                    average_sample_img_display = None
                    if display_option_val.lower() == "thresholded":
                        filtered_stack_for_avg = np.where(in_range_bool_mask, stack_filt, np.nan)
                        average_sample_img_display = np.nanmean(filtered_stack_for_avg, axis=0)
                    else: # Original
                        average_sample_img_display = np.nanmean(stack_filt, axis=0)

                    if average_sample_img_display is not None and not np.all(np.isnan(average_sample_img_display)):
                        avg_min_disp = float(np.nanmin(average_sample_img_display))
                        avg_max_disp = float(np.nanmax(average_sample_img_display))
                        fig_sample_disp = px.imshow(average_sample_img_display, color_continuous_scale="jet",
                                                    range_color=[avg_min_disp, avg_max_disp] if avg_min_disp < avg_max_disp else None,
                                                    labels={"color": "Î¤Î¹Î¼Î® Pixel"})
                        st.plotly_chart(fig_sample_disp, use_container_width=True, key=f"fig_sample_map{key_suffix}")
                        df_avg_sample_display = pd.DataFrame(average_sample_img_display)
                        add_excel_download_button(df_avg_sample_display, common_filename_prefix, "Average_Sample_Map", f"excel_avg_sample_map{key_suffix}")
                        st.caption(f"ÎœÎ­ÏƒÎ· Ï„Î¹Î¼Î® pixel (ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ·: {display_option_val}).")
                    else:
                        st.caption("Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± Ï„Î¿ 'ÎœÎ­ÏƒÎ¿ Î”ÎµÎ¯Î³Î¼Î± Î•Î¹ÎºÏŒÎ½Î±Ï‚'.")
            
            with expander_col4:
                with st.expander("Î§Î¬ÏÏ„Î·Ï‚: Î§ÏÏŒÎ½Î¿Ï‚ ÎœÎ­Î³Î¹ÏƒÏ„Î·Ï‚ Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ·Ï‚ ÎµÎ½Ï„ÏŒÏ‚ Î•ÏÏÎ¿Ï…Ï‚", expanded=True):
                    stack_for_time_max = np.where(in_range_bool_mask, stack_filt, np.nan) 
                    time_max_map = np.full(stack_for_time_max.shape[1:], np.nan, dtype=float)
                    valid_pixels_mask = ~np.all(np.isnan(stack_for_time_max), axis=0)
                    
                    if np.any(valid_pixels_mask) and filtered_dates_objects: 
                        max_indices_flat = np.nanargmax(stack_for_time_max[:, valid_pixels_mask], axis=0)
                        days_for_time_max = np.array([d.timetuple().tm_yday for d in filtered_dates_objects])
                        if len(days_for_time_max) > 0: 
                            valid_max_indices = np.clip(max_indices_flat, 0, len(days_for_time_max) - 1)
                            time_max_map[valid_pixels_mask] = days_for_time_max[valid_max_indices]

                    fig_time_max = px.imshow(time_max_map, color_continuous_scale="RdBu", 
                                            labels={"color": "Î—Î¼Î­ÏÎ± ÎœÎ­Î³Î¹ÏƒÏ„Î·Ï‚ (1-365)"},
                                            color_continuous_midpoint=182,
                                            range_color=[1,365])
                    fig_time_max.update_layout(coloraxis_colorbar=dict(tickmode='array', tickvals=tick_vals_days, ticktext=tick_text_days))
                    st.plotly_chart(fig_time_max, use_container_width=True, key=f"fig_time_max_map{key_suffix}")
                    df_time_max_map = pd.DataFrame(time_max_map)
                    add_excel_download_button(df_time_max_map, common_filename_prefix, "Time_Max_Value_Map", f"excel_time_max_map{key_suffix}")
                    st.caption("Î”ÎµÎ¯Ï‡Î½ÎµÎ¹ Ï„Î·Î½ Î·Î¼Î­ÏÎ± Ï„Î¿Ï… Î­Ï„Î¿Ï…Ï‚ Ï€Î¿Ï… ÎºÎ¬Î¸Îµ pixel ÎµÎ¯Ï‡Îµ Ï„Î· Î¼Î­Î³Î¹ÏƒÏ„Î· Ï„Î¹Î¼Î® (ÎµÎ½Ï„ÏŒÏ‚ Ï„Î¿Ï… ÎµÏÏÎ¿Ï…Ï‚).")

            st.subheader("Î ÏÏŒÏƒÎ¸ÎµÏ„Î· Î‘Î½Î¬Î»Ï…ÏƒÎ· ÎšÎ±Ï„Î±Î½Î¿Î¼Î®Ï‚ Î—Î¼ÎµÏÏÎ½ ÎµÎ½Ï„ÏŒÏ‚ Î•ÏÏÎ¿Ï…Ï‚")
            stack_full_in_range = (STACK >= lower_t) & (STACK <= upper_t)
            num_cols_display = 3
            
            with st.expander("ÎœÎ·Î½Î¹Î±Î¯Î± ÎšÎ±Ï„Î±Î½Î¿Î¼Î® Î—Î¼ÎµÏÏÎ½ ÎµÎ½Ï„ÏŒÏ‚ Î•ÏÏÎ¿Ï…Ï‚", expanded=False):
                st.caption("Î•Î¼Ï†Î±Î½Î¯Î¶Î¿Î½Ï„Î±Î¹ Î¼ÏŒÎ½Î¿ Î¿Î¹ Î¼Î®Î½ÎµÏ‚ Ï€Î¿Ï… Î­Ï‡Î¿Ï…Î½ ÎµÏ€Î¹Î»ÎµÎ³ÎµÎ¯ Ï€Î±ÏÎ±Ï€Î¬Î½Ï‰.")
                months_to_show = [m for m in range(1, 13) if m in selected_months_val]
                if not months_to_show:
                    st.info("Î”ÎµÎ½ Î­Ï‡Î¿Ï…Î½ ÎµÏ€Î¹Î»ÎµÎ³ÎµÎ¯ Î¼Î®Î½ÎµÏ‚ Î³Î¹Î± Ï„Î·Î½ Î¼Î·Î½Î¹Î±Î¯Î± Î±Î½Î¬Î»Ï…ÏƒÎ·.")
                else:
                    cols_monthly = st.columns(num_cols_display)
                    col_idx_monthly = 0
                    for month_num in months_to_show:
                        indices_for_month_all_years = [
                            i for i, dt_obj in enumerate(DATES)
                            if dt_obj.month == month_num and (not selected_years_val or dt_obj.year in selected_years_val)
                        ]
                        if indices_for_month_all_years:
                            monthly_sum_in_range = np.sum(stack_full_in_range[indices_for_month_all_years, :, :], axis=0)
                            month_name_disp = month_options_map[month_num]
                            fig_month_disp = px.imshow(monthly_sum_in_range, color_continuous_scale="plasma", title=month_name_disp, labels={"color": "Î—Î¼Î­ÏÎµÏ‚"})
                            fig_month_disp.update_layout(margin=dict(l=0,r=0,t=30,b=0), height=350)
                            fig_month_disp.update_coloraxes(showscale=False)
                            cols_monthly[col_idx_monthly].plotly_chart(fig_month_disp, use_container_width=True, key=f"fig_month_{month_num}{key_suffix}")
                            df_monthly_sum = pd.DataFrame(monthly_sum_in_range)
                            add_excel_download_button(df_monthly_sum, common_filename_prefix, f"Monthly_Dist_{month_name_disp}", f"excel_month_{month_num}{key_suffix}")
                            col_idx_monthly = (col_idx_monthly + 1) % num_cols_display
            
            with st.expander("Î•Ï„Î®ÏƒÎ¹Î± ÎšÎ±Ï„Î±Î½Î¿Î¼Î® Î—Î¼ÎµÏÏÎ½ ÎµÎ½Ï„ÏŒÏ‚ Î•ÏÏÎ¿Ï…Ï‚", expanded=False):
                st.caption("Î•Î¼Ï†Î±Î½Î¯Î¶Î¿Î½Ï„Î±Î¹ Î¼ÏŒÎ½Î¿ Ï„Î± Î­Ï„Î· Ï€Î¿Ï… Î­Ï‡Î¿Ï…Î½ ÎµÏ€Î¹Î»ÎµÎ³ÎµÎ¯ Ï€Î±ÏÎ±Ï€Î¬Î½Ï‰.")
                years_to_show = [y for y in unique_years_avail if y in selected_years_val]
                if not years_to_show:
                    st.info("Î”ÎµÎ½ Î­Ï‡Î¿Ï…Î½ ÎµÏ€Î¹Î»ÎµÎ³ÎµÎ¯ Î­Ï„Î· Î³Î¹Î± Ï„Î·Î½ ÎµÏ„Î®ÏƒÎ¹Î± Î±Î½Î¬Î»Ï…ÏƒÎ·.")
                else:
                    cols_yearly = st.columns(num_cols_display)
                    col_idx_yearly = 0
                    for year_val in years_to_show:
                        indices_for_year_selected_months = [
                            i for i, dt_obj in enumerate(DATES)
                            if dt_obj.year == year_val and (not selected_months_val or dt_obj.month in selected_months_val)
                        ]
                        if indices_for_year_selected_months:
                            yearly_sum_in_range = np.sum(stack_full_in_range[indices_for_year_selected_months, :, :], axis=0)
                            fig_year_disp = px.imshow(yearly_sum_in_range, color_continuous_scale="plasma", title=f"ÎˆÏ„Î¿Ï‚: {year_val}", labels={"color": "Î—Î¼Î­ÏÎµÏ‚"})
                            fig_year_disp.update_layout(margin=dict(l=0,r=0,t=30,b=0), height=350)
                            fig_year_disp.update_coloraxes(showscale=False)
                            cols_yearly[col_idx_yearly].plotly_chart(fig_year_disp, use_container_width=True, key=f"fig_year_{year_val}{key_suffix}")
                            df_yearly_sum = pd.DataFrame(yearly_sum_in_range)
                            add_excel_download_button(df_yearly_sum, common_filename_prefix, f"Yearly_Dist_Year_{year_val}", f"excel_year_{year_val}{key_suffix}")
                            col_idx_yearly = (col_idx_yearly + 1) % num_cols_display
        st.markdown('</div>', unsafe_allow_html=True)

def image_navigation_ui(images_folder: str, available_dates_map: dict, 
                        session_state_key_for_idx: str, key_prefix: str,
                        show_legend: bool = False, index_name_for_legend: str = ""):
    if not available_dates_map:
        st.info("Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼ÎµÏ‚ ÎµÎ¹ÎºÏŒÎ½ÎµÏ‚ Î¼Îµ Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±."); return None

    sorted_date_strings = sorted(available_dates_map.keys())
    
    if session_state_key_for_idx not in st.session_state:
        st.session_state[session_state_key_for_idx] = 0

    current_idx = st.session_state[session_state_key_for_idx]
    if current_idx >= len(sorted_date_strings): # Handle empty or out-of-bounds index
        current_idx = 0
        st.session_state[session_state_key_for_idx] = current_idx


    col_prev, col_select, col_next = st.columns([1,2,1])
    if col_prev.button("<< Î ÏÎ¿Î·Î³.", key=f"{key_prefix}_prev", help="Î ÏÎ¿Î·Î³Î¿ÏÎ¼ÎµÎ½Î· ÎµÎ¹ÎºÏŒÎ½Î±", use_container_width=True):
        current_idx = max(0, current_idx - 1)
        st.session_state[session_state_key_for_idx] = current_idx; st.rerun()

    if col_next.button("Î•Ï€ÏŒÎ¼. >>", key=f"{key_prefix}_next", help="Î•Ï€ÏŒÎ¼ÎµÎ½Î· ÎµÎ¹ÎºÏŒÎ½Î±", use_container_width=True):
        current_idx = min(len(sorted_date_strings) - 1, current_idx + 1)
        st.session_state[session_state_key_for_idx] = current_idx; st.rerun()
            
    def update_idx_from_select_nav(): 
        selected_val = st.session_state[f"{key_prefix}_select_nav"]
        if selected_val in sorted_date_strings:
                st.session_state[session_state_key_for_idx] = sorted_date_strings.index(selected_val)

    col_select.selectbox("Î•Ï€Î¹Î»Î¿Î³Î® Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±Ï‚:", options=sorted_date_strings, index=current_idx, 
                        key=f"{key_prefix}_select_nav", on_change=update_idx_from_select_nav,
                        label_visibility="collapsed")
    
    current_idx = st.session_state[session_state_key_for_idx] 
    actual_selected_date_str = sorted_date_strings[current_idx]

    st.caption(f"Î•Î¼Ï†Î±Î½Î¯Î¶ÎµÏ„Î±Î¹ ÎµÎ¹ÎºÏŒÎ½Î± Î³Î¹Î±: {actual_selected_date_str}")
    image_filename = available_dates_map[actual_selected_date_str]
    image_full_path = os.path.join(images_folder, image_filename)

    if os.path.exists(image_full_path):
        st.image(image_full_path, caption=f"{image_filename}", use_column_width=True)
        if show_legend and index_name_for_legend == "Î§Î»Ï‰ÏÎ¿Ï†ÏÎ»Î»Î·":
            try: # Use Streamlit's theme colors if available
                theme_bg = st.get_option("theme.backgroundColor")
                theme_text = st.get_option("theme.textColor")
                legend_fig = create_chl_legend_figure(orientation="horizontal", theme_bg_color=theme_bg, theme_text_color=theme_text)
            except: # Fallback if theme options are not accessible (e.g., older Streamlit version)
                legend_fig = create_chl_legend_figure(orientation="horizontal")
            st.pyplot(legend_fig)
    else:
        st.error(f"Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ ÎµÎ¹ÎºÏŒÎ½Î±Ï‚ Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ: {image_full_path}")
    return image_full_path


def analyze_sampling_for_dashboard(sampling_points: list, first_image_data_rgb, first_image_transform,
                                    images_folder_path: str, lake_height_excel_path: str, 
                                    selected_point_names_for_plot: list | None = None):
    def _geographic_to_pixel(lon: float, lat: float, transform_matrix) -> tuple[int, int]:
        inv_transform = ~transform_matrix; px, py = inv_transform * (lon, lat); return int(px), int(py)

    def _map_rgb_to_mg(r_val: float, g_val: float, b_val: float, mg_factor: float = 2.0) -> float:
        return (g_val / 255.0) * mg_factor 

    results_colors_dash, results_mg_dash = {n:[] for n,_,_ in sampling_points}, {n:[] for n,_,_ in sampling_points}
    if not os.path.isdir(images_folder_path):
        st.error(f"ÎŸ Ï†Î¬ÎºÎµÎ»Î¿Ï‚ ÎµÎ¹ÎºÏŒÎ½Ï‰Î½ '{images_folder_path}' Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Î³Î¹Î± dashboard."); return go.Figure(),go.Figure(),go.Figure(),go.Figure(),{},{},pd.DataFrame()

    for filename in sorted(os.listdir(images_folder_path)):
        if not filename.lower().endswith(('.tif', '.tiff')): continue
        m = re.search(r'(\d{4})[_-]?(\d{2})[_-]?(\d{2})', filename)
        if not m: continue
        try: date_obj = datetime(int(m.groups()[0]), int(m.groups()[1]), int(m.groups()[2]))
        except ValueError: continue

        try:
            with rasterio.open(os.path.join(images_folder_path, filename)) as src:
                if src.count < 3: continue
                for name, lon, lat in sampling_points:
                    col, row = _geographic_to_pixel(lon, lat, src.transform)
                    if 0 <= col < src.width and 0 <= row < src.height:
                        win = rasterio.windows.Window(col,row,1,1)
                        pixel_data = src.read([1,2,3], window=win)
                        r,g,b = pixel_data[0,0,0], pixel_data[1,0,0], pixel_data[2,0,0]
                        
                        mg_v = _map_rgb_to_mg(r,g,b)
                        results_mg_dash[name].append((date_obj, mg_v))
                        results_colors_dash[name].append((date_obj, (r/255.,g/255.,b/255.)))
        except Exception as e: debug_message(f"Î£Ï†Î¬Î»Î¼Î± {filename} Î³Î¹Î± dashboard: {e}"); continue
            
    if first_image_data_rgb is None or first_image_transform is None:
        st.error("Î”ÎµÎ´Î¿Î¼Î­Î½Î± ÎµÎ¹ÎºÏŒÎ½Î±Ï‚ Î±Î½Î±Ï†Î¿ÏÎ¬Ï‚ (first_image_data_rgb / first_image_transform) Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î±.")
        return go.Figure(),go.Figure(),go.Figure(),go.Figure(),{},{},pd.DataFrame()

    rgb_disp_data = first_image_data_rgb.transpose((1,2,0))
    if rgb_disp_data.max() > 1:
        rgb_disp_data = rgb_disp_data / 255.0
    rgb_disp_data = np.clip(rgb_disp_data, 0, 1)

    fig_geo_d = px.imshow(rgb_disp_data, title='Î•Î¹ÎºÏŒÎ½Î± Î‘Î½Î±Ï†Î¿ÏÎ¬Ï‚ & Î£Î·Î¼ÎµÎ¯Î± Î”ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î±Ï‚')
    for n,lon,lat in sampling_points:
        col,row=_geographic_to_pixel(lon,lat,first_image_transform)
        fig_geo_d.add_trace(go.Scatter(x=[col],y=[row],mode='markers+text', marker=dict(color='red',size=10,symbol='x'),name=n,text=n,textposition="top right", hovertemplate=f'<b>{n}</b><br>Lon:{lon:.4f}<br>Lat:{lat:.4f}<extra></extra>'))
    fig_geo_d.update_xaxes(visible=False); fig_geo_d.update_yaxes(visible=False,scaleanchor="x",scaleratio=1); fig_geo_d.update_layout(height=600,showlegend=True,legend_title_text="Î£Î·Î¼ÎµÎ¯Î±",uirevision='dashboard_geo')

    df_h_d = pd.DataFrame(columns=['Date', 'Height']) 
    if os.path.exists(str(lake_height_excel_path)):
        try:
            df_tmp=pd.read_excel(lake_height_excel_path)
            if not df_tmp.empty and len(df_tmp.columns)>=2:
                df_h_d['Date']=pd.to_datetime(df_tmp.iloc[:,0],errors='coerce'); df_h_d['Height']=pd.to_numeric(df_tmp.iloc[:,1],errors='coerce')
                df_h_d.dropna(inplace=True); df_h_d.sort_values('Date',inplace=True)
        except Exception as e: st.warning(f"Î£Ï†Î¬Î»Î¼Î± Î±Î½Î¬Î³Î½Ï‰ÏƒÎ·Ï‚ ÏƒÏ„Î¬Î¸Î¼Î·Ï‚ (dashboard): {e}")
            
    fig_colors_d=make_subplots(specs=[[{"secondary_y":True}]])
    pts_plot = selected_point_names_for_plot if selected_point_names_for_plot else [p[0] for p in sampling_points]
    pt_y_idx={n:i for i,n in enumerate(pts_plot)}

    for n_iter in pts_plot:
        if n_iter in results_colors_dash and results_colors_dash[n_iter]:
            d_list=sorted(results_colors_dash[n_iter],key=lambda x:x[0])
            if d_list:
                dts_c,cols_c_norm=zip(*d_list)
                cols_rgb_s=[f"rgb({int(c[0]*255)},{int(c[1]*255)},{int(c[2]*255)})" for c in cols_c_norm]
                y_p=pt_y_idx.get(n_iter,-1)
                if y_p != -1:
                    fig_colors_d.add_trace(go.Scatter(x=list(dts_c),y=[y_p]*len(dts_c),mode='markers',marker=dict(color=cols_rgb_s,size=10),name=n_iter,legendgroup=n_iter),secondary_y=False)
    
    if not df_h_d.empty: fig_colors_d.add_trace(go.Scatter(x=df_h_d['Date'],y=df_h_d['Height'],name='Î£Ï„Î¬Î¸Î¼Î·',mode='lines',line=dict(color='blue',width=2),legendgroup="h_grp"),secondary_y=True)
    fig_colors_d.update_layout(title='Î§ÏÏÎ¼Î±Ï„Î± Pixel & Î£Ï„Î¬Î¸Î¼Î·',xaxis_title='Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±',
                                yaxis=dict(title='Î£Î·Î¼ÎµÎ¯Î±',tickmode='array',tickvals=list(pt_y_idx.values()),ticktext=list(pt_y_idx.keys()),showgrid=False),
                                yaxis2=dict(title='Î£Ï„Î¬Î¸Î¼Î· (m)',showgrid=True,gridcolor='rgba(128,128,128,0.2)'),showlegend=True,uirevision='dashboard_colors')

    all_mg_vals_date_d={};
    for p_n in pts_plot: 
        if p_n in results_mg_dash:
            for d_obj,val_mg in results_mg_dash[p_n]: all_mg_vals_date_d.setdefault(d_obj,[]).append(val_mg)
    s_dates_mg_d=sorted(all_mg_vals_date_d.keys())
    avg_mg_d=[np.mean(all_mg_vals_date_d[d_obj]) for d_obj in s_dates_mg_d if all_mg_vals_date_d[d_obj]]
    
    fig_mg_d=go.Figure()
    if s_dates_mg_d and avg_mg_d: fig_mg_d.add_trace(go.Scatter(x=s_dates_mg_d,y=avg_mg_d,mode='lines+markers',name='ÎœÎ­ÏƒÎ¿ mg/mÂ³',marker=dict(color=avg_mg_d,colorscale='Viridis',reversescale=True,colorbar=dict(title='mg/mÂ³',thickness=15),size=10),line=dict(color='grey')))
    fig_mg_d.update_layout(title='ÎœÎ­ÏƒÎ¿ mg/mÂ³ (Î•Ï€Î¹Î»ÎµÎ³Î¼Î­Î½Î± Î£Î·Î¼ÎµÎ¯Î±)',xaxis_title='Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±',yaxis_title='mg/mÂ³',uirevision='dashboard_mg')

    fig_dual_d=make_subplots(specs=[[{"secondary_y":True}]])
    if not df_h_d.empty: 
        fig_dual_d.add_trace(go.Scatter(x=df_h_d['Date'],y=df_h_d['Height'],name='Î£Ï„Î¬Î¸Î¼Î·',mode='lines',line=dict(color='deepskyblue')),secondary_y=False)
    if s_dates_mg_d and avg_mg_d: 
        fig_dual_d.add_trace(go.Scatter(x=s_dates_mg_d,y=avg_mg_d,name='ÎœÎ­ÏƒÎ¿ mg/mÂ³',mode='lines+markers',marker=dict(color=avg_mg_d,colorscale='Viridis',reversescale=True,size=10,showscale=False),line=dict(color='lightgreen')),secondary_y=True)
    
    fig_dual_d.update_layout(
        title='Î£Ï„Î¬Î¸Î¼Î· & ÎœÎ­ÏƒÎ¿ mg/mÂ³',
        xaxis_title='Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±',
        uirevision='dashboard_dual', 
        yaxis=dict(title=dict(text="Î£Ï„Î¬Î¸Î¼Î· (m)", font=dict(color="deepskyblue")), tickfont=dict(color="deepskyblue"),side='left'),
        yaxis2=dict(title=dict(text="mg/mÂ³", font=dict(color="lightgreen")), tickfont=dict(color="lightgreen"),overlaying='y', side='right')
    )
    
    return fig_geo_d,fig_dual_d,fig_colors_d,fig_mg_d,results_colors_dash,results_mg_dash,df_h_d


def run_water_quality_dashboard(waterbody: str, index_name: str):
    with st.container():
        st.markdown('<div class="card">', unsafe_allow_html=True) # Changed to card
        st.header(f"Î ÏÎ¿Ï†Î¯Î» Î Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ ÎºÎ±Î¹ Î£Ï„Î¬Î¸Î¼Î·Ï‚: {waterbody} - {index_name}")
        
        clean_index_name_for_key = re.sub(r'[^a-zA-Z0-9_]', '', index_name)
        key_suffix_dash = f"_dash_{waterbody}_{clean_index_name_for_key}"
        common_filename_prefix_dash = f"{waterbody}_{index_name}" 

        data_folder = get_data_folder(waterbody, index_name)
        if not data_folder: 
            st.error(f"Î¦Î¬ÎºÎµÎ»Î¿Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î³Î¹Î± '{waterbody} - {index_name}' Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ. Î Î±ÏÎ±ÎºÎ±Î»Ï ÎµÎ»Î­Î³Î¾Ï„Îµ Ï„Î¹Ï‚ ÏÏ…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹ Ï„Î· Î´Î¿Î¼Î® Ï„Ï‰Î½ Ï†Î±ÎºÎ­Î»Ï‰Î½ ÏƒÎ±Ï‚.")
            st.markdown('</div>', unsafe_allow_html=True); return

        images_folder_path = os.path.join(data_folder,"GeoTIFFs")
        lake_height_excel_path = os.path.join(data_folder,"lake height.xlsx")
        default_sampling_kml_path = os.path.join(data_folder,"sampling.kml")
        vid_path = next((p for n in ["timelapse.mp4","timelapse.gif","Sentinel-2_L1C-202307221755611-timelapse.gif"] for p in [os.path.join(data_folder,n), os.path.join(images_folder_path,n)] if os.path.exists(p)), None)
        
        st.sidebar.subheader(f"Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚ Î Î¯Î½Î±ÎºÎ± ({index_name})")
        available_tifs = {str(d.date()):fn for fn in (os.listdir(images_folder_path) if os.path.exists(images_folder_path) else []) if fn.lower().endswith(('.tif','.tiff')) for _,d in [extract_date_from_filename(fn)] if d}
        
        first_img_rgb, first_img_transform = None, None
        if available_tifs:
            sel_bg_date_options = sorted(available_tifs.keys(),reverse=True)
            sel_bg_date_index = 0 if sel_bg_date_options else None

            sel_bg_date = st.sidebar.selectbox("Î•Î¹ÎºÏŒÎ½Î± Î‘Î½Î±Ï†Î¿ÏÎ¬Ï‚:", sel_bg_date_options, index=sel_bg_date_index, key=f"bg_date{key_suffix_dash}")
            if sel_bg_date and available_tifs.get(sel_bg_date):
                try:
                    with rasterio.open(os.path.join(images_folder_path,available_tifs[sel_bg_date])) as src:
                        if src.count>=3: first_img_rgb,first_img_transform = src.read([1,2,3]),src.transform
                        else: st.sidebar.error("Î•Î¹ÎºÏŒÎ½Î± < 3 ÎºÎ±Î½Î¬Î»Î¹Î±.")
                except Exception as e: st.sidebar.error(f"Î£Ï†Î¬Î»Î¼Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ Î±Î½Î±Ï†Î¿ÏÎ¬Ï‚: {e}")
        else: st.sidebar.warning("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ GeoTIFF Î³Î¹Î± ÎµÎ¹ÎºÏŒÎ½Î± Î±Î½Î±Ï†Î¿ÏÎ¬Ï‚.")

        if first_img_rgb is None: 
            st.error("Î‘Ï€Î±Î¹Ï„ÎµÎ¯Ï„Î±Î¹ Î­Î³ÎºÏ…ÏÎ· ÎµÎ¹ÎºÏŒÎ½Î± Î±Î½Î±Ï†Î¿ÏÎ¬Ï‚ GeoTIFF (Ï„Î¿Ï…Î»Î¬Ï‡Î¹ÏƒÏ„Î¿Î½ 3 ÎºÎ±Î½Î¬Î»Î¹Î±) Î³Î¹Î± Ï„Î· ÏƒÏ…Î½Î­Ï‡ÎµÎ¹Î± Ï„Î·Ï‚ Î±Î½Î¬Î»Ï…ÏƒÎ·Ï‚.")
            st.markdown('</div>', unsafe_allow_html=True); return

        tabs_ctrl = st.tabs(["Î”ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î± 1 (Î ÏÎ¿ÎµÏ€Î¹Î»Î¿Î³Î®)", "Î”ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î± 2 (Î‘Î½Î­Î²Î±ÏƒÎ¼Î± KML)"])
        
        with tabs_ctrl[0]: # Default Sampling
            st.markdown("##### Î‘Î½Î¬Î»Ï…ÏƒÎ· Î¼Îµ Î ÏÎ¿ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î± Î£Î·Î¼ÎµÎ¯Î±")
            def_pts_list = parse_sampling_kml(default_sampling_kml_path) if os.path.exists(default_sampling_kml_path) else []
            st.session_state[f"def_pts_list{key_suffix_dash}"] = def_pts_list 
            
            if def_pts_list:
                all_def_point_names = [n for n,_,_ in def_pts_list]
                default_selection = all_def_point_names[:] 

                sel_pts_def_names = st.multiselect("Î£Î·Î¼ÎµÎ¯Î± (Î ÏÎ¿ÎµÏ€Î¹Î»Î¿Î³Î®):", all_def_point_names, default=default_selection, key=f"sel_def{key_suffix_dash}")
                st.session_state[f"sel_pts_def_names{key_suffix_dash}"] = sel_pts_def_names 
                if st.button("Î•ÎºÏ„Î­Î»ÎµÏƒÎ· (Î ÏÎ¿ÎµÏ€Î¹Î»Î¿Î³Î®)", key=f"run_def{key_suffix_dash}", type="primary", use_container_width=True):
                    with st.spinner("Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Î±Î½Î¬Î»Ï…ÏƒÎ·Ï‚ Î³Î¹Î± Ï€ÏÎ¿ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î± ÏƒÎ·Î¼Îµ